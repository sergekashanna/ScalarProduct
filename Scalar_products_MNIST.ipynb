{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e4b6fed1-6bc0-4602-8475-49b1fe798c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "locals().clear()\n",
    "globals().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "51073833-bfa8-4a66-a38c-ad052098f18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Squared L2 Norm of Full Gradient: 37268453320.46509\n",
      "Sum of scalar products for gradients in same class: 31729373617.60672\n",
      "Sum of scalar products for gradients in different class: 5539079702.858368\n",
      "Loss: 74.95245361328125\n",
      "\n",
      "\n",
      "Iteration: 2\n",
      "Squared L2 Norm of Full Gradient: 17080578565.972656\n",
      "Sum of scalar products for gradients in same class: 28108120367.99756\n",
      "Sum of scalar products for gradients in different class: -11027541802.024902\n",
      "Loss: 54.22277069091797\n",
      "\n",
      "\n",
      "Iteration: 3\n",
      "Squared L2 Norm of Full Gradient: 11182722119.777588\n",
      "Sum of scalar products for gradients in same class: 24542971992.455017\n",
      "Sum of scalar products for gradients in different class: -13360249872.67743\n",
      "Loss: 42.149505615234375\n",
      "\n",
      "\n",
      "Iteration: 4\n",
      "Squared L2 Norm of Full Gradient: 8444399548.062073\n",
      "Sum of scalar products for gradients in same class: 21900292830.845398\n",
      "Sum of scalar products for gradients in different class: -13455893282.783325\n",
      "Loss: 34.15021896362305\n",
      "\n",
      "\n",
      "Iteration: 5\n",
      "Squared L2 Norm of Full Gradient: 7162624351.958557\n",
      "Sum of scalar products for gradients in same class: 18520951102.67638\n",
      "Sum of scalar products for gradients in different class: -11358326750.717823\n",
      "Loss: 28.238157272338867\n",
      "\n",
      "\n",
      "Iteration: 6\n",
      "Squared L2 Norm of Full Gradient: 6421680830.621338\n",
      "Sum of scalar products for gradients in same class: 17398723955.356674\n",
      "Sum of scalar products for gradients in different class: -10977043124.735336\n",
      "Loss: 24.11552619934082\n",
      "\n",
      "\n",
      "Iteration: 7\n",
      "Squared L2 Norm of Full Gradient: 6031353480.388245\n",
      "Sum of scalar products for gradients in same class: 13885628153.223473\n",
      "Sum of scalar products for gradients in different class: -7854274672.835228\n",
      "Loss: 20.159332275390625\n",
      "\n",
      "\n",
      "Iteration: 8\n",
      "Squared L2 Norm of Full Gradient: 6145477147.696289\n",
      "Sum of scalar products for gradients in same class: 14231622829.387325\n",
      "Sum of scalar products for gradients in different class: -8086145681.691036\n",
      "Loss: 17.529224395751953\n",
      "\n",
      "\n",
      "Iteration: 9\n",
      "Squared L2 Norm of Full Gradient: 6013314263.441406\n",
      "Sum of scalar products for gradients in same class: 11271847626.287354\n",
      "Sum of scalar products for gradients in different class: -5258533362.845947\n",
      "Loss: 14.826579093933105\n",
      "\n",
      "\n",
      "Iteration: 10\n",
      "Squared L2 Norm of Full Gradient: 5528037510.754456\n",
      "Sum of scalar products for gradients in same class: 10047452857.212292\n",
      "Sum of scalar products for gradients in different class: -4519415346.457836\n",
      "Loss: 13.084443092346191\n",
      "\n",
      "\n",
      "Iteration: 11\n",
      "Squared L2 Norm of Full Gradient: 4865281561.059631\n",
      "Sum of scalar products for gradients in same class: 8719179731.271255\n",
      "Sum of scalar products for gradients in different class: -3853898170.211624\n",
      "Loss: 11.141469955444336\n",
      "\n",
      "\n",
      "Iteration: 12\n",
      "Squared L2 Norm of Full Gradient: 4790234976.539612\n",
      "Sum of scalar products for gradients in same class: 7131706076.52488\n",
      "Sum of scalar products for gradients in different class: -2341471099.9852686\n",
      "Loss: 9.89112377166748\n",
      "\n",
      "\n",
      "Iteration: 13\n",
      "Squared L2 Norm of Full Gradient: 4929305875.031494\n",
      "Sum of scalar products for gradients in same class: 7639876479.539163\n",
      "Sum of scalar products for gradients in different class: -2710570604.5076685\n",
      "Loss: 9.073284149169922\n",
      "\n",
      "\n",
      "Iteration: 14\n",
      "Squared L2 Norm of Full Gradient: 3797297362.249283\n",
      "Sum of scalar products for gradients in same class: 5774037621.301059\n",
      "Sum of scalar products for gradients in different class: -1976740259.051776\n",
      "Loss: 8.260321617126465\n",
      "\n",
      "\n",
      "Iteration: 15\n",
      "Squared L2 Norm of Full Gradient: 2242610344.386612\n",
      "Sum of scalar products for gradients in same class: 5031128094.158753\n",
      "Sum of scalar products for gradients in different class: -2788517749.7721415\n",
      "Loss: 7.010819435119629\n",
      "\n",
      "\n",
      "Iteration: 16\n",
      "Squared L2 Norm of Full Gradient: 1599737198.2922516\n",
      "Sum of scalar products for gradients in same class: 3599794238.5495358\n",
      "Sum of scalar products for gradients in different class: -2000057040.2572842\n",
      "Loss: 6.110860824584961\n",
      "\n",
      "\n",
      "Iteration: 17\n",
      "Squared L2 Norm of Full Gradient: 1778715468.3916626\n",
      "Sum of scalar products for gradients in same class: 3680624820.40996\n",
      "Sum of scalar products for gradients in different class: -1901909352.0182972\n",
      "Loss: 5.708935260772705\n",
      "\n",
      "\n",
      "Iteration: 18\n",
      "Squared L2 Norm of Full Gradient: 1558182798.452774\n",
      "Sum of scalar products for gradients in same class: 3089365654.513117\n",
      "Sum of scalar products for gradients in different class: -1531182856.0603428\n",
      "Loss: 5.336705684661865\n",
      "\n",
      "\n",
      "Iteration: 19\n",
      "Squared L2 Norm of Full Gradient: 1207449022.1973267\n",
      "Sum of scalar products for gradients in same class: 2831920223.5218763\n",
      "Sum of scalar products for gradients in different class: -1624471201.3245497\n",
      "Loss: 4.8161821365356445\n",
      "\n",
      "\n",
      "Iteration: 20\n",
      "Squared L2 Norm of Full Gradient: 1031616234.4493446\n",
      "Sum of scalar products for gradients in same class: 2469954569.5712643\n",
      "Sum of scalar products for gradients in different class: -1438338335.1219196\n",
      "Loss: 4.464752674102783\n",
      "\n",
      "\n",
      "Iteration: 21\n",
      "Squared L2 Norm of Full Gradient: 775245591.6985512\n",
      "Sum of scalar products for gradients in same class: 2229425610.870783\n",
      "Sum of scalar products for gradients in different class: -1454180019.1722317\n",
      "Loss: 4.1108927726745605\n",
      "\n",
      "\n",
      "Iteration: 22\n",
      "Squared L2 Norm of Full Gradient: 581111194.8974648\n",
      "Sum of scalar products for gradients in same class: 1797463266.3463964\n",
      "Sum of scalar products for gradients in different class: -1216352071.4489317\n",
      "Loss: 3.7770707607269287\n",
      "\n",
      "\n",
      "Iteration: 23\n",
      "Squared L2 Norm of Full Gradient: 527184739.6289215\n",
      "Sum of scalar products for gradients in same class: 1897829163.7535448\n",
      "Sum of scalar products for gradients in different class: -1370644424.1246233\n",
      "Loss: 3.4944705963134766\n",
      "\n",
      "\n",
      "Iteration: 24\n",
      "Squared L2 Norm of Full Gradient: 511679156.1220131\n",
      "Sum of scalar products for gradients in same class: 1492866527.8128064\n",
      "Sum of scalar products for gradients in different class: -981187371.6907933\n",
      "Loss: 3.256578207015991\n",
      "\n",
      "\n",
      "Iteration: 25\n",
      "Squared L2 Norm of Full Gradient: 426131029.9018707\n",
      "Sum of scalar products for gradients in same class: 1650179450.968296\n",
      "Sum of scalar products for gradients in different class: -1224048421.0664253\n",
      "Loss: 3.010618209838867\n",
      "\n",
      "\n",
      "Iteration: 26\n",
      "Squared L2 Norm of Full Gradient: 383399422.1424904\n",
      "Sum of scalar products for gradients in same class: 1279296759.1296754\n",
      "Sum of scalar products for gradients in different class: -895897336.987185\n",
      "Loss: 2.757171869277954\n",
      "\n",
      "\n",
      "Iteration: 27\n",
      "Squared L2 Norm of Full Gradient: 448729832.3213234\n",
      "Sum of scalar products for gradients in same class: 1461669430.4986956\n",
      "Sum of scalar products for gradients in different class: -1012939598.1773722\n",
      "Loss: 2.5757253170013428\n",
      "\n",
      "\n",
      "Iteration: 28\n",
      "Squared L2 Norm of Full Gradient: 539649324.4609108\n",
      "Sum of scalar products for gradients in same class: 1269704731.3862348\n",
      "Sum of scalar products for gradients in different class: -730055406.925324\n",
      "Loss: 2.4233930110931396\n",
      "\n",
      "\n",
      "Iteration: 29\n",
      "Squared L2 Norm of Full Gradient: 966468358.6305084\n",
      "Sum of scalar products for gradients in same class: 1703892117.16241\n",
      "Sum of scalar products for gradients in different class: -737423758.5319016\n",
      "Loss: 2.3182053565979004\n",
      "\n",
      "\n",
      "Iteration: 30\n",
      "Squared L2 Norm of Full Gradient: 1169782682.4761353\n",
      "Sum of scalar products for gradients in same class: 1604040270.0279007\n",
      "Sum of scalar products for gradients in different class: -434257587.55176544\n",
      "Loss: 2.368055582046509\n",
      "\n",
      "\n",
      "Iteration: 31\n",
      "Squared L2 Norm of Full Gradient: 1120208214.6915436\n",
      "Sum of scalar products for gradients in same class: 1812048224.9889054\n",
      "Sum of scalar products for gradients in different class: -691840010.2973619\n",
      "Loss: 2.1294400691986084\n",
      "\n",
      "\n",
      "Iteration: 32\n",
      "Squared L2 Norm of Full Gradient: 1014291247.4099159\n",
      "Sum of scalar products for gradients in same class: 1372142493.5313125\n",
      "Sum of scalar products for gradients in different class: -357851246.12139654\n",
      "Loss: 2.0512382984161377\n",
      "\n",
      "\n",
      "Iteration: 33\n",
      "Squared L2 Norm of Full Gradient: 751493343.0576324\n",
      "Sum of scalar products for gradients in same class: 1305835399.7073328\n",
      "Sum of scalar products for gradients in different class: -554342056.6497004\n",
      "Loss: 1.820668339729309\n",
      "\n",
      "\n",
      "Iteration: 34\n",
      "Squared L2 Norm of Full Gradient: 637861885.7239723\n",
      "Sum of scalar products for gradients in same class: 1048599945.4643764\n",
      "Sum of scalar products for gradients in different class: -410738059.7404041\n",
      "Loss: 1.7183805704116821\n",
      "\n",
      "\n",
      "Iteration: 35\n",
      "Squared L2 Norm of Full Gradient: 592975005.8498535\n",
      "Sum of scalar products for gradients in same class: 877175491.0831134\n",
      "Sum of scalar products for gradients in different class: -284200485.2332599\n",
      "Loss: 1.5938626527786255\n",
      "\n",
      "\n",
      "Iteration: 36\n",
      "Squared L2 Norm of Full Gradient: 544489501.8002357\n",
      "Sum of scalar products for gradients in same class: 886460243.603107\n",
      "Sum of scalar products for gradients in different class: -341970741.8028712\n",
      "Loss: 1.4754825830459595\n",
      "\n",
      "\n",
      "Iteration: 37\n",
      "Squared L2 Norm of Full Gradient: 507589635.0625\n",
      "Sum of scalar products for gradients in same class: 777552892.8751881\n",
      "Sum of scalar products for gradients in different class: -269963257.8126881\n",
      "Loss: 1.3630868196487427\n",
      "\n",
      "\n",
      "Iteration: 38\n",
      "Squared L2 Norm of Full Gradient: 444008194.5605507\n",
      "Sum of scalar products for gradients in same class: 745156020.8689454\n",
      "Sum of scalar products for gradients in different class: -301147826.3083947\n",
      "Loss: 1.266362190246582\n",
      "\n",
      "\n",
      "Iteration: 39\n",
      "Squared L2 Norm of Full Gradient: 361383961.41656494\n",
      "Sum of scalar products for gradients in same class: 668248826.6989014\n",
      "Sum of scalar products for gradients in different class: -306864865.2823365\n",
      "Loss: 1.1526850461959839\n",
      "\n",
      "\n",
      "Iteration: 40\n",
      "Squared L2 Norm of Full Gradient: 301837009.21669006\n",
      "Sum of scalar products for gradients in same class: 607026464.9103302\n",
      "Sum of scalar products for gradients in different class: -305189455.6936401\n",
      "Loss: 1.0555164813995361\n",
      "\n",
      "\n",
      "Iteration: 41\n",
      "Squared L2 Norm of Full Gradient: 284980624.06204605\n",
      "Sum of scalar products for gradients in same class: 575998875.5739889\n",
      "Sum of scalar products for gradients in different class: -291018251.51194286\n",
      "Loss: 0.9619998335838318\n",
      "\n",
      "\n",
      "Iteration: 42\n",
      "Squared L2 Norm of Full Gradient: 299195735.93912125\n",
      "Sum of scalar products for gradients in same class: 571377608.068047\n",
      "Sum of scalar products for gradients in different class: -272181872.1289258\n",
      "Loss: 0.8946291208267212\n",
      "\n",
      "\n",
      "Iteration: 43\n",
      "Squared L2 Norm of Full Gradient: 353804049.9463501\n",
      "Sum of scalar products for gradients in same class: 566399543.4671053\n",
      "Sum of scalar products for gradients in different class: -212595493.52075517\n",
      "Loss: 0.8271061778068542\n",
      "\n",
      "\n",
      "Iteration: 44\n",
      "Squared L2 Norm of Full Gradient: 416964036.4197731\n",
      "Sum of scalar products for gradients in same class: 595132715.3545063\n",
      "Sum of scalar products for gradients in different class: -178168678.93473315\n",
      "Loss: 0.7916351556777954\n",
      "\n",
      "\n",
      "Iteration: 45\n",
      "Squared L2 Norm of Full Gradient: 490969866.541275\n",
      "Sum of scalar products for gradients in same class: 607550009.801506\n",
      "Sum of scalar products for gradients in different class: -116580143.26023102\n",
      "Loss: 0.739854097366333\n",
      "\n",
      "\n",
      "Iteration: 46\n",
      "Squared L2 Norm of Full Gradient: 527082408.9117775\n",
      "Sum of scalar products for gradients in same class: 610730460.1236036\n",
      "Sum of scalar products for gradients in different class: -83648051.21182609\n",
      "Loss: 0.7190091609954834\n",
      "\n",
      "\n",
      "Iteration: 47\n",
      "Squared L2 Norm of Full Gradient: 515228374.88946915\n",
      "Sum of scalar products for gradients in same class: 594415587.8207892\n",
      "Sum of scalar products for gradients in different class: -79187212.93132007\n",
      "Loss: 0.6489787101745605\n",
      "\n",
      "\n",
      "Iteration: 48\n",
      "Squared L2 Norm of Full Gradient: 467075926.9255409\n",
      "Sum of scalar products for gradients in same class: 548352054.7626231\n",
      "Sum of scalar products for gradients in different class: -81276127.83708215\n",
      "Loss: 0.6073148846626282\n",
      "\n",
      "\n",
      "Iteration: 49\n",
      "Squared L2 Norm of Full Gradient: 361403788.6303749\n",
      "Sum of scalar products for gradients in same class: 429580473.8145986\n",
      "Sum of scalar products for gradients in different class: -68176685.18422371\n",
      "Loss: 0.5264860987663269\n",
      "\n",
      "\n",
      "Iteration: 50\n",
      "Squared L2 Norm of Full Gradient: 295815880.179142\n",
      "Sum of scalar products for gradients in same class: 403576080.5773737\n",
      "Sum of scalar products for gradients in different class: -107760200.39823169\n",
      "Loss: 0.46186181902885437\n",
      "\n",
      "\n",
      "Iteration: 51\n",
      "Squared L2 Norm of Full Gradient: 223547439.8564539\n",
      "Sum of scalar products for gradients in same class: 293787167.67930484\n",
      "Sum of scalar products for gradients in different class: -70239727.82285094\n",
      "Loss: 0.4082717001438141\n",
      "\n",
      "\n",
      "Iteration: 52\n",
      "Squared L2 Norm of Full Gradient: 193121180.52252197\n",
      "Sum of scalar products for gradients in same class: 292723480.0003753\n",
      "Sum of scalar products for gradients in different class: -99602299.4778533\n",
      "Loss: 0.34402355551719666\n",
      "\n",
      "\n",
      "Iteration: 53\n",
      "Squared L2 Norm of Full Gradient: 190838683.44140625\n",
      "Sum of scalar products for gradients in same class: 245424169.67437696\n",
      "Sum of scalar products for gradients in different class: -54585486.232970715\n",
      "Loss: 0.31811994314193726\n",
      "\n",
      "\n",
      "Iteration: 54\n",
      "Squared L2 Norm of Full Gradient: 205922696.19145298\n",
      "Sum of scalar products for gradients in same class: 270062205.197858\n",
      "Sum of scalar products for gradients in different class: -64139509.006404996\n",
      "Loss: 0.27519261837005615\n",
      "\n",
      "\n",
      "Iteration: 55\n",
      "Squared L2 Norm of Full Gradient: 308588578.3425331\n",
      "Sum of scalar products for gradients in same class: 281324941.54162323\n",
      "Sum of scalar products for gradients in different class: 27263636.800909877\n",
      "Loss: 0.2665722370147705\n",
      "\n",
      "\n",
      "Iteration: 56\n",
      "Squared L2 Norm of Full Gradient: 396528657.9929352\n",
      "Sum of scalar products for gradients in same class: 385288035.5979896\n",
      "Sum of scalar products for gradients in different class: 11240622.394945562\n",
      "Loss: 0.2776445150375366\n",
      "\n",
      "\n",
      "Iteration: 57\n",
      "Squared L2 Norm of Full Gradient: 497905182.3257446\n",
      "Sum of scalar products for gradients in same class: 369547690.4710239\n",
      "Sum of scalar products for gradients in different class: 128357491.85472071\n",
      "Loss: 0.2588959038257599\n",
      "\n",
      "\n",
      "Iteration: 58\n",
      "Squared L2 Norm of Full Gradient: 500929793.6968384\n",
      "Sum of scalar products for gradients in same class: 482264646.02417094\n",
      "Sum of scalar products for gradients in different class: 18665147.672667444\n",
      "Loss: 0.27553290128707886\n",
      "\n",
      "\n",
      "Iteration: 59\n",
      "Squared L2 Norm of Full Gradient: 382966706.2317047\n",
      "Sum of scalar products for gradients in same class: 280936025.76363164\n",
      "Sum of scalar products for gradients in different class: 102030680.46807307\n",
      "Loss: 0.20584160089492798\n",
      "\n",
      "\n",
      "Iteration: 60\n",
      "Squared L2 Norm of Full Gradient: 253519631.0703516\n",
      "Sum of scalar products for gradients in same class: 273697034.2276677\n",
      "Sum of scalar products for gradients in different class: -20177403.15731609\n",
      "Loss: 0.1702549308538437\n",
      "\n",
      "\n",
      "Iteration: 61\n",
      "Squared L2 Norm of Full Gradient: 86977263.26002502\n",
      "Sum of scalar products for gradients in same class: 97264910.03558882\n",
      "Sum of scalar products for gradients in different class: -10287646.775563791\n",
      "Loss: 0.11018639802932739\n",
      "\n",
      "\n",
      "Iteration: 62\n",
      "Squared L2 Norm of Full Gradient: 23073734.21402836\n",
      "Sum of scalar products for gradients in same class: 62955189.23021129\n",
      "Sum of scalar products for gradients in different class: -39881455.01618293\n",
      "Loss: 0.06698113679885864\n",
      "\n",
      "\n",
      "Iteration: 63\n",
      "Squared L2 Norm of Full Gradient: 11519474.641860962\n",
      "Sum of scalar products for gradients in same class: 39886100.47923923\n",
      "Sum of scalar products for gradients in different class: -28366625.83737827\n",
      "Loss: 0.048671890050172806\n",
      "\n",
      "\n",
      "Iteration: 64\n",
      "Squared L2 Norm of Full Gradient: 7338542.111496985\n",
      "Sum of scalar products for gradients in same class: 31697989.694615755\n",
      "Sum of scalar products for gradients in different class: -24359447.58311877\n",
      "Loss: 0.03787694498896599\n",
      "\n",
      "\n",
      "Iteration: 65\n",
      "Squared L2 Norm of Full Gradient: 4901514.929810524\n",
      "Sum of scalar products for gradients in same class: 23828079.263495494\n",
      "Sum of scalar products for gradients in different class: -18926564.33368497\n",
      "Loss: 0.030665505677461624\n",
      "\n",
      "\n",
      "Iteration: 66\n",
      "Squared L2 Norm of Full Gradient: 3400134.3154907227\n",
      "Sum of scalar products for gradients in same class: 18415467.598290566\n",
      "Sum of scalar products for gradients in different class: -15015333.282799844\n",
      "Loss: 0.025739677250385284\n",
      "\n",
      "\n",
      "Iteration: 67\n",
      "Squared L2 Norm of Full Gradient: 2462352.4749765396\n",
      "Sum of scalar products for gradients in same class: 14473172.781718697\n",
      "Sum of scalar products for gradients in different class: -12010820.306742158\n",
      "Loss: 0.022258395329117775\n",
      "\n",
      "\n",
      "Iteration: 68\n",
      "Squared L2 Norm of Full Gradient: 1858014.2549200207\n",
      "Sum of scalar products for gradients in same class: 11567632.51622364\n",
      "Sum of scalar products for gradients in different class: -9709618.261303619\n",
      "Loss: 0.01970898173749447\n",
      "\n",
      "\n",
      "Iteration: 69\n",
      "Squared L2 Norm of Full Gradient: 1452863.8552504927\n",
      "Sum of scalar products for gradients in same class: 9528884.16731928\n",
      "Sum of scalar products for gradients in different class: -8076020.3120687865\n",
      "Loss: 0.017767343670129776\n",
      "\n",
      "\n",
      "Iteration: 70\n",
      "Squared L2 Norm of Full Gradient: 1169834.2135641724\n",
      "Sum of scalar products for gradients in same class: 7984164.914624045\n",
      "Sum of scalar products for gradients in different class: -6814330.701059872\n",
      "Loss: 0.016237899661064148\n",
      "\n",
      "\n",
      "Iteration: 71\n",
      "Squared L2 Norm of Full Gradient: 964756.6703476347\n",
      "Sum of scalar products for gradients in same class: 6830810.243015316\n",
      "Sum of scalar products for gradients in different class: -5866053.572667682\n",
      "Loss: 0.014999043196439743\n",
      "\n",
      "\n",
      "Iteration: 72\n",
      "Squared L2 Norm of Full Gradient: 811357.379714027\n",
      "Sum of scalar products for gradients in same class: 5927144.903765816\n",
      "Sum of scalar products for gradients in different class: -5115787.524051789\n",
      "Loss: 0.013972398824989796\n",
      "\n",
      "\n",
      "Iteration: 73\n",
      "Squared L2 Norm of Full Gradient: 693506.9219954163\n",
      "Sum of scalar products for gradients in same class: 5212480.783826799\n",
      "Sum of scalar products for gradients in different class: -4518973.861831383\n",
      "Loss: 0.01310550607740879\n",
      "\n",
      "\n",
      "Iteration: 74\n",
      "Squared L2 Norm of Full Gradient: 600885.379776001\n",
      "Sum of scalar products for gradients in same class: 4633585.276064889\n",
      "Sum of scalar products for gradients in different class: -4032699.8962888876\n",
      "Loss: 0.012361972592771053\n",
      "\n",
      "\n",
      "Iteration: 75\n",
      "Squared L2 Norm of Full Gradient: 526672.9308486916\n",
      "Sum of scalar products for gradients in same class: 4157755.590237093\n",
      "Sum of scalar products for gradients in different class: -3631082.6593884015\n",
      "Loss: 0.0117159653455019\n",
      "\n",
      "\n",
      "Iteration: 76\n",
      "Squared L2 Norm of Full Gradient: 466210.32227218524\n",
      "Sum of scalar products for gradients in same class: 3760771.535753133\n",
      "Sum of scalar products for gradients in different class: -3294561.2134809475\n",
      "Loss: 0.011148330755531788\n",
      "\n",
      "\n",
      "Iteration: 77\n",
      "Squared L2 Norm of Full Gradient: 416235.407456398\n",
      "Sum of scalar products for gradients in same class: 3425434.558382958\n",
      "Sum of scalar products for gradients in different class: -3009199.15092656\n",
      "Loss: 0.010644765570759773\n",
      "\n",
      "\n",
      "Iteration: 78\n",
      "Squared L2 Norm of Full Gradient: 374402.44355339184\n",
      "Sum of scalar products for gradients in same class: 3138998.6375057045\n",
      "Sum of scalar products for gradients in different class: -2764596.1939523127\n",
      "Loss: 0.010194361209869385\n",
      "\n",
      "\n",
      "Iteration: 79\n",
      "Squared L2 Norm of Full Gradient: 338993.3848375119\n",
      "Sum of scalar products for gradients in same class: 2891919.507422286\n",
      "Sum of scalar products for gradients in different class: -2552926.122584774\n",
      "Loss: 0.009788550436496735\n",
      "\n",
      "\n",
      "Iteration: 80\n",
      "Squared L2 Norm of Full Gradient: 308724.97362984717\n",
      "Sum of scalar products for gradients in same class: 2676932.6972616287\n",
      "Sum of scalar products for gradients in different class: -2368207.7236317815\n",
      "Loss: 0.009420568123459816\n",
      "\n",
      "\n",
      "Iteration: 81\n",
      "Squared L2 Norm of Full Gradient: 282622.41501511633\n",
      "Sum of scalar products for gradients in same class: 2488386.7341873953\n",
      "Sum of scalar products for gradients in different class: -2205764.319172279\n",
      "Loss: 0.009084992110729218\n",
      "\n",
      "\n",
      "Iteration: 82\n",
      "Squared L2 Norm of Full Gradient: 259936.4173298478\n",
      "Sum of scalar products for gradients in same class: 2321899.694324363\n",
      "Sum of scalar products for gradients in different class: -2061963.2769945152\n",
      "Loss: 0.008777523413300514\n",
      "\n",
      "\n",
      "Iteration: 83\n",
      "Squared L2 Norm of Full Gradient: 240075.83556896448\n",
      "Sum of scalar products for gradients in same class: 2173910.956042841\n",
      "Sum of scalar products for gradients in different class: -1933835.1204738766\n",
      "Loss: 0.008494392968714237\n",
      "\n",
      "\n",
      "Iteration: 84\n",
      "Squared L2 Norm of Full Gradient: 222577.89339460433\n",
      "Sum of scalar products for gradients in same class: 2041636.0877461426\n",
      "Sum of scalar products for gradients in different class: -1819058.1943515383\n",
      "Loss: 0.008232615888118744\n",
      "\n",
      "\n",
      "Iteration: 85\n",
      "Squared L2 Norm of Full Gradient: 207071.43570905924\n",
      "Sum of scalar products for gradients in same class: 1922783.8623809377\n",
      "Sum of scalar products for gradients in different class: -1715712.4266718784\n",
      "Loss: 0.007989718578755856\n",
      "\n",
      "\n",
      "Iteration: 86\n",
      "Squared L2 Norm of Full Gradient: 193254.9268512288\n",
      "Sum of scalar products for gradients in same class: 1815474.2884589427\n",
      "Sum of scalar products for gradients in different class: -1622219.3616077139\n",
      "Loss: 0.0077635757625103\n",
      "\n",
      "\n",
      "Iteration: 87\n",
      "Squared L2 Norm of Full Gradient: 180883.6618731022\n",
      "Sum of scalar products for gradients in same class: 1718156.1350973726\n",
      "Sum of scalar products for gradients in different class: -1537272.4732242704\n",
      "Loss: 0.007552373223006725\n",
      "\n",
      "\n",
      "Iteration: 88\n",
      "Squared L2 Norm of Full Gradient: 169757.50393067393\n",
      "Sum of scalar products for gradients in same class: 1629562.3943643402\n",
      "Sum of scalar products for gradients in different class: -1459804.8904336663\n",
      "Loss: 0.00735453749075532\n",
      "\n",
      "\n",
      "Iteration: 89\n",
      "Squared L2 Norm of Full Gradient: 159707.77515380178\n",
      "Sum of scalar products for gradients in same class: 1548592.284502199\n",
      "Sum of scalar products for gradients in different class: -1388884.5093483971\n",
      "Loss: 0.007168776821345091\n",
      "\n",
      "\n",
      "Iteration: 90\n",
      "Squared L2 Norm of Full Gradient: 150595.48828840628\n",
      "Sum of scalar products for gradients in same class: 1474338.4734242132\n",
      "Sum of scalar products for gradients in different class: -1323742.985135807\n",
      "Loss: 0.006993935909122229\n",
      "\n",
      "\n",
      "Iteration: 91\n",
      "Squared L2 Norm of Full Gradient: 142302.68840745464\n",
      "Sum of scalar products for gradients in same class: 1406021.2432757376\n",
      "Sum of scalar products for gradients in different class: -1263718.554868283\n",
      "Loss: 0.006828951183706522\n",
      "\n",
      "\n",
      "Iteration: 92\n",
      "Squared L2 Norm of Full Gradient: 134732.48171918932\n",
      "Sum of scalar products for gradients in same class: 1342997.7486030287\n",
      "Sum of scalar products for gradients in different class: -1208265.2668838394\n",
      "Loss: 0.006672960706055164\n",
      "\n",
      "\n",
      "Iteration: 93\n",
      "Squared L2 Norm of Full Gradient: 127797.30392852798\n",
      "Sum of scalar products for gradients in same class: 1284670.1561652352\n",
      "Sum of scalar products for gradients in different class: -1156872.8522367072\n",
      "Loss: 0.006525225471705198\n",
      "\n",
      "\n",
      "Iteration: 94\n",
      "Squared L2 Norm of Full Gradient: 121427.40703225136\n",
      "Sum of scalar products for gradients in same class: 1230568.5639322896\n",
      "Sum of scalar products for gradients in different class: -1109141.1569000382\n",
      "Loss: 0.0063850162550807\n",
      "\n",
      "\n",
      "Iteration: 95\n",
      "Squared L2 Norm of Full Gradient: 115560.09743810538\n",
      "Sum of scalar products for gradients in same class: 1180259.6036132476\n",
      "Sum of scalar products for gradients in different class: -1064699.5061751422\n",
      "Loss: 0.006251777522265911\n",
      "\n",
      "\n",
      "Iteration: 96\n",
      "Squared L2 Norm of Full Gradient: 110140.91434481088\n",
      "Sum of scalar products for gradients in same class: 1133364.1192538135\n",
      "Sum of scalar products for gradients in different class: -1023223.2049090026\n",
      "Loss: 0.006124905776232481\n",
      "\n",
      "\n",
      "Iteration: 97\n",
      "Squared L2 Norm of Full Gradient: 105124.56571028009\n",
      "Sum of scalar products for gradients in same class: 1089567.4068815971\n",
      "Sum of scalar products for gradients in different class: -984442.841171317\n",
      "Loss: 0.0060039390809834\n",
      "\n",
      "\n",
      "Iteration: 98\n",
      "Squared L2 Norm of Full Gradient: 100470.40729320142\n",
      "Sum of scalar products for gradients in same class: 1048583.4613839232\n",
      "Sum of scalar products for gradients in different class: -948113.0540907218\n",
      "Loss: 0.005888447165489197\n",
      "\n",
      "\n",
      "Iteration: 99\n",
      "Squared L2 Norm of Full Gradient: 96142.17930983845\n",
      "Sum of scalar products for gradients in same class: 1010150.0081271359\n",
      "Sum of scalar products for gradients in different class: -914007.8288172975\n",
      "Loss: 0.005778038874268532\n",
      "\n",
      "\n",
      "Iteration: 100\n",
      "Squared L2 Norm of Full Gradient: 92109.65663446486\n",
      "Sum of scalar products for gradients in same class: 974050.7769477449\n",
      "Sum of scalar products for gradients in different class: -881941.12031328\n",
      "Loss: 0.0056723542511463165\n",
      "\n",
      "\n",
      "Iteration: 101\n",
      "Squared L2 Norm of Full Gradient: 88345.02633885387\n",
      "Sum of scalar products for gradients in same class: 940085.8499495178\n",
      "Sum of scalar products for gradients in different class: -851740.8236106639\n",
      "Loss: 0.005571064539253712\n",
      "\n",
      "\n",
      "Iteration: 102\n",
      "Squared L2 Norm of Full Gradient: 84824.21601964533\n",
      "Sum of scalar products for gradients in same class: 908080.501078608\n",
      "Sum of scalar products for gradients in different class: -823256.2850589626\n",
      "Loss: 0.005473894998431206\n",
      "\n",
      "\n",
      "Iteration: 103\n",
      "Squared L2 Norm of Full Gradient: 81525.62004822865\n",
      "Sum of scalar products for gradients in same class: 877873.2071751263\n",
      "Sum of scalar products for gradients in different class: -796347.5871268976\n",
      "Loss: 0.005380578339099884\n",
      "\n",
      "\n",
      "Iteration: 104\n",
      "Squared L2 Norm of Full Gradient: 78430.06391674373\n",
      "Sum of scalar products for gradients in same class: 849323.5287455842\n",
      "Sum of scalar products for gradients in different class: -770893.4648288405\n",
      "Loss: 0.00529087707400322\n",
      "\n",
      "\n",
      "Iteration: 105\n",
      "Squared L2 Norm of Full Gradient: 75520.70248895884\n",
      "Sum of scalar products for gradients in same class: 822301.7918641292\n",
      "Sum of scalar products for gradients in different class: -746781.0893751704\n",
      "Loss: 0.00520454254001379\n",
      "\n",
      "\n",
      "Iteration: 106\n",
      "Squared L2 Norm of Full Gradient: 72781.9228515625\n",
      "Sum of scalar products for gradients in same class: 796693.3534283987\n",
      "Sum of scalar products for gradients in different class: -723911.4305768362\n",
      "Loss: 0.005121392197906971\n",
      "\n",
      "\n",
      "Iteration: 107\n",
      "Squared L2 Norm of Full Gradient: 70200.51421973482\n",
      "Sum of scalar products for gradients in same class: 772398.4868208498\n",
      "Sum of scalar products for gradients in different class: -702197.972601115\n",
      "Loss: 0.005041260737925768\n",
      "\n",
      "\n",
      "Iteration: 108\n",
      "Squared L2 Norm of Full Gradient: 67763.678059116\n",
      "Sum of scalar products for gradients in same class: 749317.2534325938\n",
      "Sum of scalar products for gradients in different class: -681553.5753734778\n",
      "Loss: 0.0049639539793133736\n",
      "\n",
      "\n",
      "Iteration: 109\n",
      "Squared L2 Norm of Full Gradient: 65460.87310519279\n",
      "Sum of scalar products for gradients in same class: 727369.1165508914\n",
      "Sum of scalar products for gradients in different class: -661908.2434456986\n",
      "Loss: 0.004889300558716059\n",
      "\n",
      "\n",
      "Iteration: 110\n",
      "Squared L2 Norm of Full Gradient: 63281.365272917086\n",
      "Sum of scalar products for gradients in same class: 706472.5110890006\n",
      "Sum of scalar products for gradients in different class: -643191.1458160835\n",
      "Loss: 0.004817192908376455\n",
      "\n",
      "\n",
      "Iteration: 111\n",
      "Squared L2 Norm of Full Gradient: 61216.67814590037\n",
      "Sum of scalar products for gradients in same class: 686560.1168625285\n",
      "Sum of scalar products for gradients in different class: -625343.4387166281\n",
      "Loss: 0.004747454077005386\n",
      "\n",
      "\n",
      "Iteration: 112\n",
      "Squared L2 Norm of Full Gradient: 59258.2950542951\n",
      "Sum of scalar products for gradients in same class: 667564.9051396637\n",
      "Sum of scalar products for gradients in different class: -608306.6100853686\n",
      "Loss: 0.004679983481764793\n",
      "\n",
      "\n",
      "Iteration: 113\n",
      "Squared L2 Norm of Full Gradient: 57399.01596229174\n",
      "Sum of scalar products for gradients in same class: 649430.2063660005\n",
      "Sum of scalar products for gradients in different class: -592031.1904037087\n",
      "Loss: 0.00461465772241354\n",
      "\n",
      "\n",
      "Iteration: 114\n",
      "Squared L2 Norm of Full Gradient: 55631.40826430754\n",
      "Sum of scalar products for gradients in same class: 632096.9370566914\n",
      "Sum of scalar products for gradients in different class: -576465.5287923838\n",
      "Loss: 0.00455137575045228\n",
      "\n",
      "\n",
      "Iteration: 115\n",
      "Squared L2 Norm of Full Gradient: 53950.02827704046\n",
      "Sum of scalar products for gradients in same class: 615522.8833895975\n",
      "Sum of scalar products for gradients in different class: -561572.8551125571\n",
      "Loss: 0.004490040708333254\n",
      "\n",
      "\n",
      "Iteration: 116\n",
      "Squared L2 Norm of Full Gradient: 52348.442914904095\n",
      "Sum of scalar products for gradients in same class: 599653.0469828739\n",
      "Sum of scalar products for gradients in different class: -547304.6040679698\n",
      "Loss: 0.004430545028299093\n",
      "\n",
      "\n",
      "Iteration: 117\n",
      "Squared L2 Norm of Full Gradient: 50821.91505061928\n",
      "Sum of scalar products for gradients in same class: 584451.0103454622\n",
      "Sum of scalar products for gradients in different class: -533629.095294843\n",
      "Loss: 0.004372816998511553\n",
      "\n",
      "\n",
      "Iteration: 118\n",
      "Squared L2 Norm of Full Gradient: 49365.3662581949\n",
      "Sum of scalar products for gradients in same class: 569874.3189196007\n",
      "Sum of scalar products for gradients in different class: -520508.9526614058\n",
      "Loss: 0.0043167429976165295\n",
      "\n",
      "\n",
      "Iteration: 119\n",
      "Squared L2 Norm of Full Gradient: 47974.54142200295\n",
      "Sum of scalar products for gradients in same class: 555889.4739677547\n",
      "Sum of scalar products for gradients in different class: -507914.9325457518\n",
      "Loss: 0.0042622932232916355\n",
      "\n",
      "\n",
      "Iteration: 120\n",
      "Squared L2 Norm of Full Gradient: 46645.381219504634\n",
      "Sum of scalar products for gradients in same class: 542461.5264334017\n",
      "Sum of scalar products for gradients in different class: -495816.1452138971\n",
      "Loss: 0.004209357313811779\n",
      "\n",
      "\n",
      "Iteration: 121\n",
      "Squared L2 Norm of Full Gradient: 45374.25234927237\n",
      "Sum of scalar products for gradients in same class: 529563.1775205794\n",
      "Sum of scalar products for gradients in different class: -484188.92517130706\n",
      "Loss: 0.004157875198870897\n",
      "\n",
      "\n",
      "Iteration: 122\n",
      "Squared L2 Norm of Full Gradient: 44157.37002554373\n",
      "Sum of scalar products for gradients in same class: 517157.8752804916\n",
      "Sum of scalar products for gradients in different class: -473000.5052549479\n",
      "Loss: 0.0041077956557273865\n",
      "\n",
      "\n",
      "Iteration: 123\n",
      "Squared L2 Norm of Full Gradient: 42991.930548213655\n",
      "Sum of scalar products for gradients in same class: 505226.036915008\n",
      "Sum of scalar products for gradients in different class: -462234.1063667943\n",
      "Loss: 0.0040590777061879635\n",
      "\n",
      "\n",
      "Iteration: 124\n",
      "Squared L2 Norm of Full Gradient: 41874.70035989676\n",
      "Sum of scalar products for gradients in same class: 493739.7338161017\n",
      "Sum of scalar products for gradients in different class: -451865.0334562049\n",
      "Loss: 0.004011605400592089\n",
      "\n",
      "\n",
      "Iteration: 125\n",
      "Squared L2 Norm of Full Gradient: 40802.90888180607\n",
      "Sum of scalar products for gradients in same class: 482674.8626833498\n",
      "Sum of scalar products for gradients in different class: -441871.95380154374\n",
      "Loss: 0.003965387120842934\n",
      "\n",
      "\n",
      "Iteration: 126\n",
      "Squared L2 Norm of Full Gradient: 39774.263474757085\n",
      "Sum of scalar products for gradients in same class: 472012.4178983609\n",
      "Sum of scalar products for gradients in different class: -432238.1544236038\n",
      "Loss: 0.003920326475054026\n",
      "\n",
      "\n",
      "Iteration: 127\n",
      "Squared L2 Norm of Full Gradient: 38786.440382693196\n",
      "Sum of scalar products for gradients in same class: 461731.37151087564\n",
      "Sum of scalar products for gradients in different class: -422944.93112818245\n",
      "Loss: 0.003876421833410859\n",
      "\n",
      "\n",
      "Iteration: 128\n",
      "Squared L2 Norm of Full Gradient: 37836.91011366341\n",
      "Sum of scalar products for gradients in same class: 451811.58681307925\n",
      "Sum of scalar products for gradients in different class: -413974.67669941584\n",
      "Loss: 0.0038335940334945917\n",
      "\n",
      "\n",
      "Iteration: 129\n",
      "Squared L2 Norm of Full Gradient: 36923.83676171303\n",
      "Sum of scalar products for gradients in same class: 442234.995130454\n",
      "Sum of scalar products for gradients in different class: -405311.158368741\n",
      "Loss: 0.003791805589571595\n",
      "\n",
      "\n",
      "Iteration: 130\n",
      "Squared L2 Norm of Full Gradient: 36045.32497787126\n",
      "Sum of scalar products for gradients in same class: 432987.0907164836\n",
      "Sum of scalar products for gradients in different class: -396941.76573861233\n",
      "Loss: 0.003751032054424286\n",
      "\n",
      "\n",
      "Iteration: 131\n",
      "Squared L2 Norm of Full Gradient: 35199.42463954189\n",
      "Sum of scalar products for gradients in same class: 424050.1965494322\n",
      "Sum of scalar products for gradients in different class: -388850.7719098903\n",
      "Loss: 0.0037112152203917503\n",
      "\n",
      "\n",
      "Iteration: 132\n",
      "Squared L2 Norm of Full Gradient: 34384.87070918456\n",
      "Sum of scalar products for gradients in same class: 415413.2945060642\n",
      "Sum of scalar products for gradients in different class: -381028.42379687965\n",
      "Loss: 0.0036723280791193247\n",
      "\n",
      "\n",
      "Iteration: 133\n",
      "Squared L2 Norm of Full Gradient: 33599.52882322692\n",
      "Sum of scalar products for gradients in same class: 407056.2275737669\n",
      "Sum of scalar products for gradients in different class: -373456.69875054\n",
      "Loss: 0.0036343492101877928\n",
      "\n",
      "\n",
      "Iteration: 134\n",
      "Squared L2 Norm of Full Gradient: 32842.44753175974\n",
      "Sum of scalar products for gradients in same class: 398972.6865943284\n",
      "Sum of scalar products for gradients in different class: -366130.23906256864\n",
      "Loss: 0.0035972213372588158\n",
      "\n",
      "\n",
      "Iteration: 135\n",
      "Squared L2 Norm of Full Gradient: 32111.96625353396\n",
      "Sum of scalar products for gradients in same class: 391146.76345237787\n",
      "Sum of scalar products for gradients in different class: -359034.7971988439\n",
      "Loss: 0.0035609446931630373\n",
      "\n",
      "\n",
      "Iteration: 136\n",
      "Squared L2 Norm of Full Gradient: 31406.69627511152\n",
      "Sum of scalar products for gradients in same class: 383565.4132625663\n",
      "Sum of scalar products for gradients in different class: -352158.7169874548\n",
      "Loss: 0.0035254533868283033\n",
      "\n",
      "\n",
      "Iteration: 137\n",
      "Squared L2 Norm of Full Gradient: 30725.76328951493\n",
      "Sum of scalar products for gradients in same class: 376222.4938812871\n",
      "Sum of scalar products for gradients in different class: -345496.7305917722\n",
      "Loss: 0.00349075673148036\n",
      "\n",
      "\n",
      "Iteration: 138\n",
      "Squared L2 Norm of Full Gradient: 30067.864805459976\n",
      "Sum of scalar products for gradients in same class: 369105.3033194901\n",
      "Sum of scalar products for gradients in different class: -339037.43851403013\n",
      "Loss: 0.0034567872062325478\n",
      "\n",
      "\n",
      "Iteration: 139\n",
      "Squared L2 Norm of Full Gradient: 29432.04742819909\n",
      "Sum of scalar products for gradients in same class: 362204.7868538588\n",
      "Sum of scalar products for gradients in different class: -332772.7394256597\n",
      "Loss: 0.003423569491133094\n",
      "\n",
      "\n",
      "Iteration: 140\n",
      "Squared L2 Norm of Full Gradient: 28817.186486282386\n",
      "Sum of scalar products for gradients in same class: 355511.5797828397\n",
      "Sum of scalar products for gradients in different class: -326694.3932965573\n",
      "Loss: 0.003391026286408305\n",
      "\n",
      "\n",
      "Iteration: 141\n",
      "Squared L2 Norm of Full Gradient: 28222.374779256294\n",
      "Sum of scalar products for gradients in same class: 349017.1878460228\n",
      "Sum of scalar products for gradients in different class: -320794.8130667665\n",
      "Loss: 0.0033591818064451218\n",
      "\n",
      "\n",
      "Iteration: 142\n",
      "Squared L2 Norm of Full Gradient: 27646.627676720032\n",
      "Sum of scalar products for gradients in same class: 342711.99661461293\n",
      "Sum of scalar products for gradients in different class: -315065.3689378929\n",
      "Loss: 0.0033279911149293184\n",
      "\n",
      "\n",
      "Iteration: 143\n",
      "Squared L2 Norm of Full Gradient: 27089.269174123416\n",
      "Sum of scalar products for gradients in same class: 336590.75048664\n",
      "Sum of scalar products for gradients in different class: -309501.4813125166\n",
      "Loss: 0.003297419287264347\n",
      "\n",
      "\n",
      "Iteration: 144\n",
      "Squared L2 Norm of Full Gradient: 26549.523956213146\n",
      "Sum of scalar products for gradients in same class: 330645.6402982179\n",
      "Sum of scalar products for gradients in different class: -304096.11634200474\n",
      "Loss: 0.0032674705144017935\n",
      "\n",
      "\n",
      "Iteration: 145\n",
      "Squared L2 Norm of Full Gradient: 26026.42912972346\n",
      "Sum of scalar products for gradients in same class: 324867.85920215165\n",
      "Sum of scalar products for gradients in different class: -298841.4300724282\n",
      "Loss: 0.0032381026539951563\n",
      "\n",
      "\n",
      "Iteration: 146\n",
      "Squared L2 Norm of Full Gradient: 25519.38485404686\n",
      "Sum of scalar products for gradients in same class: 319251.7566598944\n",
      "Sum of scalar products for gradients in different class: -293732.37180584756\n",
      "Loss: 0.003209342248737812\n",
      "\n",
      "\n",
      "Iteration: 147\n",
      "Squared L2 Norm of Full Gradient: 25027.76044826233\n",
      "Sum of scalar products for gradients in same class: 313791.03390574513\n",
      "Sum of scalar products for gradients in different class: -288763.2734574828\n",
      "Loss: 0.0031811317894607782\n",
      "\n",
      "\n",
      "Iteration: 148\n",
      "Squared L2 Norm of Full Gradient: 24550.977437973255\n",
      "Sum of scalar products for gradients in same class: 308481.6753891908\n",
      "Sum of scalar products for gradients in different class: -283930.69795121753\n",
      "Loss: 0.003153452416881919\n",
      "\n",
      "\n",
      "Iteration: 149\n",
      "Squared L2 Norm of Full Gradient: 24088.18525775359\n",
      "Sum of scalar products for gradients in same class: 303313.8635910522\n",
      "Sum of scalar products for gradients in different class: -279225.6783332986\n",
      "Loss: 0.0031263011042028666\n",
      "\n",
      "\n",
      "Iteration: 150\n",
      "Squared L2 Norm of Full Gradient: 23639.006195101887\n",
      "Sum of scalar products for gradients in same class: 298285.2050465682\n",
      "Sum of scalar products for gradients in different class: -274646.1988514663\n",
      "Loss: 0.003099659224972129\n",
      "\n",
      "\n",
      "Iteration: 151\n",
      "Squared L2 Norm of Full Gradient: 23202.867506576935\n",
      "Sum of scalar products for gradients in same class: 293389.3872614073\n",
      "Sum of scalar products for gradients in different class: -270186.51975483034\n",
      "Loss: 0.0030735228210687637\n",
      "\n",
      "\n",
      "Iteration: 152\n",
      "Squared L2 Norm of Full Gradient: 22779.22706308309\n",
      "Sum of scalar products for gradients in same class: 288622.6836242406\n",
      "Sum of scalar products for gradients in different class: -265843.45656115754\n",
      "Loss: 0.0030478492844849825\n",
      "\n",
      "\n",
      "Iteration: 153\n",
      "Squared L2 Norm of Full Gradient: 22367.731887001777\n",
      "Sum of scalar products for gradients in same class: 283981.0796889264\n",
      "Sum of scalar products for gradients in different class: -261613.34780192462\n",
      "Loss: 0.0030226607341319323\n",
      "\n",
      "\n",
      "Iteration: 154\n",
      "Squared L2 Norm of Full Gradient: 21967.75298693427\n",
      "Sum of scalar products for gradients in same class: 279458.2408403085\n",
      "Sum of scalar products for gradients in different class: -257490.48785337422\n",
      "Loss: 0.0029979206155985594\n",
      "\n",
      "\n",
      "Iteration: 155\n",
      "Squared L2 Norm of Full Gradient: 21578.881961707026\n",
      "Sum of scalar products for gradients in same class: 275050.59064544534\n",
      "Sum of scalar products for gradients in different class: -253471.7086837383\n",
      "Loss: 0.0029736212454736233\n",
      "\n",
      "\n",
      "Iteration: 156\n",
      "Squared L2 Norm of Full Gradient: 21200.68147567124\n",
      "Sum of scalar products for gradients in same class: 270753.62666407815\n",
      "Sum of scalar products for gradients in different class: -249552.9451884069\n",
      "Loss: 0.0029497486539185047\n",
      "\n",
      "\n",
      "Iteration: 157\n",
      "Squared L2 Norm of Full Gradient: 20832.80559186102\n",
      "Sum of scalar products for gradients in same class: 266563.57835812616\n",
      "Sum of scalar products for gradients in different class: -245730.77276626515\n",
      "Loss: 0.0029262995813041925\n",
      "\n",
      "\n",
      "Iteration: 158\n",
      "Squared L2 Norm of Full Gradient: 20474.834387273528\n",
      "Sum of scalar products for gradients in same class: 262477.29183436837\n",
      "Sum of scalar products for gradients in different class: -242002.45744709484\n",
      "Loss: 0.0029032437596470118\n",
      "\n",
      "\n",
      "Iteration: 159\n",
      "Squared L2 Norm of Full Gradient: 20126.437431573868\n",
      "Sum of scalar products for gradients in same class: 258491.35332441592\n",
      "Sum of scalar products for gradients in different class: -238364.91589284205\n",
      "Loss: 0.0028805930633097887\n",
      "\n",
      "\n",
      "Iteration: 160\n",
      "Squared L2 Norm of Full Gradient: 19787.27137619257\n",
      "Sum of scalar products for gradients in same class: 254602.2826327249\n",
      "Sum of scalar products for gradients in different class: -234815.01125653234\n",
      "Loss: 0.002858327003195882\n",
      "\n",
      "\n",
      "Iteration: 161\n",
      "Squared L2 Norm of Full Gradient: 19457.044458799297\n",
      "Sum of scalar products for gradients in same class: 250807.71885170264\n",
      "Sum of scalar products for gradients in different class: -231350.67439290334\n",
      "Loss: 0.0028364346362650394\n",
      "\n",
      "\n",
      "Iteration: 162\n",
      "Squared L2 Norm of Full Gradient: 19135.20629256987\n",
      "Sum of scalar products for gradients in same class: 247100.53272473614\n",
      "Sum of scalar products for gradients in different class: -227965.32643216627\n",
      "Loss: 0.0028149113059043884\n",
      "\n",
      "\n",
      "Iteration: 163\n",
      "Squared L2 Norm of Full Gradient: 18821.80851672683\n",
      "Sum of scalar products for gradients in same class: 243483.73183631297\n",
      "Sum of scalar products for gradients in different class: -224661.92331958615\n",
      "Loss: 0.002793725347146392\n",
      "\n",
      "\n",
      "Iteration: 164\n",
      "Squared L2 Norm of Full Gradient: 18516.226229682565\n",
      "Sum of scalar products for gradients in same class: 239949.1950844865\n",
      "Sum of scalar products for gradients in different class: -221432.96885480394\n",
      "Loss: 0.0027729026041924953\n",
      "\n",
      "\n",
      "Iteration: 165\n",
      "Squared L2 Norm of Full Gradient: 18218.437633078778\n",
      "Sum of scalar products for gradients in same class: 236497.73905738612\n",
      "Sum of scalar products for gradients in different class: -218279.30142430734\n",
      "Loss: 0.0027524144388735294\n",
      "\n",
      "\n",
      "Iteration: 166\n",
      "Squared L2 Norm of Full Gradient: 17928.06013257266\n",
      "Sum of scalar products for gradients in same class: 233124.62709522562\n",
      "Sum of scalar products for gradients in different class: -215196.56696265296\n",
      "Loss: 0.0027322557289153337\n",
      "\n",
      "\n",
      "Iteration: 167\n",
      "Squared L2 Norm of Full Gradient: 17644.887673801044\n",
      "Sum of scalar products for gradients in same class: 229828.80601837725\n",
      "Sum of scalar products for gradients in different class: -212183.9183445762\n",
      "Loss: 0.002712412504479289\n",
      "\n",
      "\n",
      "Iteration: 168\n",
      "Squared L2 Norm of Full Gradient: 17368.638527580537\n",
      "Sum of scalar products for gradients in same class: 226607.07981387794\n",
      "Sum of scalar products for gradients in different class: -209238.4412862974\n",
      "Loss: 0.0026928773149847984\n",
      "\n",
      "\n",
      "Iteration: 169\n",
      "Squared L2 Norm of Full Gradient: 17099.0660516778\n",
      "Sum of scalar products for gradients in same class: 223457.0490971004\n",
      "Sum of scalar products for gradients in different class: -206357.9830454226\n",
      "Loss: 0.0026736618019640446\n",
      "\n",
      "\n",
      "Iteration: 170\n",
      "Squared L2 Norm of Full Gradient: 16836.10786534846\n",
      "Sum of scalar products for gradients in same class: 220378.46188081423\n",
      "Sum of scalar products for gradients in different class: -203542.35401546577\n",
      "Loss: 0.002654734533280134\n",
      "\n",
      "\n",
      "Iteration: 171\n",
      "Squared L2 Norm of Full Gradient: 16579.25406890572\n",
      "Sum of scalar products for gradients in same class: 217364.55266382603\n",
      "Sum of scalar products for gradients in different class: -200785.2985949203\n",
      "Loss: 0.002636098535731435\n",
      "\n",
      "\n",
      "Iteration: 172\n",
      "Squared L2 Norm of Full Gradient: 16328.570398696698\n",
      "Sum of scalar products for gradients in same class: 214418.35695438663\n",
      "Sum of scalar products for gradients in different class: -198089.78655568993\n",
      "Loss: 0.002617737278342247\n",
      "\n",
      "\n",
      "Iteration: 173\n",
      "Squared L2 Norm of Full Gradient: 16083.697413705522\n",
      "Sum of scalar products for gradients in same class: 211534.6326079163\n",
      "Sum of scalar products for gradients in different class: -195450.9351942108\n",
      "Loss: 0.0025996726471930742\n",
      "\n",
      "\n",
      "Iteration: 174\n",
      "Squared L2 Norm of Full Gradient: 15844.588611686835\n",
      "Sum of scalar products for gradients in same class: 208713.42906036729\n",
      "Sum of scalar products for gradients in different class: -192868.84044868045\n",
      "Loss: 0.0025818718131631613\n",
      "\n",
      "\n",
      "Iteration: 175\n",
      "Squared L2 Norm of Full Gradient: 15611.024168450444\n",
      "Sum of scalar products for gradients in same class: 205952.56481721502\n",
      "Sum of scalar products for gradients in different class: -190341.54064876458\n",
      "Loss: 0.0025643238332122564\n",
      "\n",
      "\n",
      "Iteration: 176\n",
      "Squared L2 Norm of Full Gradient: 15382.677909967548\n",
      "Sum of scalar products for gradients in same class: 203248.09435769578\n",
      "Sum of scalar products for gradients in different class: -187865.41644772823\n",
      "Loss: 0.0025470475666224957\n",
      "\n",
      "\n",
      "Iteration: 177\n",
      "Squared L2 Norm of Full Gradient: 15159.607811384834\n",
      "Sum of scalar products for gradients in same class: 200602.00376917038\n",
      "Sum of scalar products for gradients in different class: -185442.39595778554\n",
      "Loss: 0.002530014608055353\n",
      "\n",
      "\n",
      "Iteration: 178\n",
      "Squared L2 Norm of Full Gradient: 14941.538991730718\n",
      "Sum of scalar products for gradients in same class: 198010.702338841\n",
      "Sum of scalar products for gradients in different class: -183069.16334711027\n",
      "Loss: 0.002513232873752713\n",
      "\n",
      "\n",
      "Iteration: 179\n",
      "Squared L2 Norm of Full Gradient: 14728.331227749819\n",
      "Sum of scalar products for gradients in same class: 195471.88418587972\n",
      "Sum of scalar products for gradients in different class: -180743.5529581299\n",
      "Loss: 0.002496694913133979\n",
      "\n",
      "\n",
      "Iteration: 180\n",
      "Squared L2 Norm of Full Gradient: 14519.777462035476\n",
      "Sum of scalar products for gradients in same class: 192984.24530965212\n",
      "Sum of scalar products for gradients in different class: -178464.46784761664\n",
      "Loss: 0.0024803830310702324\n",
      "\n",
      "\n",
      "Iteration: 181\n",
      "Squared L2 Norm of Full Gradient: 14315.792412791401\n",
      "Sum of scalar products for gradients in same class: 190546.72589104174\n",
      "Sum of scalar products for gradients in different class: -176230.93347825034\n",
      "Loss: 0.0024643063079565763\n",
      "\n",
      "\n",
      "Iteration: 182\n",
      "Squared L2 Norm of Full Gradient: 14116.386588106456\n",
      "Sum of scalar products for gradients in same class: 188160.8153714112\n",
      "Sum of scalar products for gradients in different class: -174044.42878330476\n",
      "Loss: 0.002448457293212414\n",
      "\n",
      "\n",
      "Iteration: 183\n",
      "Squared L2 Norm of Full Gradient: 13921.157097030024\n",
      "Sum of scalar products for gradients in same class: 185819.98103622627\n",
      "Sum of scalar products for gradients in different class: -171898.82393919624\n",
      "Loss: 0.0024328280705958605\n",
      "\n",
      "\n",
      "Iteration: 184\n",
      "Squared L2 Norm of Full Gradient: 13730.219138380198\n",
      "Sum of scalar products for gradients in same class: 183526.7510912252\n",
      "Sum of scalar products for gradients in different class: -169796.531952845\n",
      "Loss: 0.0024174137506633997\n",
      "\n",
      "\n",
      "Iteration: 185\n",
      "Squared L2 Norm of Full Gradient: 13543.176139854826\n",
      "Sum of scalar products for gradients in same class: 181276.98426970677\n",
      "Sum of scalar products for gradients in different class: -167733.80812985194\n",
      "Loss: 0.0024022101424634457\n",
      "\n",
      "\n",
      "Iteration: 186\n",
      "Squared L2 Norm of Full Gradient: 13360.211242633173\n",
      "Sum of scalar products for gradients in same class: 179072.4516819017\n",
      "Sum of scalar products for gradients in different class: -165712.24043926853\n",
      "Loss: 0.0023872111923992634\n",
      "\n",
      "\n",
      "Iteration: 187\n",
      "Squared L2 Norm of Full Gradient: 13181.021958054567\n",
      "Sum of scalar products for gradients in same class: 176910.27971271746\n",
      "Sum of scalar products for gradients in different class: -163729.2577546629\n",
      "Loss: 0.002372414106503129\n",
      "\n",
      "\n",
      "Iteration: 188\n",
      "Squared L2 Norm of Full Gradient: 13005.532478562614\n",
      "Sum of scalar products for gradients in same class: 174788.97985295573\n",
      "Sum of scalar products for gradients in different class: -161783.44737439312\n",
      "Loss: 0.0023578209802508354\n",
      "\n",
      "\n",
      "Iteration: 189\n",
      "Squared L2 Norm of Full Gradient: 12833.76690231968\n",
      "Sum of scalar products for gradients in same class: 172709.3274262718\n",
      "Sum of scalar products for gradients in different class: -159875.56052395212\n",
      "Loss: 0.0023434225004166365\n",
      "\n",
      "\n",
      "Iteration: 190\n",
      "Squared L2 Norm of Full Gradient: 12665.38918437023\n",
      "Sum of scalar products for gradients in same class: 170667.21336709132\n",
      "Sum of scalar products for gradients in different class: -158001.8241827211\n",
      "Loss: 0.002329206094145775\n",
      "\n",
      "\n",
      "Iteration: 191\n",
      "Squared L2 Norm of Full Gradient: 12500.542342882196\n",
      "Sum of scalar products for gradients in same class: 168665.82202287368\n",
      "Sum of scalar products for gradients in different class: -156165.27967999148\n",
      "Loss: 0.0023151813074946404\n",
      "\n",
      "\n",
      "Iteration: 192\n",
      "Squared L2 Norm of Full Gradient: 12338.921047383978\n",
      "Sum of scalar products for gradients in same class: 166699.30051060632\n",
      "Sum of scalar products for gradients in different class: -154360.37946322234\n",
      "Loss: 0.0023013402242213488\n",
      "\n",
      "\n",
      "Iteration: 193\n",
      "Squared L2 Norm of Full Gradient: 12180.59610553109\n",
      "Sum of scalar products for gradients in same class: 164770.65669780242\n",
      "Sum of scalar products for gradients in different class: -152590.06059227133\n",
      "Loss: 0.0022876677103340626\n",
      "\n",
      "\n",
      "Iteration: 194\n",
      "Squared L2 Norm of Full Gradient: 12025.401740547328\n",
      "Sum of scalar products for gradients in same class: 162877.0733432775\n",
      "Sum of scalar products for gradients in different class: -150851.67160273017\n",
      "Loss: 0.0022741814609616995\n",
      "\n",
      "\n",
      "Iteration: 195\n",
      "Squared L2 Norm of Full Gradient: 11873.219124074152\n",
      "Sum of scalar products for gradients in same class: 161017.36803885724\n",
      "Sum of scalar products for gradients in different class: -149144.1489147831\n",
      "Loss: 0.0022608607541769743\n",
      "\n",
      "\n",
      "Iteration: 196\n",
      "Squared L2 Norm of Full Gradient: 11724.075691882521\n",
      "Sum of scalar products for gradients in same class: 159191.86953529099\n",
      "Sum of scalar products for gradients in different class: -147467.79384340846\n",
      "Loss: 0.0022477114107459784\n",
      "\n",
      "\n",
      "Iteration: 197\n",
      "Squared L2 Norm of Full Gradient: 11577.799075960706\n",
      "Sum of scalar products for gradients in same class: 157399.1472751405\n",
      "Sum of scalar products for gradients in different class: -145821.3481991798\n",
      "Loss: 0.002234719693660736\n",
      "\n",
      "\n",
      "Iteration: 198\n",
      "Squared L2 Norm of Full Gradient: 11434.365976872155\n",
      "Sum of scalar products for gradients in same class: 155638.21008123778\n",
      "Sum of scalar products for gradients in different class: -144203.84410436562\n",
      "Loss: 0.002221898641437292\n",
      "\n",
      "\n",
      "Iteration: 199\n",
      "Squared L2 Norm of Full Gradient: 11293.660822772421\n",
      "Sum of scalar products for gradients in same class: 153908.57380106061\n",
      "Sum of scalar products for gradients in different class: -142614.9129782882\n",
      "Loss: 0.002209232421591878\n",
      "\n",
      "\n",
      "Iteration: 200\n",
      "Squared L2 Norm of Full Gradient: 11155.676843477646\n",
      "Sum of scalar products for gradients in same class: 152210.2186449003\n",
      "Sum of scalar products for gradients in different class: -141054.54180142266\n",
      "Loss: 0.0021967238280922174\n",
      "\n",
      "\n",
      "Iteration: 201\n",
      "Squared L2 Norm of Full Gradient: 11020.285309448896\n",
      "Sum of scalar products for gradients in same class: 150541.20205427974\n",
      "Sum of scalar products for gradients in different class: -139520.91674483084\n",
      "Loss: 0.002184367273002863\n",
      "\n",
      "\n",
      "Iteration: 202\n",
      "Squared L2 Norm of Full Gradient: 10887.420737207867\n",
      "Sum of scalar products for gradients in same class: 148900.93458488444\n",
      "Sum of scalar products for gradients in different class: -138013.51384767657\n",
      "Loss: 0.0021721685770899057\n",
      "\n",
      "\n",
      "Iteration: 203\n",
      "Squared L2 Norm of Full Gradient: 10757.05209471524\n",
      "Sum of scalar products for gradients in same class: 147289.19364281918\n",
      "Sum of scalar products for gradients in different class: -136532.14154810394\n",
      "Loss: 0.002160100033506751\n",
      "\n",
      "\n",
      "Iteration: 204\n",
      "Squared L2 Norm of Full Gradient: 10629.082676217891\n",
      "Sum of scalar products for gradients in same class: 145705.28449882806\n",
      "Sum of scalar products for gradients in different class: -135076.20182261016\n",
      "Loss: 0.0021481760777533054\n",
      "\n",
      "\n",
      "Iteration: 205\n",
      "Squared L2 Norm of Full Gradient: 10503.449016362487\n",
      "Sum of scalar products for gradients in same class: 144147.7042959648\n",
      "Sum of scalar products for gradients in different class: -133644.2552796023\n",
      "Loss: 0.002136409282684326\n",
      "\n",
      "\n",
      "Iteration: 206\n",
      "Squared L2 Norm of Full Gradient: 10380.147902766475\n",
      "Sum of scalar products for gradients in same class: 142617.15602938685\n",
      "Sum of scalar products for gradients in different class: -132237.00812662038\n",
      "Loss: 0.002124774968251586\n",
      "\n",
      "\n",
      "Iteration: 207\n",
      "Squared L2 Norm of Full Gradient: 10259.064615880197\n",
      "Sum of scalar products for gradients in same class: 141111.92048280622\n",
      "Sum of scalar products for gradients in different class: -130852.85586692602\n",
      "Loss: 0.00211326708085835\n",
      "\n",
      "\n",
      "Iteration: 208\n",
      "Squared L2 Norm of Full Gradient: 10140.180539165216\n",
      "Sum of scalar products for gradients in same class: 139632.21564372\n",
      "Sum of scalar products for gradients in different class: -129492.03510455479\n",
      "Loss: 0.0021019084379076958\n",
      "\n",
      "\n",
      "Iteration: 209\n",
      "Squared L2 Norm of Full Gradient: 10023.45276057726\n",
      "Sum of scalar products for gradients in same class: 138177.1582072404\n",
      "Sum of scalar products for gradients in different class: -128153.70544666314\n",
      "Loss: 0.0020906671416014433\n",
      "\n",
      "\n",
      "Iteration: 210\n",
      "Squared L2 Norm of Full Gradient: 9908.766173873097\n",
      "Sum of scalar products for gradients in same class: 136745.8111908576\n",
      "Sum of scalar products for gradients in different class: -126837.04501698451\n",
      "Loss: 0.002079561585560441\n",
      "\n",
      "\n",
      "Iteration: 211\n",
      "Squared L2 Norm of Full Gradient: 9796.110732590372\n",
      "Sum of scalar products for gradients in same class: 135337.96288948483\n",
      "Sum of scalar products for gradients in different class: -125541.85215689446\n",
      "Loss: 0.0020685840863734484\n",
      "\n",
      "\n",
      "Iteration: 212\n",
      "Squared L2 Norm of Full Gradient: 9685.408788612345\n",
      "Sum of scalar products for gradients in same class: 133952.993013546\n",
      "Sum of scalar products for gradients in different class: -124267.58422493364\n",
      "Loss: 0.0020577346440404654\n",
      "\n",
      "\n",
      "Iteration: 213\n",
      "Squared L2 Norm of Full Gradient: 9576.687231967459\n",
      "Sum of scalar products for gradients in same class: 132590.5187432167\n",
      "Sum of scalar products for gradients in different class: -123013.83151124924\n",
      "Loss: 0.0020470009185373783\n",
      "\n",
      "\n",
      "Iteration: 214\n",
      "Squared L2 Norm of Full Gradient: 9469.847385817207\n",
      "Sum of scalar products for gradients in same class: 131250.2782991373\n",
      "Sum of scalar products for gradients in different class: -121780.4309133201\n",
      "Loss: 0.0020363880321383476\n",
      "\n",
      "\n",
      "Iteration: 215\n",
      "Squared L2 Norm of Full Gradient: 9364.832411267795\n",
      "Sum of scalar products for gradients in same class: 129931.38504787257\n",
      "Sum of scalar products for gradients in different class: -120566.55263660477\n",
      "Loss: 0.0020258999429643154\n",
      "\n",
      "\n",
      "Iteration: 216\n",
      "Squared L2 Norm of Full Gradient: 9261.633498167852\n",
      "Sum of scalar products for gradients in same class: 128633.39263881923\n",
      "Sum of scalar products for gradients in different class: -119371.75914065138\n",
      "Loss: 0.0020155184902250767\n",
      "\n",
      "\n",
      "Iteration: 217\n",
      "Squared L2 Norm of Full Gradient: 9160.184863256349\n",
      "Sum of scalar products for gradients in same class: 127355.83791453467\n",
      "Sum of scalar products for gradients in different class: -118195.65305127832\n",
      "Loss: 0.00200526206754148\n",
      "\n",
      "\n",
      "Iteration: 218\n",
      "Squared L2 Norm of Full Gradient: 9060.4626246728\n",
      "Sum of scalar products for gradients in same class: 126098.16570374882\n",
      "Sum of scalar products for gradients in different class: -117037.70307907602\n",
      "Loss: 0.001995110185816884\n",
      "\n",
      "\n",
      "Iteration: 219\n",
      "Squared L2 Norm of Full Gradient: 8962.411442407407\n",
      "Sum of scalar products for gradients in same class: 124860.39518972085\n",
      "Sum of scalar products for gradients in different class: -115897.98374731344\n",
      "Loss: 0.0019850684329867363\n",
      "\n",
      "\n",
      "Iteration: 220\n",
      "Squared L2 Norm of Full Gradient: 8866.02439408243\n",
      "Sum of scalar products for gradients in same class: 123642.41018575961\n",
      "Sum of scalar products for gradients in different class: -114776.38579167718\n",
      "Loss: 0.0019751358777284622\n",
      "\n",
      "\n",
      "Iteration: 221\n",
      "Squared L2 Norm of Full Gradient: 8771.217353604792\n",
      "Sum of scalar products for gradients in same class: 122442.48636033469\n",
      "Sum of scalar products for gradients in different class: -113671.2690067299\n",
      "Loss: 0.0019653120543807745\n",
      "\n",
      "\n",
      "Iteration: 222\n",
      "Squared L2 Norm of Full Gradient: 8677.981726965168\n",
      "Sum of scalar products for gradients in same class: 121261.49790182867\n",
      "Sum of scalar products for gradients in different class: -112583.5161748635\n",
      "Loss: 0.001955590210855007\n",
      "\n",
      "\n",
      "Iteration: 223\n",
      "Squared L2 Norm of Full Gradient: 8586.253788624948\n",
      "Sum of scalar products for gradients in same class: 120097.59647081223\n",
      "Sum of scalar products for gradients in different class: -111511.34268218729\n",
      "Loss: 0.0019459775649011135\n",
      "\n",
      "\n",
      "Iteration: 224\n",
      "Squared L2 Norm of Full Gradient: 8496.045533387223\n",
      "Sum of scalar products for gradients in same class: 118951.9648416249\n",
      "Sum of scalar products for gradients in different class: -110455.91930823767\n",
      "Loss: 0.001936462358571589\n",
      "\n",
      "\n",
      "Iteration: 225\n",
      "Squared L2 Norm of Full Gradient: 8407.326572005695\n",
      "Sum of scalar products for gradients in same class: 117823.7621580742\n",
      "Sum of scalar products for gradients in different class: -109416.4355860685\n",
      "Loss: 0.0019270457560196519\n",
      "\n",
      "\n",
      "Iteration: 226\n",
      "Squared L2 Norm of Full Gradient: 8320.025239918381\n",
      "Sum of scalar products for gradients in same class: 116712.40557452146\n",
      "Sum of scalar products for gradients in different class: -108392.38033460308\n",
      "Loss: 0.0019177263602614403\n",
      "\n",
      "\n",
      "Iteration: 227\n",
      "Squared L2 Norm of Full Gradient: 8234.10720769834\n",
      "Sum of scalar products for gradients in same class: 115617.66698574135\n",
      "Sum of scalar products for gradients in different class: -107383.55977804301\n",
      "Loss: 0.0019085058011114597\n",
      "\n",
      "\n",
      "Iteration: 228\n",
      "Squared L2 Norm of Full Gradient: 8149.571768036345\n",
      "Sum of scalar products for gradients in same class: 114539.06921014539\n",
      "Sum of scalar products for gradients in different class: -106389.49744210904\n",
      "Loss: 0.0018993911799043417\n",
      "\n",
      "\n",
      "Iteration: 229\n",
      "Squared L2 Norm of Full Gradient: 8066.387938826869\n",
      "Sum of scalar products for gradients in same class: 113476.41041771107\n",
      "Sum of scalar products for gradients in different class: -105410.0224788842\n",
      "Loss: 0.0018903494346886873\n",
      "\n",
      "\n",
      "Iteration: 230\n",
      "Squared L2 Norm of Full Gradient: 7984.474785802013\n",
      "Sum of scalar products for gradients in same class: 112428.74595968863\n",
      "Sum of scalar products for gradients in different class: -104444.27117388662\n",
      "Loss: 0.0018814110662788153\n",
      "\n",
      "\n",
      "Iteration: 231\n",
      "Squared L2 Norm of Full Gradient: 7903.899391559011\n",
      "Sum of scalar products for gradients in same class: 111397.3580695421\n",
      "Sum of scalar products for gradients in different class: -103493.45867798309\n",
      "Loss: 0.0018725653644651175\n",
      "\n",
      "\n",
      "Iteration: 232\n",
      "Squared L2 Norm of Full Gradient: 7824.5491960681975\n",
      "Sum of scalar products for gradients in same class: 110380.28341599776\n",
      "Sum of scalar products for gradients in different class: -102555.73421992957\n",
      "Loss: 0.0018638058099895716\n",
      "\n",
      "\n",
      "Iteration: 233\n",
      "Squared L2 Norm of Full Gradient: 7746.446726434166\n",
      "Sum of scalar products for gradients in same class: 109377.89001296497\n",
      "Sum of scalar products for gradients in different class: -101631.4432865308\n",
      "Loss: 0.0018551298417150974\n",
      "\n",
      "\n",
      "Iteration: 234\n",
      "Squared L2 Norm of Full Gradient: 7669.531091817713\n",
      "Sum of scalar products for gradients in same class: 108390.38495926134\n",
      "Sum of scalar products for gradients in different class: -100720.85386744363\n",
      "Loss: 0.001846545492298901\n",
      "\n",
      "\n",
      "Iteration: 235\n",
      "Squared L2 Norm of Full Gradient: 7593.798339427507\n",
      "Sum of scalar products for gradients in same class: 107416.14623999258\n",
      "Sum of scalar products for gradients in different class: -99822.34790056507\n",
      "Loss: 0.0018380421679466963\n",
      "\n",
      "\n",
      "Iteration: 236\n",
      "Squared L2 Norm of Full Gradient: 7519.28285427863\n",
      "Sum of scalar products for gradients in same class: 106456.74996464305\n",
      "Sum of scalar products for gradients in different class: -98937.46711036442\n",
      "Loss: 0.001829627901315689\n",
      "\n",
      "\n",
      "Iteration: 237\n",
      "Squared L2 Norm of Full Gradient: 7445.797040463425\n",
      "Sum of scalar products for gradients in same class: 105509.89771382883\n",
      "Sum of scalar products for gradients in different class: -98064.1006733654\n",
      "Loss: 0.0018212879076600075\n",
      "\n",
      "\n",
      "Iteration: 238\n",
      "Squared L2 Norm of Full Gradient: 7373.475244978676\n",
      "Sum of scalar products for gradients in same class: 104576.71801760478\n",
      "Sum of scalar products for gradients in different class: -97203.24277262611\n",
      "Loss: 0.0018130429089069366\n",
      "\n",
      "\n",
      "Iteration: 239\n",
      "Squared L2 Norm of Full Gradient: 7302.269170082232\n",
      "Sum of scalar products for gradients in same class: 103657.30852961379\n",
      "Sum of scalar products for gradients in different class: -96355.03935953155\n",
      "Loss: 0.0018048693891614676\n",
      "\n",
      "\n",
      "Iteration: 240\n",
      "Squared L2 Norm of Full Gradient: 7232.0405174517655\n",
      "Sum of scalar products for gradients in same class: 102748.89819802862\n",
      "Sum of scalar products for gradients in different class: -95516.85768057685\n",
      "Loss: 0.0017967710737138987\n",
      "\n",
      "\n",
      "Iteration: 241\n",
      "Squared L2 Norm of Full Gradient: 7162.9169934021775\n",
      "Sum of scalar products for gradients in same class: 101854.38933435222\n",
      "Sum of scalar products for gradients in different class: -94691.47234095004\n",
      "Loss: 0.001788754016160965\n",
      "\n",
      "\n",
      "Iteration: 242\n",
      "Squared L2 Norm of Full Gradient: 7094.7937151957885\n",
      "Sum of scalar products for gradients in same class: 100971.79532898108\n",
      "Sum of scalar products for gradients in different class: -93877.0016137853\n",
      "Loss: 0.0017808123957365751\n",
      "\n",
      "\n",
      "Iteration: 243\n",
      "Squared L2 Norm of Full Gradient: 7027.687942374556\n",
      "Sum of scalar products for gradients in same class: 100101.52851727752\n",
      "Sum of scalar products for gradients in different class: -93073.84057490296\n",
      "Loss: 0.0017729480750858784\n",
      "\n",
      "\n",
      "Iteration: 244\n",
      "Squared L2 Norm of Full Gradient: 6961.560504403955\n",
      "Sum of scalar products for gradients in same class: 99243.17521118827\n",
      "Sum of scalar products for gradients in different class: -92281.61470678431\n",
      "Loss: 0.0017651621019467711\n",
      "\n",
      "\n",
      "Iteration: 245\n",
      "Squared L2 Norm of Full Gradient: 6896.360210713232\n",
      "Sum of scalar products for gradients in same class: 98395.62513093516\n",
      "Sum of scalar products for gradients in different class: -91499.26492022193\n",
      "Loss: 0.0017574451630935073\n",
      "\n",
      "\n",
      "Iteration: 246\n",
      "Squared L2 Norm of Full Gradient: 6832.155301934166\n",
      "Sum of scalar products for gradients in same class: 97560.38336130779\n",
      "Sum of scalar products for gradients in different class: -90728.22805937362\n",
      "Loss: 0.0017498031957075\n",
      "\n",
      "\n",
      "Iteration: 247\n",
      "Squared L2 Norm of Full Gradient: 6768.839428536652\n",
      "Sum of scalar products for gradients in same class: 96735.80221589388\n",
      "Sum of scalar products for gradients in different class: -89966.96278735723\n",
      "Loss: 0.0017422238597646356\n",
      "\n",
      "\n",
      "Iteration: 248\n",
      "Squared L2 Norm of Full Gradient: 6706.451832834864\n",
      "Sum of scalar products for gradients in same class: 95922.606884308\n",
      "Sum of scalar products for gradients in different class: -89216.15505147314\n",
      "Loss: 0.0017347291577607393\n",
      "\n",
      "\n",
      "Iteration: 249\n",
      "Squared L2 Norm of Full Gradient: 6644.961305678822\n",
      "Sum of scalar products for gradients in same class: 95120.20583312168\n",
      "Sum of scalar products for gradients in different class: -88475.24452744286\n",
      "Loss: 0.0017272880068048835\n",
      "\n",
      "\n",
      "Iteration: 250\n",
      "Squared L2 Norm of Full Gradient: 6584.283896239707\n",
      "Sum of scalar products for gradients in same class: 94327.40864707764\n",
      "Sum of scalar products for gradients in different class: -87743.12475083793\n",
      "Loss: 0.0017199238063767552\n",
      "\n",
      "\n",
      "Iteration: 251\n",
      "Squared L2 Norm of Full Gradient: 6524.518292343477\n",
      "Sum of scalar products for gradients in same class: 93546.11519770908\n",
      "Sum of scalar products for gradients in different class: -87021.5969053656\n",
      "Loss: 0.0017126182792708278\n",
      "\n",
      "\n",
      "Iteration: 252\n",
      "Squared L2 Norm of Full Gradient: 6465.55642672634\n",
      "Sum of scalar products for gradients in same class: 92774.49936389978\n",
      "Sum of scalar products for gradients in different class: -86308.94293717344\n",
      "Loss: 0.0017053915653377771\n",
      "\n",
      "\n",
      "Iteration: 253\n",
      "Squared L2 Norm of Full Gradient: 6407.44356931746\n",
      "Sum of scalar products for gradients in same class: 92013.6072912258\n",
      "Sum of scalar products for gradients in different class: -85606.16372190833\n",
      "Loss: 0.0016982215456664562\n",
      "\n",
      "\n",
      "Iteration: 254\n",
      "Squared L2 Norm of Full Gradient: 6350.115895284398\n",
      "Sum of scalar products for gradients in same class: 91261.6157083333\n",
      "Sum of scalar products for gradients in different class: -84911.4998130489\n",
      "Loss: 0.001691117649897933\n",
      "\n",
      "\n",
      "Iteration: 255\n",
      "Squared L2 Norm of Full Gradient: 6293.601445055625\n",
      "Sum of scalar products for gradients in same class: 90520.07096969688\n",
      "Sum of scalar products for gradients in different class: -84226.46952464126\n",
      "Loss: 0.0016840827884152532\n",
      "\n",
      "\n",
      "Iteration: 256\n",
      "Squared L2 Norm of Full Gradient: 6237.842135400511\n",
      "Sum of scalar products for gradients in same class: 89787.37000932325\n",
      "Sum of scalar products for gradients in different class: -83549.52787392274\n",
      "Loss: 0.0016771008959040046\n",
      "\n",
      "\n",
      "Iteration: 257\n",
      "Squared L2 Norm of Full Gradient: 6182.8348424942815\n",
      "Sum of scalar products for gradients in same class: 89063.94380340978\n",
      "Sum of scalar products for gradients in different class: -82881.1089609155\n",
      "Loss: 0.0016701827989891171\n",
      "\n",
      "\n",
      "Iteration: 258\n",
      "Squared L2 Norm of Full Gradient: 6128.636166954006\n",
      "Sum of scalar products for gradients in same class: 88350.4470901984\n",
      "Sum of scalar products for gradients in different class: -82221.8109232444\n",
      "Loss: 0.0016633307095617056\n",
      "\n",
      "\n",
      "Iteration: 259\n",
      "Squared L2 Norm of Full Gradient: 6075.118508585787\n",
      "Sum of scalar products for gradients in same class: 87645.3533127844\n",
      "Sum of scalar products for gradients in different class: -81570.23480419861\n",
      "Loss: 0.0016565402038395405\n",
      "\n",
      "\n",
      "Iteration: 260\n",
      "Squared L2 Norm of Full Gradient: 6022.334056649357\n",
      "Sum of scalar products for gradients in same class: 86949.4507296425\n",
      "Sum of scalar products for gradients in different class: -80927.11667299314\n",
      "Loss: 0.0016498041804879904\n",
      "\n",
      "\n",
      "Iteration: 261\n",
      "Squared L2 Norm of Full Gradient: 5970.264481195249\n",
      "Sum of scalar products for gradients in same class: 86262.09038065137\n",
      "Sum of scalar products for gradients in different class: -80291.82589945612\n",
      "Loss: 0.0016431203112006187\n",
      "\n",
      "\n",
      "Iteration: 262\n",
      "Squared L2 Norm of Full Gradient: 5918.88232605072\n",
      "Sum of scalar products for gradients in same class: 85583.15556267282\n",
      "Sum of scalar products for gradients in different class: -79664.2732366221\n",
      "Loss: 0.0016365054761990905\n",
      "\n",
      "\n",
      "Iteration: 263\n",
      "Squared L2 Norm of Full Gradient: 5868.171076700324\n",
      "Sum of scalar products for gradients in same class: 84912.62121113397\n",
      "Sum of scalar products for gradients in different class: -79044.45013443365\n",
      "Loss: 0.0016299375565722585\n",
      "\n",
      "\n",
      "Iteration: 264\n",
      "Squared L2 Norm of Full Gradient: 5818.1493690647185\n",
      "Sum of scalar products for gradients in same class: 84250.33577031684\n",
      "Sum of scalar products for gradients in different class: -78432.18640125213\n",
      "Loss: 0.001623426447622478\n",
      "\n",
      "\n",
      "Iteration: 265\n",
      "Squared L2 Norm of Full Gradient: 5768.8192497754935\n",
      "Sum of scalar products for gradients in same class: 83596.76931743175\n",
      "Sum of scalar products for gradients in different class: -77827.95006765626\n",
      "Loss: 0.001616987749002874\n",
      "\n",
      "\n",
      "Iteration: 266\n",
      "Squared L2 Norm of Full Gradient: 5720.088053837011\n",
      "Sum of scalar products for gradients in same class: 82950.68815406681\n",
      "Sum of scalar products for gradients in different class: -77230.6001002298\n",
      "Loss: 0.0016105931717902422\n",
      "\n",
      "\n",
      "Iteration: 267\n",
      "Squared L2 Norm of Full Gradient: 5672.009429991245\n",
      "Sum of scalar products for gradients in same class: 82312.77755930412\n",
      "Sum of scalar products for gradients in different class: -76640.76812931287\n",
      "Loss: 0.0016042451607063413\n",
      "\n",
      "\n",
      "Iteration: 268\n",
      "Squared L2 Norm of Full Gradient: 5624.538812554034\n",
      "Sum of scalar products for gradients in same class: 81682.28073755803\n",
      "Sum of scalar products for gradients in different class: -76057.741925004\n",
      "Loss: 0.0015979554736986756\n",
      "\n",
      "\n",
      "Iteration: 269\n",
      "Squared L2 Norm of Full Gradient: 5577.690456687065\n",
      "Sum of scalar products for gradients in same class: 81059.25922392514\n",
      "Sum of scalar products for gradients in different class: -75481.56876723807\n",
      "Loss: 0.0015917145647108555\n",
      "\n",
      "\n",
      "Iteration: 270\n",
      "Squared L2 Norm of Full Gradient: 5531.44315895834\n",
      "Sum of scalar products for gradients in same class: 80443.91823243999\n",
      "Sum of scalar products for gradients in different class: -74912.47507348165\n",
      "Loss: 0.0015855352394282818\n",
      "\n",
      "\n",
      "Iteration: 271\n",
      "Squared L2 Norm of Full Gradient: 5485.808801378647\n",
      "Sum of scalar products for gradients in same class: 79836.17041295454\n",
      "Sum of scalar products for gradients in different class: -74350.36161157589\n",
      "Loss: 0.001579404342919588\n",
      "\n",
      "\n",
      "Iteration: 272\n",
      "Squared L2 Norm of Full Gradient: 5440.733751865628\n",
      "Sum of scalar products for gradients in same class: 79235.30449192491\n",
      "Sum of scalar products for gradients in different class: -73794.57074005928\n",
      "Loss: 0.0015733217587694526\n",
      "\n",
      "\n",
      "Iteration: 273\n",
      "Squared L2 Norm of Full Gradient: 5396.222385406494\n",
      "Sum of scalar products for gradients in same class: 78641.57284211136\n",
      "Sum of scalar products for gradients in different class: -73245.35045670487\n",
      "Loss: 0.001567286904901266\n",
      "\n",
      "\n",
      "Iteration: 274\n",
      "Squared L2 Norm of Full Gradient: 5352.270037830807\n",
      "Sum of scalar products for gradients in same class: 78054.58486929139\n",
      "Sum of scalar products for gradients in different class: -72702.31483146058\n",
      "Loss: 0.0015613059513270855\n",
      "\n",
      "\n",
      "Iteration: 275\n",
      "Squared L2 Norm of Full Gradient: 5308.9109972128645\n",
      "Sum of scalar products for gradients in same class: 77475.22897976081\n",
      "Sum of scalar products for gradients in different class: -72166.31798254795\n",
      "Loss: 0.0015553627163171768\n",
      "\n",
      "\n",
      "Iteration: 276\n",
      "Squared L2 Norm of Full Gradient: 5266.073769145645\n",
      "Sum of scalar products for gradients in same class: 76902.24818196314\n",
      "Sum of scalar products for gradients in different class: -71636.17441281749\n",
      "Loss: 0.0015494775725528598\n",
      "\n",
      "\n",
      "Iteration: 277\n",
      "Squared L2 Norm of Full Gradient: 5223.746426860394\n",
      "Sum of scalar products for gradients in same class: 76335.57334725936\n",
      "Sum of scalar products for gradients in different class: -71111.82692039896\n",
      "Loss: 0.001543637365102768\n",
      "\n",
      "\n",
      "Iteration: 278\n",
      "Squared L2 Norm of Full Gradient: 5181.951252264029\n",
      "Sum of scalar products for gradients in same class: 75775.5854722952\n",
      "Sum of scalar products for gradients in different class: -70593.63422003118\n",
      "Loss: 0.0015378448879346251\n",
      "\n",
      "\n",
      "Iteration: 279\n",
      "Squared L2 Norm of Full Gradient: 5140.686070137657\n",
      "Sum of scalar products for gradients in same class: 75222.36671728732\n",
      "Sum of scalar products for gradients in different class: -70081.68064714967\n",
      "Loss: 0.0015321027021855116\n",
      "\n",
      "\n",
      "Iteration: 280\n",
      "Squared L2 Norm of Full Gradient: 5099.918197039748\n",
      "Sum of scalar products for gradients in same class: 74675.11318884659\n",
      "Sum of scalar products for gradients in different class: -69575.19499180684\n",
      "Loss: 0.001526402891613543\n",
      "\n",
      "\n",
      "Iteration: 281\n",
      "Squared L2 Norm of Full Gradient: 5059.6631925046095\n",
      "Sum of scalar products for gradients in same class: 74134.43556406957\n",
      "Sum of scalar products for gradients in different class: -69074.77237156496\n",
      "Loss: 0.001520749181509018\n",
      "\n",
      "\n",
      "Iteration: 282\n",
      "Squared L2 Norm of Full Gradient: 5019.920124320546\n",
      "Sum of scalar products for gradients in same class: 73600.1608278782\n",
      "Sum of scalar products for gradients in different class: -68580.24070355765\n",
      "Loss: 0.0015151358675211668\n",
      "\n",
      "\n",
      "Iteration: 283\n",
      "Squared L2 Norm of Full Gradient: 4980.634202376008\n",
      "Sum of scalar products for gradients in same class: 73071.77485234916\n",
      "Sum of scalar products for gradients in different class: -68091.14064997315\n",
      "Loss: 0.0015095701673999429\n",
      "\n",
      "\n",
      "Iteration: 284\n",
      "Squared L2 Norm of Full Gradient: 4941.787934303284\n",
      "Sum of scalar products for gradients in same class: 72548.74726844953\n",
      "Sum of scalar products for gradients in different class: -67606.95933414625\n",
      "Loss: 0.0015040399739518762\n",
      "\n",
      "\n",
      "Iteration: 285\n",
      "Squared L2 Norm of Full Gradient: 4903.453824956028\n",
      "Sum of scalar products for gradients in same class: 72032.07696323372\n",
      "Sum of scalar products for gradients in different class: -67128.62313827769\n",
      "Loss: 0.001498567289672792\n",
      "\n",
      "\n",
      "Iteration: 286\n",
      "Squared L2 Norm of Full Gradient: 4865.581892523915\n",
      "Sum of scalar products for gradients in same class: 71521.63525371342\n",
      "Sum of scalar products for gradients in different class: -66656.05336118951\n",
      "Loss: 0.001493129413574934\n",
      "\n",
      "\n",
      "Iteration: 287\n",
      "Squared L2 Norm of Full Gradient: 4828.120779130608\n",
      "Sum of scalar products for gradients in same class: 71015.94457471164\n",
      "Sum of scalar products for gradients in different class: -66187.82379558103\n",
      "Loss: 0.0014877349603921175\n",
      "\n",
      "\n",
      "Iteration: 288\n",
      "Squared L2 Norm of Full Gradient: 4791.157193502644\n",
      "Sum of scalar products for gradients in same class: 70516.58128483596\n",
      "Sum of scalar products for gradients in different class: -65725.42409133332\n",
      "Loss: 0.0014823834644630551\n",
      "\n",
      "\n",
      "Iteration: 289\n",
      "Squared L2 Norm of Full Gradient: 4754.578689444403\n",
      "Sum of scalar products for gradients in same class: 70021.98697809337\n",
      "Sum of scalar products for gradients in different class: -65267.40828864896\n",
      "Loss: 0.001477065379731357\n",
      "\n",
      "\n",
      "Iteration: 290\n",
      "Squared L2 Norm of Full Gradient: 4718.441163249372\n",
      "Sum of scalar products for gradients in same class: 69533.11124835149\n",
      "Sum of scalar products for gradients in different class: -64814.670085102116\n",
      "Loss: 0.0014717894373461604\n",
      "\n",
      "\n",
      "Iteration: 291\n",
      "Squared L2 Norm of Full Gradient: 4682.752651528048\n",
      "Sum of scalar products for gradients in same class: 69049.95006805913\n",
      "Sum of scalar products for gradients in different class: -64367.19741653108\n",
      "Loss: 0.0014665526105090976\n",
      "\n",
      "\n",
      "Iteration: 292\n",
      "Squared L2 Norm of Full Gradient: 4647.497121079883\n",
      "Sum of scalar products for gradients in same class: 68572.45167890206\n",
      "Sum of scalar products for gradients in different class: -63924.95455782217\n",
      "Loss: 0.0014613661915063858\n",
      "\n",
      "\n",
      "Iteration: 293\n",
      "Squared L2 Norm of Full Gradient: 4612.6017594486475\n",
      "Sum of scalar products for gradients in same class: 68099.11306537471\n",
      "Sum of scalar products for gradients in different class: -63486.51130592606\n",
      "Loss: 0.0014562072465196252\n",
      "\n",
      "\n",
      "Iteration: 294\n",
      "Squared L2 Norm of Full Gradient: 4578.151753102487\n",
      "Sum of scalar products for gradients in same class: 67631.68649736249\n",
      "Sum of scalar products for gradients in different class: -63053.53474426\n",
      "Loss: 0.0014510919572785497\n",
      "\n",
      "\n",
      "Iteration: 295\n",
      "Squared L2 Norm of Full Gradient: 4544.059221298434\n",
      "Sum of scalar products for gradients in same class: 67168.57174388484\n",
      "Sum of scalar products for gradients in different class: -62624.5125225864\n",
      "Loss: 0.0014460200909525156\n",
      "\n",
      "\n",
      "Iteration: 296\n",
      "Squared L2 Norm of Full Gradient: 4510.393332784588\n",
      "Sum of scalar products for gradients in same class: 66710.98842086887\n",
      "Sum of scalar products for gradients in different class: -62200.59508808429\n",
      "Loss: 0.0014409812865778804\n",
      "\n",
      "\n",
      "Iteration: 297\n",
      "Squared L2 Norm of Full Gradient: 4477.084379522188\n",
      "Sum of scalar products for gradients in same class: 66257.96095330923\n",
      "Sum of scalar products for gradients in different class: -61780.87657378704\n",
      "Loss: 0.0014359750784933567\n",
      "\n",
      "\n",
      "Iteration: 298\n",
      "Squared L2 Norm of Full Gradient: 4444.193864751665\n",
      "Sum of scalar products for gradients in same class: 65810.36473380096\n",
      "Sum of scalar products for gradients in different class: -61366.170869049296\n",
      "Loss: 0.0014310134574770927\n",
      "\n",
      "\n",
      "Iteration: 299\n",
      "Squared L2 Norm of Full Gradient: 4411.642507509328\n",
      "Sum of scalar products for gradients in same class: 65366.82020533373\n",
      "Sum of scalar products for gradients in different class: -60955.1776978244\n",
      "Loss: 0.0014260814059525728\n",
      "\n",
      "\n",
      "Iteration: 300\n",
      "Squared L2 Norm of Full Gradient: 4379.446076695109\n",
      "Sum of scalar products for gradients in same class: 64927.85502146189\n",
      "Sum of scalar products for gradients in different class: -60548.40894476678\n",
      "Loss: 0.0014211887028068304\n",
      "\n",
      "\n",
      "Iteration: 301\n",
      "Squared L2 Norm of Full Gradient: 4347.640214709623\n",
      "Sum of scalar products for gradients in same class: 64493.86523255495\n",
      "Sum of scalar products for gradients in different class: -60146.225017845325\n",
      "Loss: 0.0014163302257657051\n",
      "\n",
      "\n",
      "Iteration: 302\n",
      "Squared L2 Norm of Full Gradient: 4316.1808337832335\n",
      "Sum of scalar products for gradients in same class: 64064.5350277564\n",
      "Sum of scalar products for gradients in different class: -59748.354193973166\n",
      "Loss: 0.0014115080703049898\n",
      "\n",
      "\n",
      "Iteration: 303\n",
      "Squared L2 Norm of Full Gradient: 4285.078402701765\n",
      "Sum of scalar products for gradients in same class: 63639.602787624084\n",
      "Sum of scalar products for gradients in different class: -59354.52438492232\n",
      "Loss: 0.0014067234005779028\n",
      "\n",
      "\n",
      "Iteration: 304\n",
      "Squared L2 Norm of Full Gradient: 4254.320331062248\n",
      "Sum of scalar products for gradients in same class: 63219.02776321517\n",
      "Sum of scalar products for gradients in different class: -58964.70743215292\n",
      "Loss: 0.0014019700465723872\n",
      "\n",
      "\n",
      "Iteration: 305\n",
      "Squared L2 Norm of Full Gradient: 4223.882291338465\n",
      "Sum of scalar products for gradients in same class: 62802.54741697502\n",
      "Sum of scalar products for gradients in different class: -58578.66512563656\n",
      "Loss: 0.0013972531305626035\n",
      "\n",
      "\n",
      "Iteration: 306\n",
      "Squared L2 Norm of Full Gradient: 4193.81933856383\n",
      "Sum of scalar products for gradients in same class: 62391.01725402466\n",
      "Sum of scalar products for gradients in different class: -58197.19791546083\n",
      "Loss: 0.001392569625750184\n",
      "\n",
      "\n",
      "Iteration: 307\n",
      "Squared L2 Norm of Full Gradient: 4164.0715101195965\n",
      "Sum of scalar products for gradients in same class: 61983.5023759225\n",
      "Sum of scalar products for gradients in different class: -57819.430865802904\n",
      "Loss: 0.0013879159232601523\n",
      "\n",
      "\n",
      "Iteration: 308\n",
      "Squared L2 Norm of Full Gradient: 4134.615979353199\n",
      "Sum of scalar products for gradients in same class: 61579.49079167236\n",
      "Sum of scalar products for gradients in different class: -57444.87481231916\n",
      "Loss: 0.0013832987751811743\n",
      "\n",
      "\n",
      "Iteration: 309\n",
      "Squared L2 Norm of Full Gradient: 4105.5309285318945\n",
      "Sum of scalar products for gradients in same class: 61180.42142898163\n",
      "Sum of scalar products for gradients in different class: -57074.890500449736\n",
      "Loss: 0.001378713990561664\n",
      "\n",
      "\n",
      "Iteration: 310\n",
      "Squared L2 Norm of Full Gradient: 4076.725852623582\n",
      "Sum of scalar products for gradients in same class: 60784.867277810976\n",
      "Sum of scalar products for gradients in different class: -56708.141425187394\n",
      "Loss: 0.0013741558650508523\n",
      "\n",
      "\n",
      "Iteration: 311\n",
      "Squared L2 Norm of Full Gradient: 4048.2493598610163\n",
      "Sum of scalar products for gradients in same class: 60393.518866173355\n",
      "Sum of scalar products for gradients in different class: -56345.26950631234\n",
      "Loss: 0.0013696348760277033\n",
      "\n",
      "\n",
      "Iteration: 312\n",
      "Squared L2 Norm of Full Gradient: 4020.0743868779537\n",
      "Sum of scalar products for gradients in same class: 60006.32857453995\n",
      "Sum of scalar products for gradients in different class: -55986.254187661994\n",
      "Loss: 0.0013651425251737237\n",
      "\n",
      "\n",
      "Iteration: 313\n",
      "Squared L2 Norm of Full Gradient: 3992.1809807550744\n",
      "Sum of scalar products for gradients in same class: 59622.565810472675\n",
      "Sum of scalar products for gradients in different class: -55630.3848297176\n",
      "Loss: 0.0013606831198558211\n",
      "\n",
      "\n",
      "Iteration: 314\n",
      "Squared L2 Norm of Full Gradient: 3964.6147831068956\n",
      "Sum of scalar products for gradients in same class: 59242.9746723866\n",
      "Sum of scalar products for gradients in different class: -55278.3598892797\n",
      "Loss: 0.0013562592212110758\n",
      "\n",
      "\n",
      "Iteration: 315\n",
      "Squared L2 Norm of Full Gradient: 3937.3547276249737\n",
      "Sum of scalar products for gradients in same class: 58867.32612321504\n",
      "Sum of scalar products for gradients in different class: -54929.971395590066\n",
      "Loss: 0.0013518580235540867\n",
      "\n",
      "\n",
      "Iteration: 316\n",
      "Squared L2 Norm of Full Gradient: 3910.3638030155707\n",
      "Sum of scalar products for gradients in same class: 58495.147484133384\n",
      "Sum of scalar products for gradients in different class: -54584.78368111781\n",
      "Loss: 0.0013474931474775076\n",
      "\n",
      "\n",
      "Iteration: 317\n",
      "Squared L2 Norm of Full Gradient: 3883.6454295768053\n",
      "Sum of scalar products for gradients in same class: 58126.474653664205\n",
      "Sum of scalar products for gradients in different class: -54242.8292240874\n",
      "Loss: 0.0013431544648483396\n",
      "\n",
      "\n",
      "Iteration: 318\n",
      "Squared L2 Norm of Full Gradient: 3857.227133582477\n",
      "Sum of scalar products for gradients in same class: 57761.91125405251\n",
      "Sum of scalar products for gradients in different class: -53904.68412047003\n",
      "Loss: 0.0013388473307713866\n",
      "\n",
      "\n",
      "Iteration: 319\n",
      "Squared L2 Norm of Full Gradient: 3831.0996933533024\n",
      "Sum of scalar products for gradients in same class: 57400.91542582908\n",
      "Sum of scalar products for gradients in different class: -53569.81573247578\n",
      "Loss: 0.0013345717452466488\n",
      "\n",
      "\n",
      "Iteration: 320\n",
      "Squared L2 Norm of Full Gradient: 3805.1989360081498\n",
      "Sum of scalar products for gradients in same class: 57042.748120272125\n",
      "Sum of scalar products for gradients in different class: -53237.549184263975\n",
      "Loss: 0.0013303199084475636\n",
      "\n",
      "\n",
      "Iteration: 321\n",
      "Squared L2 Norm of Full Gradient: 3779.595688323083\n",
      "Sum of scalar products for gradients in same class: 56688.6042242877\n",
      "Sum of scalar products for gradients in different class: -52909.00853596462\n",
      "Loss: 0.0013261004351079464\n",
      "\n",
      "\n",
      "Iteration: 322\n",
      "Squared L2 Norm of Full Gradient: 3754.25743799709\n",
      "Sum of scalar products for gradients in same class: 56337.77265743601\n",
      "Sum of scalar products for gradients in different class: -52583.51521943892\n",
      "Loss: 0.0013219083193689585\n",
      "\n",
      "\n",
      "Iteration: 323\n",
      "Squared L2 Norm of Full Gradient: 3729.1935619490687\n",
      "Sum of scalar products for gradients in same class: 55990.44618827113\n",
      "Sum of scalar products for gradients in different class: -52261.252626322064\n",
      "Loss: 0.0013177403016015887\n",
      "\n",
      "\n",
      "Iteration: 324\n",
      "Squared L2 Norm of Full Gradient: 3704.369651679008\n",
      "Sum of scalar products for gradients in same class: 55646.50833034987\n",
      "Sum of scalar products for gradients in different class: -51942.13867867086\n",
      "Loss: 0.0013136047637090087\n",
      "\n",
      "\n",
      "Iteration: 325\n",
      "Squared L2 Norm of Full Gradient: 3679.7989513734356\n",
      "Sum of scalar products for gradients in same class: 55305.71240171074\n",
      "Sum of scalar products for gradients in different class: -51625.913450337306\n",
      "Loss: 0.001309497281908989\n",
      "\n",
      "\n",
      "Iteration: 326\n",
      "Squared L2 Norm of Full Gradient: 3655.497286610538\n",
      "Sum of scalar products for gradients in same class: 54968.46031398118\n",
      "Sum of scalar products for gradients in different class: -51312.96302737064\n",
      "Loss: 0.0013054149458184838\n",
      "\n",
      "\n",
      "Iteration: 327\n",
      "Squared L2 Norm of Full Gradient: 3631.4434830623213\n",
      "Sum of scalar products for gradients in same class: 54634.235506908124\n",
      "Sum of scalar products for gradients in different class: -51002.7920238458\n",
      "Loss: 0.0013013564748689532\n",
      "\n",
      "\n",
      "Iteration: 328\n",
      "Squared L2 Norm of Full Gradient: 3607.624882758595\n",
      "Sum of scalar products for gradients in same class: 54303.27749832964\n",
      "Sum of scalar products for gradients in different class: -50695.652615571045\n",
      "Loss: 0.0012973339762538671\n",
      "\n",
      "\n",
      "Iteration: 329\n",
      "Squared L2 Norm of Full Gradient: 3584.025786069469\n",
      "Sum of scalar products for gradients in same class: 53975.149312245514\n",
      "Sum of scalar products for gradients in different class: -50391.123526176045\n",
      "Loss: 0.0012933304533362389\n",
      "\n",
      "\n",
      "Iteration: 330\n",
      "Squared L2 Norm of Full Gradient: 3560.6812217901606\n",
      "Sum of scalar products for gradients in same class: 53650.392385775674\n",
      "Sum of scalar products for gradients in different class: -50089.711163985514\n",
      "Loss: 0.001289358246140182\n",
      "\n",
      "\n",
      "Iteration: 331\n",
      "Squared L2 Norm of Full Gradient: 3537.5794680418912\n",
      "Sum of scalar products for gradients in same class: 53328.6284935725\n",
      "Sum of scalar products for gradients in different class: -49791.04902553061\n",
      "Loss: 0.0012854039669036865\n",
      "\n",
      "\n",
      "Iteration: 332\n",
      "Squared L2 Norm of Full Gradient: 3514.7012561243173\n",
      "Sum of scalar products for gradients in same class: 53009.80384378313\n",
      "Sum of scalar products for gradients in different class: -49495.10258765881\n",
      "Loss: 0.0012814830988645554\n",
      "\n",
      "\n",
      "Iteration: 333\n",
      "Squared L2 Norm of Full Gradient: 3492.045139838534\n",
      "Sum of scalar products for gradients in same class: 52694.0396925376\n",
      "Sum of scalar products for gradients in different class: -49201.99455269906\n",
      "Loss: 0.001277583185583353\n",
      "\n",
      "\n",
      "Iteration: 334\n",
      "Squared L2 Norm of Full Gradient: 3469.631702877814\n",
      "Sum of scalar products for gradients in same class: 52381.45221152366\n",
      "Sum of scalar products for gradients in different class: -48911.82050864585\n",
      "Loss: 0.0012737109791487455\n",
      "\n",
      "\n",
      "Iteration: 335\n",
      "Squared L2 Norm of Full Gradient: 3447.4413878076157\n",
      "Sum of scalar products for gradients in same class: 52071.59432992413\n",
      "Sum of scalar products for gradients in different class: -48624.15294211652\n",
      "Loss: 0.0012698582140728831\n",
      "\n",
      "\n",
      "Iteration: 336\n",
      "Squared L2 Norm of Full Gradient: 3425.4334449073212\n",
      "Sum of scalar products for gradients in same class: 51764.09275385094\n",
      "Sum of scalar products for gradients in different class: -48338.65930894362\n",
      "Loss: 0.0012660331558436155\n",
      "\n",
      "\n",
      "Iteration: 337\n",
      "Squared L2 Norm of Full Gradient: 3403.685142809758\n",
      "Sum of scalar products for gradients in same class: 51460.22487802102\n",
      "Sum of scalar products for gradients in different class: -48056.53973521126\n",
      "Loss: 0.0012622363865375519\n",
      "\n",
      "\n",
      "Iteration: 338\n",
      "Squared L2 Norm of Full Gradient: 3382.133440990234\n",
      "Sum of scalar products for gradients in same class: 51158.730806573934\n",
      "Sum of scalar products for gradients in different class: -47776.5973655837\n",
      "Loss: 0.0012584569631144404\n",
      "\n",
      "\n",
      "Iteration: 339\n",
      "Squared L2 Norm of Full Gradient: 3360.785970079727\n",
      "Sum of scalar products for gradients in same class: 50860.028052842754\n",
      "Sum of scalar products for gradients in different class: -47499.24208276303\n",
      "Loss: 0.0012547014048323035\n",
      "\n",
      "\n",
      "Iteration: 340\n",
      "Squared L2 Norm of Full Gradient: 3339.638792991187\n",
      "Sum of scalar products for gradients in same class: 50563.888242397385\n",
      "Sum of scalar products for gradients in different class: -47224.2494494062\n",
      "Loss: 0.0012509770458564162\n",
      "\n",
      "\n",
      "Iteration: 341\n",
      "Squared L2 Norm of Full Gradient: 3318.7073527733446\n",
      "Sum of scalar products for gradients in same class: 50270.55945780955\n",
      "Sum of scalar products for gradients in different class: -46951.8521050362\n",
      "Loss: 0.001247277483344078\n",
      "\n",
      "\n",
      "Iteration: 342\n",
      "Squared L2 Norm of Full Gradient: 3297.9630773026147\n",
      "Sum of scalar products for gradients in same class: 49979.81939655787\n",
      "Sum of scalar products for gradients in different class: -46681.856319255254\n",
      "Loss: 0.0012435909593477845\n",
      "\n",
      "\n",
      "Iteration: 343\n",
      "Squared L2 Norm of Full Gradient: 3277.455052302743\n",
      "Sum of scalar products for gradients in same class: 49692.19358124523\n",
      "Sum of scalar products for gradients in different class: -46414.738528942486\n",
      "Loss: 0.001239929930306971\n",
      "\n",
      "\n",
      "Iteration: 344\n",
      "Squared L2 Norm of Full Gradient: 3257.109393486986\n",
      "Sum of scalar products for gradients in same class: 49406.56916722185\n",
      "Sum of scalar products for gradients in different class: -46149.45977373487\n",
      "Loss: 0.0012362976558506489\n",
      "\n",
      "\n",
      "Iteration: 345\n",
      "Squared L2 Norm of Full Gradient: 3236.982911379906\n",
      "Sum of scalar products for gradients in same class: 49123.885779559554\n",
      "Sum of scalar products for gradients in different class: -45886.90286817965\n",
      "Loss: 0.0012326875003054738\n",
      "\n",
      "\n",
      "Iteration: 346\n",
      "Squared L2 Norm of Full Gradient: 3217.0369398915354\n",
      "Sum of scalar products for gradients in same class: 48843.53764206231\n",
      "Sum of scalar products for gradients in different class: -45626.50070217077\n",
      "Loss: 0.0012290942249819636\n",
      "\n",
      "\n",
      "Iteration: 347\n",
      "Squared L2 Norm of Full Gradient: 3197.2652052464546\n",
      "Sum of scalar products for gradients in same class: 48565.59725951729\n",
      "Sum of scalar products for gradients in different class: -45368.33205427084\n",
      "Loss: 0.0012255246983841062\n",
      "\n",
      "\n",
      "Iteration: 348\n",
      "Squared L2 Norm of Full Gradient: 3177.6963398766384\n",
      "Sum of scalar products for gradients in same class: 48290.2262568267\n",
      "Sum of scalar products for gradients in different class: -45112.529916950065\n",
      "Loss: 0.0012219777563586831\n",
      "\n",
      "\n",
      "Iteration: 349\n",
      "Squared L2 Norm of Full Gradient: 3158.3281772593036\n",
      "Sum of scalar products for gradients in same class: 48017.59734645524\n",
      "Sum of scalar products for gradients in different class: -44859.26916919593\n",
      "Loss: 0.001218452351167798\n",
      "\n",
      "\n",
      "Iteration: 350\n",
      "Squared L2 Norm of Full Gradient: 3139.1128326228354\n",
      "Sum of scalar products for gradients in same class: 47746.84944611427\n",
      "Sum of scalar products for gradients in different class: -44607.736613491434\n",
      "Loss: 0.001214948482811451\n",
      "\n",
      "\n",
      "Iteration: 351\n",
      "Squared L2 Norm of Full Gradient: 3120.0771480726544\n",
      "Sum of scalar products for gradients in same class: 47478.52843924238\n",
      "Sum of scalar products for gradients in different class: -44358.451291169724\n",
      "Loss: 0.0012114630080759525\n",
      "\n",
      "\n",
      "Iteration: 352\n",
      "Squared L2 Norm of Full Gradient: 3101.2416861091187\n",
      "Sum of scalar products for gradients in same class: 47212.927652043756\n",
      "Sum of scalar products for gradients in different class: -44111.68596593464\n",
      "Loss: 0.0012080015148967505\n",
      "\n",
      "\n",
      "Iteration: 353\n",
      "Squared L2 Norm of Full Gradient: 3082.5699938708567\n",
      "Sum of scalar products for gradients in same class: 46949.51339740222\n",
      "Sum of scalar products for gradients in different class: -43866.94340353136\n",
      "Loss: 0.0012045580660924315\n",
      "\n",
      "\n",
      "Iteration: 354\n",
      "Squared L2 Norm of Full Gradient: 3064.0847527716687\n",
      "Sum of scalar products for gradients in same class: 46688.569815518495\n",
      "Sum of scalar products for gradients in different class: -43624.485062746826\n",
      "Loss: 0.0012011436047032475\n",
      "\n",
      "\n",
      "Iteration: 355\n",
      "Squared L2 Norm of Full Gradient: 3045.754050501637\n",
      "Sum of scalar products for gradients in same class: 46429.56628153958\n",
      "Sum of scalar products for gradients in different class: -43383.81223103794\n",
      "Loss: 0.0011977461399510503\n",
      "\n",
      "\n",
      "Iteration: 356\n",
      "Squared L2 Norm of Full Gradient: 3027.5895890095853\n",
      "Sum of scalar products for gradients in same class: 46172.79417836861\n",
      "Sum of scalar products for gradients in different class: -43145.204589359026\n",
      "Loss: 0.0011943642748519778\n",
      "\n",
      "\n",
      "Iteration: 357\n",
      "Squared L2 Norm of Full Gradient: 3009.585764627569\n",
      "Sum of scalar products for gradients in same class: 45918.14469992294\n",
      "Sum of scalar products for gradients in different class: -42908.55893529537\n",
      "Loss: 0.0011910035973414779\n",
      "\n",
      "\n",
      "Iteration: 358\n",
      "Squared L2 Norm of Full Gradient: 2991.7783476543264\n",
      "Sum of scalar products for gradients in same class: 45666.05790368469\n",
      "Sum of scalar products for gradients in different class: -42674.279556030364\n",
      "Loss: 0.0011876636417582631\n",
      "\n",
      "\n",
      "Iteration: 359\n",
      "Squared L2 Norm of Full Gradient: 2974.0990779013955\n",
      "Sum of scalar products for gradients in same class: 45415.703484411744\n",
      "Sum of scalar products for gradients in different class: -42441.60440651035\n",
      "Loss: 0.0011843456886708736\n",
      "\n",
      "\n",
      "Iteration: 360\n",
      "Squared L2 Norm of Full Gradient: 2956.6124153810088\n",
      "Sum of scalar products for gradients in same class: 45168.08628716349\n",
      "Sum of scalar products for gradients in different class: -42211.47387178248\n",
      "Loss: 0.0011810457799583673\n",
      "\n",
      "\n",
      "Iteration: 361\n",
      "Squared L2 Norm of Full Gradient: 2939.2583826254704\n",
      "Sum of scalar products for gradients in same class: 44922.23517919611\n",
      "Sum of scalar products for gradients in different class: -41982.97679657064\n",
      "Loss: 0.00117776810657233\n",
      "\n",
      "\n",
      "Iteration: 362\n",
      "Squared L2 Norm of Full Gradient: 2922.06471930143\n",
      "Sum of scalar products for gradients in same class: 44678.3532299994\n",
      "Sum of scalar products for gradients in different class: -41756.28851069797\n",
      "Loss: 0.0011745019583031535\n",
      "\n",
      "\n",
      "Iteration: 363\n",
      "Squared L2 Norm of Full Gradient: 2905.028817369617\n",
      "Sum of scalar products for gradients in same class: 44436.808678222864\n",
      "Sum of scalar products for gradients in different class: -41531.77986085325\n",
      "Loss: 0.001171265495941043\n",
      "\n",
      "\n",
      "Iteration: 364\n",
      "Squared L2 Norm of Full Gradient: 2888.154654307815\n",
      "Sum of scalar products for gradients in same class: 44197.09424907551\n",
      "Sum of scalar products for gradients in different class: -41308.9395947677\n",
      "Loss: 0.0011680388124659657\n",
      "\n",
      "\n",
      "Iteration: 365\n",
      "Squared L2 Norm of Full Gradient: 2871.432665204178\n",
      "Sum of scalar products for gradients in same class: 43959.519740696676\n",
      "Sum of scalar products for gradients in different class: -41088.0870754925\n",
      "Loss: 0.0011648338986560702\n",
      "\n",
      "\n",
      "Iteration: 366\n",
      "Squared L2 Norm of Full Gradient: 2854.8517602828942\n",
      "Sum of scalar products for gradients in same class: 43723.766931878985\n",
      "Sum of scalar products for gradients in different class: -40868.91517159609\n",
      "Loss: 0.001161649590358138\n",
      "\n",
      "\n",
      "Iteration: 367\n",
      "Squared L2 Norm of Full Gradient: 2838.4180445285892\n",
      "Sum of scalar products for gradients in same class: 43490.24027905702\n",
      "Sum of scalar products for gradients in different class: -40651.82223452843\n",
      "Loss: 0.001158480765298009\n",
      "\n",
      "\n",
      "Iteration: 368\n",
      "Squared L2 Norm of Full Gradient: 2822.1184988123277\n",
      "Sum of scalar products for gradients in same class: 43258.22337960241\n",
      "Sum of scalar products for gradients in different class: -40436.10488079008\n",
      "Loss: 0.001155333360657096\n",
      "\n",
      "\n",
      "Iteration: 369\n",
      "Squared L2 Norm of Full Gradient: 2805.9733880367276\n",
      "Sum of scalar products for gradients in same class: 43028.33175101766\n",
      "Sum of scalar products for gradients in different class: -40222.35836298093\n",
      "Loss: 0.0011522028362378478\n",
      "\n",
      "\n",
      "Iteration: 370\n",
      "Squared L2 Norm of Full Gradient: 2789.9729200145375\n",
      "Sum of scalar products for gradients in same class: 42800.46567687976\n",
      "Sum of scalar products for gradients in different class: -40010.49275686522\n",
      "Loss: 0.0011490894248709083\n",
      "\n",
      "\n",
      "Iteration: 371\n",
      "Squared L2 Norm of Full Gradient: 2774.121875837576\n",
      "Sum of scalar products for gradients in same class: 42574.48928485466\n",
      "Sum of scalar products for gradients in different class: -39800.36740901708\n",
      "Loss: 0.0011459925444796681\n",
      "\n",
      "\n",
      "Iteration: 372\n",
      "Squared L2 Norm of Full Gradient: 2758.38931571343\n",
      "Sum of scalar products for gradients in same class: 42350.13115725487\n",
      "Sum of scalar products for gradients in different class: -39591.74184154144\n",
      "Loss: 0.0011429169680923223\n",
      "\n",
      "\n",
      "Iteration: 373\n",
      "Squared L2 Norm of Full Gradient: 2742.800584841185\n",
      "Sum of scalar products for gradients in same class: 42127.78039842594\n",
      "Sum of scalar products for gradients in different class: -39384.97981358475\n",
      "Loss: 0.001139851869083941\n",
      "\n",
      "\n",
      "Iteration: 374\n",
      "Squared L2 Norm of Full Gradient: 2727.3520505656634\n",
      "Sum of scalar products for gradients in same class: 41907.41878001926\n",
      "Sum of scalar products for gradients in different class: -39180.066729453596\n",
      "Loss: 0.0011368074920028448\n",
      "\n",
      "\n",
      "Iteration: 375\n",
      "Squared L2 Norm of Full Gradient: 2712.0556123741553\n",
      "Sum of scalar products for gradients in same class: 41688.89390841518\n",
      "Sum of scalar products for gradients in different class: -38976.83829604102\n",
      "Loss: 0.001133785001002252\n",
      "\n",
      "\n",
      "Iteration: 376\n",
      "Squared L2 Norm of Full Gradient: 2696.8544888401084\n",
      "Sum of scalar products for gradients in same class: 41471.78752721583\n",
      "Sum of scalar products for gradients in different class: -38774.93303837572\n",
      "Loss: 0.0011307739187031984\n",
      "\n",
      "\n",
      "Iteration: 377\n",
      "Squared L2 Norm of Full Gradient: 2681.819355570711\n",
      "Sum of scalar products for gradients in same class: 41256.805172388835\n",
      "Sum of scalar products for gradients in different class: -38574.98581681812\n",
      "Loss: 0.00112778483889997\n",
      "\n",
      "\n",
      "Iteration: 378\n",
      "Squared L2 Norm of Full Gradient: 2666.886925561834\n",
      "Sum of scalar products for gradients in same class: 41043.243465805106\n",
      "Sum of scalar products for gradients in different class: -38376.35654024327\n",
      "Loss: 0.001124807633459568\n",
      "\n",
      "\n",
      "Iteration: 379\n",
      "Squared L2 Norm of Full Gradient: 2652.0881219769362\n",
      "Sum of scalar products for gradients in same class: 40831.48607477314\n",
      "Sum of scalar products for gradients in different class: -38179.39795279621\n",
      "Loss: 0.0011218470754101872\n",
      "\n",
      "\n",
      "Iteration: 380\n",
      "Squared L2 Norm of Full Gradient: 2637.417474583621\n",
      "Sum of scalar products for gradients in same class: 40621.4498594458\n",
      "Sum of scalar products for gradients in different class: -37984.03238486218\n",
      "Loss: 0.0011189032811671495\n",
      "\n",
      "\n",
      "Iteration: 381\n",
      "Squared L2 Norm of Full Gradient: 2622.87074204105\n",
      "Sum of scalar products for gradients in same class: 40413.04342945649\n",
      "Sum of scalar products for gradients in different class: -37790.17268741544\n",
      "Loss: 0.0011159760178998113\n",
      "\n",
      "\n",
      "Iteration: 382\n",
      "Squared L2 Norm of Full Gradient: 2608.4484019044467\n",
      "Sum of scalar products for gradients in same class: 40206.42246789648\n",
      "Sum of scalar products for gradients in different class: -37597.974065992035\n",
      "Loss: 0.001113070291467011\n",
      "\n",
      "\n",
      "Iteration: 383\n",
      "Squared L2 Norm of Full Gradient: 2594.170740804999\n",
      "Sum of scalar products for gradients in same class: 40001.578405988985\n",
      "Sum of scalar products for gradients in different class: -37407.407665183986\n",
      "Loss: 0.001110174460336566\n",
      "\n",
      "\n",
      "Iteration: 384\n",
      "Squared L2 Norm of Full Gradient: 2579.9876779466867\n",
      "Sum of scalar products for gradients in same class: 39798.09030897505\n",
      "Sum of scalar products for gradients in different class: -37218.10263102836\n",
      "Loss: 0.0011072963243350387\n",
      "\n",
      "\n",
      "Iteration: 385\n",
      "Squared L2 Norm of Full Gradient: 2565.9142156066955\n",
      "Sum of scalar products for gradients in same class: 39596.01431197718\n",
      "Sum of scalar products for gradients in different class: -37030.10009637049\n",
      "Loss: 0.0011044290149584413\n",
      "\n",
      "\n",
      "Iteration: 386\n",
      "Squared L2 Norm of Full Gradient: 2551.9929391452024\n",
      "Sum of scalar products for gradients in same class: 39396.14800978571\n",
      "Sum of scalar products for gradients in different class: -36844.15507064051\n",
      "Loss: 0.0011015859199687839\n",
      "\n",
      "\n",
      "Iteration: 387\n",
      "Squared L2 Norm of Full Gradient: 2538.1548855943256\n",
      "Sum of scalar products for gradients in same class: 39197.42815049218\n",
      "Sum of scalar products for gradients in different class: -36659.273264897856\n",
      "Loss: 0.0010987530695274472\n",
      "\n",
      "\n",
      "Iteration: 388\n",
      "Squared L2 Norm of Full Gradient: 2524.445300628955\n",
      "Sum of scalar products for gradients in same class: 39000.26096702383\n",
      "Sum of scalar products for gradients in different class: -36475.815666394876\n",
      "Loss: 0.001095943502150476\n",
      "\n",
      "\n",
      "Iteration: 389\n",
      "Squared L2 Norm of Full Gradient: 2510.8458595234115\n",
      "Sum of scalar products for gradients in same class: 38804.72451762034\n",
      "Sum of scalar products for gradients in different class: -36293.87865809693\n",
      "Loss: 0.0010931318392977118\n",
      "\n",
      "\n",
      "Iteration: 390\n",
      "Squared L2 Norm of Full Gradient: 2497.3677891656407\n",
      "Sum of scalar products for gradients in same class: 38610.91242265281\n",
      "Sum of scalar products for gradients in different class: -36113.54463348717\n",
      "Loss: 0.001090346253477037\n",
      "\n",
      "\n",
      "Iteration: 391\n",
      "Squared L2 Norm of Full Gradient: 2484.0096447765973\n",
      "Sum of scalar products for gradients in same class: 38418.508207377774\n",
      "Sum of scalar products for gradients in different class: -35934.49856260118\n",
      "Loss: 0.0010875785956159234\n",
      "\n",
      "\n",
      "Iteration: 392\n",
      "Squared L2 Norm of Full Gradient: 2470.7457231386215\n",
      "Sum of scalar products for gradients in same class: 38227.42614782942\n",
      "Sum of scalar products for gradients in different class: -35756.6804246908\n",
      "Loss: 0.0010848231613636017\n",
      "\n",
      "\n",
      "Iteration: 393\n",
      "Squared L2 Norm of Full Gradient: 2457.5933309295797\n",
      "Sum of scalar products for gradients in same class: 38038.08340813877\n",
      "Sum of scalar products for gradients in different class: -35580.49007720919\n",
      "Loss: 0.0010820809984579682\n",
      "\n",
      "\n",
      "Iteration: 394\n",
      "Squared L2 Norm of Full Gradient: 2444.5345067975722\n",
      "Sum of scalar products for gradients in same class: 37849.717944490825\n",
      "Sum of scalar products for gradients in different class: -35405.18343769325\n",
      "Loss: 0.001079354784451425\n",
      "\n",
      "\n",
      "Iteration: 395\n",
      "Squared L2 Norm of Full Gradient: 2431.590227022767\n",
      "Sum of scalar products for gradients in same class: 37663.028154757354\n",
      "Sum of scalar products for gradients in different class: -35231.43792773459\n",
      "Loss: 0.0010766421910375357\n",
      "\n",
      "\n",
      "Iteration: 396\n",
      "Squared L2 Norm of Full Gradient: 2418.7613564636704\n",
      "Sum of scalar products for gradients in same class: 37477.86453947668\n",
      "Sum of scalar products for gradients in different class: -35059.10318301301\n",
      "Loss: 0.0010739411227405071\n",
      "\n",
      "\n",
      "Iteration: 397\n",
      "Squared L2 Norm of Full Gradient: 2406.0521162023215\n",
      "Sum of scalar products for gradients in same class: 37294.389358479704\n",
      "Sum of scalar products for gradients in different class: -34888.33724227738\n",
      "Loss: 0.0010712607763707638\n",
      "\n",
      "\n",
      "Iteration: 398\n",
      "Squared L2 Norm of Full Gradient: 2393.4151717112545\n",
      "Sum of scalar products for gradients in same class: 37112.02034968471\n",
      "Sum of scalar products for gradients in different class: -34718.605177973455\n",
      "Loss: 0.0010685916058719158\n",
      "\n",
      "\n",
      "Iteration: 399\n",
      "Squared L2 Norm of Full Gradient: 2380.895260647172\n",
      "Sum of scalar products for gradients in same class: 36930.88807365937\n",
      "Sum of scalar products for gradients in different class: -34549.9928130122\n",
      "Loss: 0.0010659339604899287\n",
      "\n",
      "\n",
      "Iteration: 400\n",
      "Squared L2 Norm of Full Gradient: 2368.4828119772137\n",
      "Sum of scalar products for gradients in same class: 36751.512719596154\n",
      "Sum of scalar products for gradients in different class: -34383.02990761894\n",
      "Loss: 0.0010632957564666867\n",
      "\n",
      "\n",
      "Iteration: 401\n",
      "Squared L2 Norm of Full Gradient: 2356.1409471589286\n",
      "Sum of scalar products for gradients in same class: 36572.903298813035\n",
      "Sum of scalar products for gradients in different class: -34216.762351654106\n",
      "Loss: 0.0010606684954836965\n",
      "\n",
      "\n",
      "Iteration: 402\n",
      "Squared L2 Norm of Full Gradient: 2343.920339644086\n",
      "Sum of scalar products for gradients in same class: 36396.168314043534\n",
      "Sum of scalar products for gradients in different class: -34052.24797439945\n",
      "Loss: 0.0010580511298030615\n",
      "\n",
      "\n",
      "Iteration: 403\n",
      "Squared L2 Norm of Full Gradient: 2331.8026102615986\n",
      "Sum of scalar products for gradients in same class: 36220.78258949316\n",
      "Sum of scalar products for gradients in different class: -33888.97997923156\n",
      "Loss: 0.0010554479667916894\n",
      "\n",
      "\n",
      "Iteration: 404\n",
      "Squared L2 Norm of Full Gradient: 2319.7545013373165\n",
      "Sum of scalar products for gradients in same class: 36046.300933879524\n",
      "Sum of scalar products for gradients in different class: -33726.54643254221\n",
      "Loss: 0.0010528567945584655\n",
      "\n",
      "\n",
      "Iteration: 405\n",
      "Squared L2 Norm of Full Gradient: 2307.8156653926853\n",
      "Sum of scalar products for gradients in same class: 35873.36777785784\n",
      "Sum of scalar products for gradients in different class: -33565.55211246516\n",
      "Loss: 0.0010502873919904232\n",
      "\n",
      "\n",
      "Iteration: 406\n",
      "Squared L2 Norm of Full Gradient: 2295.97672366444\n",
      "Sum of scalar products for gradients in same class: 35701.64145548316\n",
      "Sum of scalar products for gradients in different class: -33405.66473181872\n",
      "Loss: 0.0010477277683094144\n",
      "\n",
      "\n",
      "Iteration: 407\n",
      "Squared L2 Norm of Full Gradient: 2284.236048521838\n",
      "Sum of scalar products for gradients in same class: 35531.36397164315\n",
      "Sum of scalar products for gradients in different class: -33247.12792312131\n",
      "Loss: 0.001045180018991232\n",
      "\n",
      "\n",
      "Iteration: 408\n",
      "Squared L2 Norm of Full Gradient: 2272.5858436154667\n",
      "Sum of scalar products for gradients in same class: 35362.2279411154\n",
      "Sum of scalar products for gradients in different class: -33089.642097499935\n",
      "Loss: 0.0010426458902657032\n",
      "\n",
      "\n",
      "Iteration: 409\n",
      "Squared L2 Norm of Full Gradient: 2261.0260080567095\n",
      "Sum of scalar products for gradients in same class: 35194.3411214074\n",
      "Sum of scalar products for gradients in different class: -32933.31511335069\n",
      "Loss: 0.0010401232866570354\n",
      "\n",
      "\n",
      "Iteration: 410\n",
      "Squared L2 Norm of Full Gradient: 2249.5492025176063\n",
      "Sum of scalar products for gradients in same class: 35027.7255501418\n",
      "Sum of scalar products for gradients in different class: -32778.17634762419\n",
      "Loss: 0.0010376095306128263\n",
      "\n",
      "\n",
      "Iteration: 411\n",
      "Squared L2 Norm of Full Gradient: 2238.171981895357\n",
      "Sum of scalar products for gradients in same class: 34862.26026192559\n",
      "Sum of scalar products for gradients in different class: -32624.088280030235\n",
      "Loss: 0.0010351190576329827\n",
      "\n",
      "\n",
      "Iteration: 412\n",
      "Squared L2 Norm of Full Gradient: 2226.8725684276433\n",
      "Sum of scalar products for gradients in same class: 34698.166553116505\n",
      "Sum of scalar products for gradients in different class: -32471.293984688862\n",
      "Loss: 0.001032627304084599\n",
      "\n",
      "\n",
      "Iteration: 413\n",
      "Squared L2 Norm of Full Gradient: 2215.66244091891\n",
      "Sum of scalar products for gradients in same class: 34535.063416584555\n",
      "Sum of scalar products for gradients in different class: -32319.400975665645\n",
      "Loss: 0.0010301627917215228\n",
      "\n",
      "\n",
      "Iteration: 414\n",
      "Squared L2 Norm of Full Gradient: 2204.560125019634\n",
      "Sum of scalar products for gradients in same class: 34373.55210853659\n",
      "Sum of scalar products for gradients in different class: -32168.991983516957\n",
      "Loss: 0.0010277052642777562\n",
      "\n",
      "\n",
      "Iteration: 415\n",
      "Squared L2 Norm of Full Gradient: 2193.516781919883\n",
      "Sum of scalar products for gradients in same class: 34212.81760254607\n",
      "Sum of scalar products for gradients in different class: -32019.300820626187\n",
      "Loss: 0.0010252619395032525\n",
      "\n",
      "\n",
      "Iteration: 416\n",
      "Squared L2 Norm of Full Gradient: 2182.5674635507166\n",
      "Sum of scalar products for gradients in same class: 34053.36843337676\n",
      "Sum of scalar products for gradients in different class: -31870.800969826043\n",
      "Loss: 0.0010228217579424381\n",
      "\n",
      "\n",
      "Iteration: 417\n",
      "Squared L2 Norm of Full Gradient: 2171.7034941916936\n",
      "Sum of scalar products for gradients in same class: 33894.99633487112\n",
      "Sum of scalar products for gradients in different class: -31723.292840679424\n",
      "Loss: 0.0010204034624621272\n",
      "\n",
      "\n",
      "Iteration: 418\n",
      "Squared L2 Norm of Full Gradient: 2160.92621280835\n",
      "Sum of scalar products for gradients in same class: 33737.99039572118\n",
      "Sum of scalar products for gradients in different class: -31577.06418291283\n",
      "Loss: 0.0010179913369938731\n",
      "\n",
      "\n",
      "Iteration: 419\n",
      "Squared L2 Norm of Full Gradient: 2150.216423927355\n",
      "Sum of scalar products for gradients in same class: 33581.78552692411\n",
      "Sum of scalar products for gradients in different class: -31431.569102996757\n",
      "Loss: 0.0010155895724892616\n",
      "\n",
      "\n",
      "Iteration: 420\n",
      "Squared L2 Norm of Full Gradient: 2139.592174890582\n",
      "Sum of scalar products for gradients in same class: 33426.823967097676\n",
      "Sum of scalar products for gradients in different class: -31287.231792207094\n",
      "Loss: 0.0010132048046216369\n",
      "\n",
      "\n",
      "Iteration: 421\n",
      "Squared L2 Norm of Full Gradient: 2129.064292345196\n",
      "Sum of scalar products for gradients in same class: 33273.22300321056\n",
      "Sum of scalar products for gradients in different class: -31144.158710865362\n",
      "Loss: 0.00101082946639508\n",
      "\n",
      "\n",
      "Iteration: 422\n",
      "Squared L2 Norm of Full Gradient: 2118.597491593813\n",
      "Sum of scalar products for gradients in same class: 33120.3901108189\n",
      "Sum of scalar products for gradients in different class: -31001.79261922509\n",
      "Loss: 0.0010084710083901882\n",
      "\n",
      "\n",
      "Iteration: 423\n",
      "Squared L2 Norm of Full Gradient: 2108.219186826158\n",
      "Sum of scalar products for gradients in same class: 32968.828004761584\n",
      "Sum of scalar products for gradients in different class: -30860.608817935426\n",
      "Loss: 0.0010061206994578242\n",
      "\n",
      "\n",
      "Iteration: 424\n",
      "Squared L2 Norm of Full Gradient: 2097.9187815399055\n",
      "Sum of scalar products for gradients in same class: 32818.32022992248\n",
      "Sum of scalar products for gradients in different class: -30720.401448382574\n",
      "Loss: 0.0010037780739367008\n",
      "\n",
      "\n",
      "Iteration: 425\n",
      "Squared L2 Norm of Full Gradient: 2087.688918232583\n",
      "Sum of scalar products for gradients in same class: 32668.7881780655\n",
      "Sum of scalar products for gradients in different class: -30581.099259832918\n",
      "Loss: 0.0010014482541009784\n",
      "\n",
      "\n",
      "Iteration: 426\n",
      "Squared L2 Norm of Full Gradient: 2077.546303869225\n",
      "Sum of scalar products for gradients in same class: 32520.324784532557\n",
      "Sum of scalar products for gradients in different class: -30442.77848066333\n",
      "Loss: 0.000999133801087737\n",
      "\n",
      "\n",
      "Iteration: 427\n",
      "Squared L2 Norm of Full Gradient: 2067.483891959433\n",
      "Sum of scalar products for gradients in same class: 32373.127909729057\n",
      "Sum of scalar products for gradients in different class: -30305.644017769624\n",
      "Loss: 0.0009968243539333344\n",
      "\n",
      "\n",
      "Iteration: 428\n",
      "Squared L2 Norm of Full Gradient: 2057.4801677529613\n",
      "Sum of scalar products for gradients in same class: 32226.783367606957\n",
      "Sum of scalar products for gradients in different class: -30169.303199853995\n",
      "Loss: 0.0009945333003997803\n",
      "\n",
      "\n",
      "Iteration: 429\n",
      "Squared L2 Norm of Full Gradient: 2047.5490360481344\n",
      "Sum of scalar products for gradients in same class: 32081.32586112738\n",
      "Sum of scalar products for gradients in different class: -30033.776825079247\n",
      "Loss: 0.000992250395938754\n",
      "\n",
      "\n",
      "Iteration: 430\n",
      "Squared L2 Norm of Full Gradient: 2037.7046103287867\n",
      "Sum of scalar products for gradients in same class: 31937.17210981535\n",
      "Sum of scalar products for gradients in different class: -29899.467499486564\n",
      "Loss: 0.0009899777360260487\n",
      "\n",
      "\n",
      "Iteration: 431\n",
      "Squared L2 Norm of Full Gradient: 2027.9251354806038\n",
      "Sum of scalar products for gradients in same class: 31793.661847206487\n",
      "Sum of scalar products for gradients in different class: -29765.736711725884\n",
      "Loss: 0.0009877145057544112\n",
      "\n",
      "\n",
      "Iteration: 432\n",
      "Squared L2 Norm of Full Gradient: 2018.2274510031712\n",
      "Sum of scalar products for gradients in same class: 31651.57803882049\n",
      "Sum of scalar products for gradients in different class: -29633.35058781732\n",
      "Loss: 0.0009854640811681747\n",
      "\n",
      "\n",
      "Iteration: 433\n",
      "Squared L2 Norm of Full Gradient: 2008.5895958626643\n",
      "Sum of scalar products for gradients in same class: 31510.197293553676\n",
      "Sum of scalar products for gradients in different class: -29501.60769769101\n",
      "Loss: 0.0009832250652834773\n",
      "\n",
      "\n",
      "Iteration: 434\n",
      "Squared L2 Norm of Full Gradient: 1999.0307505071542\n",
      "Sum of scalar products for gradients in same class: 31370.016066753087\n",
      "Sum of scalar products for gradients in different class: -29370.985316245933\n",
      "Loss: 0.0009809962939471006\n",
      "\n",
      "\n",
      "Iteration: 435\n",
      "Squared L2 Norm of Full Gradient: 1989.5352004914457\n",
      "Sum of scalar products for gradients in same class: 31230.555702482092\n",
      "Sum of scalar products for gradients in different class: -29241.020501990646\n",
      "Loss: 0.0009787766030058265\n",
      "\n",
      "\n",
      "Iteration: 436\n",
      "Squared L2 Norm of Full Gradient: 1980.1172545745649\n",
      "Sum of scalar products for gradients in same class: 31092.240587763186\n",
      "Sum of scalar products for gradients in different class: -29112.12333318862\n",
      "Loss: 0.0009765707654878497\n",
      "\n",
      "\n",
      "Iteration: 437\n",
      "Squared L2 Norm of Full Gradient: 1970.765005229172\n",
      "Sum of scalar products for gradients in same class: 30954.788634533445\n",
      "Sum of scalar products for gradients in different class: -28984.023629304273\n",
      "Loss: 0.000974371621850878\n",
      "\n",
      "\n",
      "Iteration: 438\n",
      "Squared L2 Norm of Full Gradient: 1961.4778063297272\n",
      "Sum of scalar products for gradients in same class: 30818.337955415267\n",
      "Sum of scalar products for gradients in different class: -28856.86014908554\n",
      "Loss: 0.000972183421254158\n",
      "\n",
      "\n",
      "Iteration: 439\n",
      "Squared L2 Norm of Full Gradient: 1952.2590615606314\n",
      "Sum of scalar products for gradients in same class: 30682.80854127808\n",
      "Sum of scalar products for gradients in different class: -28730.549479717447\n",
      "Loss: 0.000970005989074707\n",
      "\n",
      "\n",
      "Iteration: 440\n",
      "Squared L2 Norm of Full Gradient: 1943.0933079247043\n",
      "Sum of scalar products for gradients in same class: 30547.998395640392\n",
      "Sum of scalar products for gradients in different class: -28604.905087715688\n",
      "Loss: 0.0009678376954980195\n",
      "\n",
      "\n",
      "Iteration: 441\n",
      "Squared L2 Norm of Full Gradient: 1934.013540825821\n",
      "Sum of scalar products for gradients in same class: 30414.423516908286\n",
      "Sum of scalar products for gradients in different class: -28480.409976082465\n",
      "Loss: 0.0009656855254434049\n",
      "\n",
      "\n",
      "Iteration: 442\n",
      "Squared L2 Norm of Full Gradient: 1924.991523818113\n",
      "Sum of scalar products for gradients in same class: 30281.587149455667\n",
      "Sum of scalar products for gradients in different class: -28356.595625637554\n",
      "Loss: 0.0009635377791710198\n",
      "\n",
      "\n",
      "Iteration: 443\n",
      "Squared L2 Norm of Full Gradient: 1916.035015678266\n",
      "Sum of scalar products for gradients in same class: 30149.619355888106\n",
      "Sum of scalar products for gradients in different class: -28233.58434020984\n",
      "Loss: 0.0009614034206606448\n",
      "\n",
      "\n",
      "Iteration: 444\n",
      "Squared L2 Norm of Full Gradient: 1907.1443716969952\n",
      "Sum of scalar products for gradients in same class: 30018.61152332406\n",
      "Sum of scalar products for gradients in different class: -28111.467151627065\n",
      "Loss: 0.0009592778515070677\n",
      "\n",
      "\n",
      "Iteration: 445\n",
      "Squared L2 Norm of Full Gradient: 1898.317615662003\n",
      "Sum of scalar products for gradients in same class: 29888.665520653976\n",
      "Sum of scalar products for gradients in different class: -27990.347904991973\n",
      "Loss: 0.0009571564150974154\n",
      "\n",
      "\n",
      "Iteration: 446\n",
      "Squared L2 Norm of Full Gradient: 1889.5541148819611\n",
      "Sum of scalar products for gradients in same class: 29759.38095856825\n",
      "Sum of scalar products for gradients in different class: -27869.82684368629\n",
      "Loss: 0.0009550537797622383\n",
      "\n",
      "\n",
      "Iteration: 447\n",
      "Squared L2 Norm of Full Gradient: 1880.8562190993835\n",
      "Sum of scalar products for gradients in same class: 29631.16553503745\n",
      "Sum of scalar products for gradients in different class: -27750.309315938066\n",
      "Loss: 0.0009529552771709859\n",
      "\n",
      "\n",
      "Iteration: 448\n",
      "Squared L2 Norm of Full Gradient: 1872.2044674535427\n",
      "Sum of scalar products for gradients in same class: 29503.427338777066\n",
      "Sum of scalar products for gradients in different class: -27631.222871323524\n",
      "Loss: 0.0009508663206361234\n",
      "\n",
      "\n",
      "Iteration: 449\n",
      "Squared L2 Norm of Full Gradient: 1863.6270041475655\n",
      "Sum of scalar products for gradients in same class: 29376.896450721237\n",
      "Sum of scalar products for gradients in different class: -27513.26944657367\n",
      "Loss: 0.0009487885399721563\n",
      "\n",
      "\n",
      "Iteration: 450\n",
      "Squared L2 Norm of Full Gradient: 1855.1014378408581\n",
      "Sum of scalar products for gradients in same class: 29250.92951465644\n",
      "Sum of scalar products for gradients in different class: -27395.828076815582\n",
      "Loss: 0.0009467220515944064\n",
      "\n",
      "\n",
      "Iteration: 451\n",
      "Squared L2 Norm of Full Gradient: 1846.6324645957357\n",
      "Sum of scalar products for gradients in same class: 29125.823831001053\n",
      "Sum of scalar products for gradients in different class: -27279.191366405317\n",
      "Loss: 0.0009446603944525123\n",
      "\n",
      "\n",
      "Iteration: 452\n",
      "Squared L2 Norm of Full Gradient: 1838.2401104858727\n",
      "Sum of scalar products for gradients in same class: 29001.772622091274\n",
      "Sum of scalar products for gradients in different class: -27163.5325116054\n",
      "Loss: 0.0009426141623407602\n",
      "\n",
      "\n",
      "Iteration: 453\n",
      "Squared L2 Norm of Full Gradient: 1829.8913473617868\n",
      "Sum of scalar products for gradients in same class: 28878.352571963263\n",
      "Sum of scalar products for gradients in different class: -27048.461224601477\n",
      "Loss: 0.0009405717137269676\n",
      "\n",
      "\n",
      "Iteration: 454\n",
      "Squared L2 Norm of Full Gradient: 1821.6162909535342\n",
      "Sum of scalar products for gradients in same class: 28755.97817468862\n",
      "Sum of scalar products for gradients in different class: -26934.361883735084\n",
      "Loss: 0.0009385432931594551\n",
      "\n",
      "\n",
      "Iteration: 455\n",
      "Squared L2 Norm of Full Gradient: 1813.3915016824758\n",
      "Sum of scalar products for gradients in same class: 28634.221949733914\n",
      "Sum of scalar products for gradients in different class: -26820.830448051438\n",
      "Loss: 0.0009365199948661029\n",
      "\n",
      "\n",
      "Iteration: 456\n",
      "Squared L2 Norm of Full Gradient: 1805.2119030431495\n",
      "Sum of scalar products for gradients in same class: 28513.20660917281\n",
      "Sum of scalar products for gradients in different class: -26707.99470612966\n",
      "Loss: 0.0009345086291432381\n",
      "\n",
      "\n",
      "Iteration: 457\n",
      "Squared L2 Norm of Full Gradient: 1797.0999543937069\n",
      "Sum of scalar products for gradients in same class: 28393.136453644493\n",
      "Sum of scalar products for gradients in different class: -26596.036499250786\n",
      "Loss: 0.0009325054124929011\n",
      "\n",
      "\n",
      "Iteration: 458\n",
      "Squared L2 Norm of Full Gradient: 1789.0259574651864\n",
      "Sum of scalar products for gradients in same class: 28273.51512661277\n",
      "Sum of scalar products for gradients in different class: -26484.489169147582\n",
      "Loss: 0.000930504989810288\n",
      "\n",
      "\n",
      "Iteration: 459\n",
      "Squared L2 Norm of Full Gradient: 1781.0403294250282\n",
      "Sum of scalar products for gradients in same class: 28155.18589180898\n",
      "Sum of scalar products for gradients in different class: -26374.14556238395\n",
      "Loss: 0.0009285223204642534\n",
      "\n",
      "\n",
      "Iteration: 460\n",
      "Squared L2 Norm of Full Gradient: 1773.0854142169846\n",
      "Sum of scalar products for gradients in same class: 28037.297199748995\n",
      "Sum of scalar products for gradients in different class: -26264.21178553201\n",
      "Loss: 0.0009265479166060686\n",
      "\n",
      "\n",
      "Iteration: 461\n",
      "Squared L2 Norm of Full Gradient: 1765.1967055793502\n",
      "Sum of scalar products for gradients in same class: 27920.291936886035\n",
      "Sum of scalar products for gradients in different class: -26155.095231306685\n",
      "Loss: 0.0009245775872841477\n",
      "\n",
      "\n",
      "Iteration: 462\n",
      "Squared L2 Norm of Full Gradient: 1757.3604464831296\n",
      "Sum of scalar products for gradients in same class: 27804.073050596184\n",
      "Sum of scalar products for gradients in different class: -26046.712604113054\n",
      "Loss: 0.0009226194233633578\n",
      "\n",
      "\n",
      "Iteration: 463\n",
      "Squared L2 Norm of Full Gradient: 1749.56810685237\n",
      "Sum of scalar products for gradients in same class: 27688.47810811013\n",
      "Sum of scalar products for gradients in different class: -25938.91000125776\n",
      "Loss: 0.0009206680697388947\n",
      "\n",
      "\n",
      "Iteration: 464\n",
      "Squared L2 Norm of Full Gradient: 1741.8402068764553\n",
      "Sum of scalar products for gradients in same class: 27573.6291450334\n",
      "Sum of scalar products for gradients in different class: -25831.788938156944\n",
      "Loss: 0.0009187299874611199\n",
      "\n",
      "\n",
      "Iteration: 465\n",
      "Squared L2 Norm of Full Gradient: 1734.168172723861\n",
      "Sum of scalar products for gradients in same class: 27459.723484410006\n",
      "Sum of scalar products for gradients in different class: -25725.555311686145\n",
      "Loss: 0.0009167979005724192\n",
      "\n",
      "\n",
      "Iteration: 466\n",
      "Squared L2 Norm of Full Gradient: 1726.5273373854725\n",
      "Sum of scalar products for gradients in same class: 27346.201992768594\n",
      "Sum of scalar products for gradients in different class: -25619.67465538312\n",
      "Loss: 0.0009148683166131377\n",
      "\n",
      "\n",
      "Iteration: 467\n",
      "Squared L2 Norm of Full Gradient: 1718.9527172340458\n",
      "Sum of scalar products for gradients in same class: 27233.63100411803\n",
      "Sum of scalar products for gradients in different class: -25514.678286883984\n",
      "Loss: 0.0009129496174864471\n",
      "\n",
      "\n",
      "Iteration: 468\n",
      "Squared L2 Norm of Full Gradient: 1711.4304146161885\n",
      "Sum of scalar products for gradients in same class: 27121.851229884927\n",
      "Sum of scalar products for gradients in different class: -25410.42081526874\n",
      "Loss: 0.0009110464598052204\n",
      "\n",
      "\n",
      "Iteration: 469\n",
      "Squared L2 Norm of Full Gradient: 1703.9702725559473\n",
      "Sum of scalar products for gradients in same class: 27010.77672634474\n",
      "Sum of scalar products for gradients in different class: -25306.80645378879\n",
      "Loss: 0.0009091468527913094\n",
      "\n",
      "\n",
      "Iteration: 470\n",
      "Squared L2 Norm of Full Gradient: 1696.5283109256998\n",
      "Sum of scalar products for gradients in same class: 26900.2051200527\n",
      "Sum of scalar products for gradients in different class: -25203.676809127\n",
      "Loss: 0.0009072538232430816\n",
      "\n",
      "\n",
      "Iteration: 471\n",
      "Squared L2 Norm of Full Gradient: 1689.1443394747475\n",
      "Sum of scalar products for gradients in same class: 26790.3034332295\n",
      "Sum of scalar products for gradients in different class: -25101.15909375475\n",
      "Loss: 0.0009053740068338811\n",
      "\n",
      "\n",
      "Iteration: 472\n",
      "Squared L2 Norm of Full Gradient: 1681.8259070850909\n",
      "Sum of scalar products for gradients in same class: 26681.29823682524\n",
      "Sum of scalar products for gradients in different class: -24999.47232974015\n",
      "Loss: 0.0009034928516484797\n",
      "\n",
      "\n",
      "Iteration: 473\n",
      "Squared L2 Norm of Full Gradient: 1674.5505248364643\n",
      "Sum of scalar products for gradients in same class: 26572.990574173706\n",
      "Sum of scalar products for gradients in different class: -24898.44004933724\n",
      "Loss: 0.0009016299154609442\n",
      "\n",
      "\n",
      "Iteration: 474\n",
      "Squared L2 Norm of Full Gradient: 1667.3298540520627\n",
      "Sum of scalar products for gradients in same class: 26465.31581789945\n",
      "Sum of scalar products for gradients in different class: -24797.985963847386\n",
      "Loss: 0.00089977344032377\n",
      "\n",
      "\n",
      "Iteration: 475\n",
      "Squared L2 Norm of Full Gradient: 1660.1415710203\n",
      "Sum of scalar products for gradients in same class: 26358.247525282088\n",
      "Sum of scalar products for gradients in different class: -24698.105954261788\n",
      "Loss: 0.0008979187696240842\n",
      "\n",
      "\n",
      "Iteration: 476\n",
      "Squared L2 Norm of Full Gradient: 1653.0020068237209\n",
      "Sum of scalar products for gradients in same class: 26251.818349910725\n",
      "Sum of scalar products for gradients in different class: -24598.816343087004\n",
      "Loss: 0.0008960787672549486\n",
      "\n",
      "\n",
      "Iteration: 477\n",
      "Squared L2 Norm of Full Gradient: 1645.9131133267656\n",
      "Sum of scalar products for gradients in same class: 26146.132120172217\n",
      "Sum of scalar products for gradients in different class: -24500.21900684545\n",
      "Loss: 0.0008942456333898008\n",
      "\n",
      "\n",
      "Iteration: 478\n",
      "Squared L2 Norm of Full Gradient: 1638.8725007873873\n",
      "Sum of scalar products for gradients in same class: 26041.08964587651\n",
      "Sum of scalar products for gradients in different class: -24402.217145089122\n",
      "Loss: 0.0008924143621698022\n",
      "\n",
      "\n",
      "Iteration: 479\n",
      "Squared L2 Norm of Full Gradient: 1631.8855040958297\n",
      "Sum of scalar products for gradients in same class: 25936.827797015318\n",
      "Sum of scalar products for gradients in different class: -24304.942292919488\n",
      "Loss: 0.0008905958966352046\n",
      "\n",
      "\n",
      "Iteration: 480\n",
      "Squared L2 Norm of Full Gradient: 1624.927580038333\n",
      "Sum of scalar products for gradients in same class: 25832.806371870698\n",
      "Sum of scalar products for gradients in different class: -24207.878791832365\n",
      "Loss: 0.0008887872099876404\n",
      "\n",
      "\n",
      "Iteration: 481\n",
      "Squared L2 Norm of Full Gradient: 1618.0195062607672\n",
      "Sum of scalar products for gradients in same class: 25729.764009397393\n",
      "Sum of scalar products for gradients in different class: -24111.744503136626\n",
      "Loss: 0.0008869765442796052\n",
      "\n",
      "\n",
      "Iteration: 482\n",
      "Squared L2 Norm of Full Gradient: 1611.1677961988753\n",
      "Sum of scalar products for gradients in same class: 25627.36394283829\n",
      "Sum of scalar products for gradients in different class: -24016.196146639413\n",
      "Loss: 0.0008851847960613668\n",
      "\n",
      "\n",
      "Iteration: 483\n",
      "Squared L2 Norm of Full Gradient: 1604.3700453141355\n",
      "Sum of scalar products for gradients in same class: 25525.73704723697\n",
      "Sum of scalar products for gradients in different class: -23921.367001922834\n",
      "Loss: 0.0008833997417241335\n",
      "\n",
      "\n",
      "Iteration: 484\n",
      "Squared L2 Norm of Full Gradient: 1597.60740147451\n",
      "Sum of scalar products for gradients in same class: 25424.696409001197\n",
      "Sum of scalar products for gradients in different class: -23827.089007526687\n",
      "Loss: 0.0008816205663606524\n",
      "\n",
      "\n",
      "Iteration: 485\n",
      "Squared L2 Norm of Full Gradient: 1590.8785159348045\n",
      "Sum of scalar products for gradients in same class: 25323.96743077728\n",
      "Sum of scalar products for gradients in different class: -23733.088914842476\n",
      "Loss: 0.0008798466296866536\n",
      "\n",
      "\n",
      "Iteration: 486\n",
      "Squared L2 Norm of Full Gradient: 1584.195108166954\n",
      "Sum of scalar products for gradients in same class: 25223.970403550866\n",
      "Sum of scalar products for gradients in different class: -23639.77529538391\n",
      "Loss: 0.0008780781645327806\n",
      "\n",
      "\n",
      "Iteration: 487\n",
      "Squared L2 Norm of Full Gradient: 1577.550919897054\n",
      "Sum of scalar products for gradients in same class: 25124.618422896674\n",
      "Sum of scalar products for gradients in different class: -23547.06750299962\n",
      "Loss: 0.0008763226796872914\n",
      "\n",
      "\n",
      "Iteration: 488\n",
      "Squared L2 Norm of Full Gradient: 1570.9485139288008\n",
      "Sum of scalar products for gradients in same class: 25025.75352343894\n",
      "Sum of scalar products for gradients in different class: -23454.80500951014\n",
      "Loss: 0.0008745701052248478\n",
      "\n",
      "\n",
      "Iteration: 489\n",
      "Squared L2 Norm of Full Gradient: 1564.3967678875342\n",
      "Sum of scalar products for gradients in same class: 24927.62225272034\n",
      "Sum of scalar products for gradients in different class: -23363.225484832805\n",
      "Loss: 0.0008728262037038803\n",
      "\n",
      "\n",
      "Iteration: 490\n",
      "Squared L2 Norm of Full Gradient: 1557.89514960839\n",
      "Sum of scalar products for gradients in same class: 24830.188315830535\n",
      "Sum of scalar products for gradients in different class: -23272.293166222145\n",
      "Loss: 0.0008710898691788316\n",
      "\n",
      "\n",
      "Iteration: 491\n",
      "Squared L2 Norm of Full Gradient: 1551.4208931097673\n",
      "Sum of scalar products for gradients in same class: 24733.169101916938\n",
      "Sum of scalar products for gradients in different class: -23181.74820880717\n",
      "Loss: 0.0008693629642948508\n",
      "\n",
      "\n",
      "Iteration: 492\n",
      "Squared L2 Norm of Full Gradient: 1544.9934043549583\n",
      "Sum of scalar products for gradients in same class: 24636.804080424896\n",
      "Sum of scalar products for gradients in different class: -23091.810676069937\n",
      "Loss: 0.0008676390862092376\n",
      "\n",
      "\n",
      "Iteration: 493\n",
      "Squared L2 Norm of Full Gradient: 1538.6058920333162\n",
      "Sum of scalar products for gradients in same class: 24541.094585251856\n",
      "Sum of scalar products for gradients in different class: -23002.48869321854\n",
      "Loss: 0.000865927548147738\n",
      "\n",
      "\n",
      "Iteration: 494\n",
      "Squared L2 Norm of Full Gradient: 1532.2641633743333\n",
      "Sum of scalar products for gradients in same class: 24445.88398006292\n",
      "Sum of scalar products for gradients in different class: -22913.619816688588\n",
      "Loss: 0.0008642164757475257\n",
      "\n",
      "\n",
      "Iteration: 495\n",
      "Squared L2 Norm of Full Gradient: 1525.9510287223966\n",
      "Sum of scalar products for gradients in same class: 24351.2619073392\n",
      "Sum of scalar products for gradients in different class: -22825.310878616805\n",
      "Loss: 0.0008625144837424159\n",
      "\n",
      "\n",
      "Iteration: 496\n",
      "Squared L2 Norm of Full Gradient: 1519.682155086717\n",
      "Sum of scalar products for gradients in same class: 24257.093035162692\n",
      "Sum of scalar products for gradients in different class: -22737.410880075975\n",
      "Loss: 0.0008608209900557995\n",
      "\n",
      "\n",
      "Iteration: 497\n",
      "Squared L2 Norm of Full Gradient: 1513.4564590090886\n",
      "Sum of scalar products for gradients in same class: 24163.58342432682\n",
      "Sum of scalar products for gradients in different class: -22650.12696531773\n",
      "Loss: 0.0008591376827098429\n",
      "\n",
      "\n",
      "Iteration: 498\n",
      "Squared L2 Norm of Full Gradient: 1507.268126069117\n",
      "Sum of scalar products for gradients in same class: 24070.669165328483\n",
      "Sum of scalar products for gradients in different class: -22563.401039259366\n",
      "Loss: 0.0008574534440413117\n",
      "\n",
      "\n",
      "Iteration: 499\n",
      "Squared L2 Norm of Full Gradient: 1501.1240993103856\n",
      "Sum of scalar products for gradients in same class: 23978.312723438507\n",
      "Sum of scalar products for gradients in different class: -22477.18862412812\n",
      "Loss: 0.0008557790424674749\n",
      "\n",
      "\n",
      "Iteration: 500\n",
      "Squared L2 Norm of Full Gradient: 1495.0097300444177\n",
      "Sum of scalar products for gradients in same class: 23886.43202746876\n",
      "Sum of scalar products for gradients in different class: -22391.422297424342\n",
      "Loss: 0.0008541152928955853\n",
      "\n",
      "\n",
      "Iteration: 501\n",
      "Squared L2 Norm of Full Gradient: 1488.9296236954542\n",
      "Sum of scalar products for gradients in same class: 23794.969198405546\n",
      "Sum of scalar products for gradients in different class: -22306.039574710092\n",
      "Loss: 0.0008524574805051088\n",
      "\n",
      "\n",
      "Iteration: 502\n",
      "Squared L2 Norm of Full Gradient: 1482.90568162594\n",
      "Sum of scalar products for gradients in same class: 23704.432868044583\n",
      "Sum of scalar products for gradients in different class: -22221.527186418643\n",
      "Loss: 0.000850799900945276\n",
      "\n",
      "\n",
      "Iteration: 503\n",
      "Squared L2 Norm of Full Gradient: 1476.8898453598522\n",
      "Sum of scalar products for gradients in same class: 23613.947844330476\n",
      "Sum of scalar products for gradients in different class: -22137.057998970624\n",
      "Loss: 0.0008491571643389761\n",
      "\n",
      "\n",
      "Iteration: 504\n",
      "Squared L2 Norm of Full Gradient: 1470.949146838524\n",
      "Sum of scalar products for gradients in same class: 23524.48009122161\n",
      "Sum of scalar products for gradients in different class: -22053.530944383085\n",
      "Loss: 0.0008475204231217504\n",
      "\n",
      "\n",
      "Iteration: 505\n",
      "Squared L2 Norm of Full Gradient: 1465.013411994456\n",
      "Sum of scalar products for gradients in same class: 23435.182493635733\n",
      "Sum of scalar products for gradients in different class: -21970.169081641277\n",
      "Loss: 0.0008458859520033002\n",
      "\n",
      "\n",
      "Iteration: 506\n",
      "Squared L2 Norm of Full Gradient: 1459.1398036609316\n",
      "Sum of scalar products for gradients in same class: 23346.811703518706\n",
      "Sum of scalar products for gradients in different class: -21887.671899857774\n",
      "Loss: 0.0008442612597718835\n",
      "\n",
      "\n",
      "Iteration: 507\n",
      "Squared L2 Norm of Full Gradient: 1453.2884638855612\n",
      "Sum of scalar products for gradients in same class: 23258.58137337223\n",
      "Sum of scalar products for gradients in different class: -21805.29290948667\n",
      "Loss: 0.0008426434942521155\n",
      "\n",
      "\n",
      "Iteration: 508\n",
      "Squared L2 Norm of Full Gradient: 1447.4616516094102\n",
      "Sum of scalar products for gradients in same class: 23170.840669005152\n",
      "Sum of scalar products for gradients in different class: -21723.379017395742\n",
      "Loss: 0.0008410267764702439\n",
      "\n",
      "\n",
      "Iteration: 509\n",
      "Squared L2 Norm of Full Gradient: 1441.6894168680446\n",
      "Sum of scalar products for gradients in same class: 23083.784555104306\n",
      "Sum of scalar products for gradients in different class: -21642.095138236262\n",
      "Loss: 0.0008394212345592678\n",
      "\n",
      "\n",
      "Iteration: 510\n",
      "Squared L2 Norm of Full Gradient: 1435.9373876669124\n",
      "Sum of scalar products for gradients in same class: 22997.103376875\n",
      "Sum of scalar products for gradients in different class: -21561.165989208086\n",
      "Loss: 0.0008378208731301129\n",
      "\n",
      "\n",
      "Iteration: 511\n",
      "Squared L2 Norm of Full Gradient: 1430.229171410334\n",
      "Sum of scalar products for gradients in same class: 22910.956456375327\n",
      "Sum of scalar products for gradients in different class: -21480.727284964993\n",
      "Loss: 0.0008362251683138311\n",
      "\n",
      "\n",
      "Iteration: 512\n",
      "Squared L2 Norm of Full Gradient: 1424.5504648564965\n",
      "Sum of scalar products for gradients in same class: 22825.375215716922\n",
      "Sum of scalar products for gradients in different class: -21400.824750860425\n",
      "Loss: 0.0008346393587999046\n",
      "\n",
      "\n",
      "Iteration: 513\n",
      "Squared L2 Norm of Full Gradient: 1418.9057578230277\n",
      "Sum of scalar products for gradients in same class: 22740.152296171298\n",
      "Sum of scalar products for gradients in different class: -21321.24653834827\n",
      "Loss: 0.0008330539567396045\n",
      "\n",
      "\n",
      "Iteration: 514\n",
      "Squared L2 Norm of Full Gradient: 1413.3026590629015\n",
      "Sum of scalar products for gradients in same class: 22655.57166106697\n",
      "Sum of scalar products for gradients in different class: -21242.269002004068\n",
      "Loss: 0.000831478857435286\n",
      "\n",
      "\n",
      "Iteration: 515\n",
      "Squared L2 Norm of Full Gradient: 1407.7366941495711\n",
      "Sum of scalar products for gradients in same class: 22571.552760392045\n",
      "Sum of scalar products for gradients in different class: -21163.816066242474\n",
      "Loss: 0.0008299116743728518\n",
      "\n",
      "\n",
      "Iteration: 516\n",
      "Squared L2 Norm of Full Gradient: 1402.1979952744587\n",
      "Sum of scalar products for gradients in same class: 22487.928216395037\n",
      "Sum of scalar products for gradients in different class: -21085.73022112058\n",
      "Loss: 0.0008283486822620034\n",
      "\n",
      "\n",
      "Iteration: 517\n",
      "Squared L2 Norm of Full Gradient: 1396.6978711823467\n",
      "Sum of scalar products for gradients in same class: 22404.78310566227\n",
      "Sum of scalar products for gradients in different class: -21008.085234479924\n",
      "Loss: 0.0008267918019555509\n",
      "\n",
      "\n",
      "Iteration: 518\n",
      "Squared L2 Norm of Full Gradient: 1391.227621548809\n",
      "Sum of scalar products for gradients in same class: 22322.114153729308\n",
      "Sum of scalar products for gradients in different class: -20930.8865321805\n",
      "Loss: 0.0008252431871369481\n",
      "\n",
      "\n",
      "Iteration: 519\n",
      "Squared L2 Norm of Full Gradient: 1385.7800337151275\n",
      "Sum of scalar products for gradients in same class: 22239.67480467312\n",
      "Sum of scalar products for gradients in different class: -20853.89477095799\n",
      "Loss: 0.0008236988796852529\n",
      "\n",
      "\n",
      "Iteration: 520\n",
      "Squared L2 Norm of Full Gradient: 1380.3839500641916\n",
      "Sum of scalar products for gradients in same class: 22158.15626789434\n",
      "Sum of scalar products for gradients in different class: -20777.77231783015\n",
      "Loss: 0.0008221562602557242\n",
      "\n",
      "\n",
      "Iteration: 521\n",
      "Squared L2 Norm of Full Gradient: 1375.011406489648\n",
      "Sum of scalar products for gradients in same class: 22076.822386670567\n",
      "Sum of scalar products for gradients in different class: -20701.81098018092\n",
      "Loss: 0.0008206332568079233\n",
      "\n",
      "\n",
      "Iteration: 522\n",
      "Squared L2 Norm of Full Gradient: 1369.659503236413\n",
      "Sum of scalar products for gradients in same class: 21995.82916082735\n",
      "Sum of scalar products for gradients in different class: -20626.169657590937\n",
      "Loss: 0.0008190979715436697\n",
      "\n",
      "\n",
      "Iteration: 523\n",
      "Squared L2 Norm of Full Gradient: 1364.3634067021922\n",
      "Sum of scalar products for gradients in same class: 21915.603496719454\n",
      "Sum of scalar products for gradients in different class: -20551.24009001726\n",
      "Loss: 0.0008175807306542993\n",
      "\n",
      "\n",
      "Iteration: 524\n",
      "Squared L2 Norm of Full Gradient: 1359.080663178247\n",
      "Sum of scalar products for gradients in same class: 21835.6633085776\n",
      "Sum of scalar products for gradients in different class: -20476.582645399354\n",
      "Loss: 0.0008160703582689166\n",
      "\n",
      "\n",
      "Iteration: 525\n",
      "Squared L2 Norm of Full Gradient: 1353.8351157163415\n",
      "Sum of scalar products for gradients in same class: 21756.214115349045\n",
      "Sum of scalar products for gradients in different class: -20402.378999632703\n",
      "Loss: 0.0008145553874783218\n",
      "\n",
      "\n",
      "Iteration: 526\n",
      "Squared L2 Norm of Full Gradient: 1348.6221249791706\n",
      "Sum of scalar products for gradients in same class: 21677.277070250006\n",
      "Sum of scalar products for gradients in different class: -20328.654945270835\n",
      "Loss: 0.0008130537462420762\n",
      "\n",
      "\n",
      "Iteration: 527\n",
      "Squared L2 Norm of Full Gradient: 1343.4253420536552\n",
      "Sum of scalar products for gradients in same class: 21598.495936324078\n",
      "Sum of scalar products for gradients in different class: -20255.070594270423\n",
      "Loss: 0.0008115566452033818\n",
      "\n",
      "\n",
      "Iteration: 528\n",
      "Squared L2 Norm of Full Gradient: 1338.2785024354234\n",
      "Sum of scalar products for gradients in same class: 21520.52067181508\n",
      "Sum of scalar products for gradients in different class: -20182.242169379657\n",
      "Loss: 0.0008100669365376234\n",
      "\n",
      "\n",
      "Iteration: 529\n",
      "Squared L2 Norm of Full Gradient: 1333.1576977394434\n",
      "Sum of scalar products for gradients in same class: 21442.908768897665\n",
      "Sum of scalar products for gradients in different class: -20109.75107115822\n",
      "Loss: 0.0008085791487246752\n",
      "\n",
      "\n",
      "Iteration: 530\n",
      "Squared L2 Norm of Full Gradient: 1328.0508794883644\n",
      "Sum of scalar products for gradients in same class: 21365.475113953034\n",
      "Sum of scalar products for gradients in different class: -20037.42423446467\n",
      "Loss: 0.0008071009069681168\n",
      "\n",
      "\n",
      "Iteration: 531\n",
      "Squared L2 Norm of Full Gradient: 1322.9935438978137\n",
      "Sum of scalar products for gradients in same class: 21288.65577685285\n",
      "Sum of scalar products for gradients in different class: -19965.662232955037\n",
      "Loss: 0.0008056241786107421\n",
      "\n",
      "\n",
      "Iteration: 532\n",
      "Squared L2 Norm of Full Gradient: 1317.96579827393\n",
      "Sum of scalar products for gradients in same class: 21212.311719462632\n",
      "Sum of scalar products for gradients in different class: -19894.345921188702\n",
      "Loss: 0.00080415781121701\n",
      "\n",
      "\n",
      "Iteration: 533\n",
      "Squared L2 Norm of Full Gradient: 1312.9517709924985\n",
      "Sum of scalar products for gradients in same class: 21136.275965250985\n",
      "Sum of scalar products for gradients in different class: -19823.324194258486\n",
      "Loss: 0.0008026966243050992\n",
      "\n",
      "\n",
      "Iteration: 534\n",
      "Squared L2 Norm of Full Gradient: 1307.9809621125605\n",
      "Sum of scalar products for gradients in same class: 21060.71274582351\n",
      "Sum of scalar products for gradients in different class: -19752.73178371095\n",
      "Loss: 0.0008012360776774585\n",
      "\n",
      "\n",
      "Iteration: 535\n",
      "Squared L2 Norm of Full Gradient: 1303.0264658129308\n",
      "Sum of scalar products for gradients in same class: 20985.535519803623\n",
      "Sum of scalar products for gradients in different class: -19682.509053990692\n",
      "Loss: 0.000799784786067903\n",
      "\n",
      "\n",
      "Iteration: 536\n",
      "Squared L2 Norm of Full Gradient: 1298.1110579521774\n",
      "Sum of scalar products for gradients in same class: 20910.78011278107\n",
      "Sum of scalar products for gradients in different class: -19612.669054828893\n",
      "Loss: 0.0007983357645571232\n",
      "\n",
      "\n",
      "Iteration: 537\n",
      "Squared L2 Norm of Full Gradient: 1293.2268878608593\n",
      "Sum of scalar products for gradients in same class: 20836.64651507415\n",
      "Sum of scalar products for gradients in different class: -19543.41962721329\n",
      "Loss: 0.0007969007128849626\n",
      "\n",
      "\n",
      "Iteration: 538\n",
      "Squared L2 Norm of Full Gradient: 1288.3672589466587\n",
      "Sum of scalar products for gradients in same class: 20762.71269270056\n",
      "Sum of scalar products for gradients in different class: -19474.3454337539\n",
      "Loss: 0.0007954639731906354\n",
      "\n",
      "\n",
      "Iteration: 539\n",
      "Squared L2 Norm of Full Gradient: 1283.5372778732708\n",
      "Sum of scalar products for gradients in same class: 20689.265363810162\n",
      "Sum of scalar products for gradients in different class: -19405.72808593689\n",
      "Loss: 0.0007940322393551469\n",
      "\n",
      "\n",
      "Iteration: 540\n",
      "Squared L2 Norm of Full Gradient: 1278.7256433256116\n",
      "Sum of scalar products for gradients in same class: 20616.072799785856\n",
      "Sum of scalar products for gradients in different class: -19337.347156460244\n",
      "Loss: 0.0007926070829853415\n",
      "\n",
      "\n",
      "Iteration: 541\n",
      "Squared L2 Norm of Full Gradient: 1273.9513647534332\n",
      "Sum of scalar products for gradients in same class: 20543.418597902702\n",
      "Sum of scalar products for gradients in different class: -19269.46723314927\n",
      "Loss: 0.0007911925204098225\n",
      "\n",
      "\n",
      "Iteration: 542\n",
      "Squared L2 Norm of Full Gradient: 1269.1909079763718\n",
      "Sum of scalar products for gradients in same class: 20471.034361430426\n",
      "Sum of scalar products for gradients in different class: -19201.843453454054\n",
      "Loss: 0.0007897742907516658\n",
      "\n",
      "\n",
      "Iteration: 543\n",
      "Squared L2 Norm of Full Gradient: 1264.4624222463463\n",
      "Sum of scalar products for gradients in same class: 20398.987975657557\n",
      "Sum of scalar products for gradients in different class: -19134.52555341121\n",
      "Loss: 0.0007883670623414218\n",
      "\n",
      "\n",
      "Iteration: 544\n",
      "Squared L2 Norm of Full Gradient: 1259.7785055643326\n",
      "Sum of scalar products for gradients in same class: 20327.595703051975\n",
      "Sum of scalar products for gradients in different class: -19067.817197487642\n",
      "Loss: 0.0007869607070460916\n",
      "\n",
      "\n",
      "Iteration: 545\n",
      "Squared L2 Norm of Full Gradient: 1255.0932795392728\n",
      "Sum of scalar products for gradients in same class: 20256.26409449302\n",
      "Sum of scalar products for gradients in different class: -19001.170814953748\n",
      "Loss: 0.0007855611620470881\n",
      "\n",
      "\n",
      "Iteration: 546\n",
      "Squared L2 Norm of Full Gradient: 1250.4623761810362\n",
      "Sum of scalar products for gradients in same class: 20185.691479758672\n",
      "Sum of scalar products for gradients in different class: -18935.229103577636\n",
      "Loss: 0.0007841702317818999\n",
      "\n",
      "\n",
      "Iteration: 547\n",
      "Squared L2 Norm of Full Gradient: 1245.8524193149206\n",
      "Sum of scalar products for gradients in same class: 20115.479658331962\n",
      "Sum of scalar products for gradients in different class: -18869.62723901704\n",
      "Loss: 0.0007827841327525675\n",
      "\n",
      "\n",
      "Iteration: 548\n",
      "Squared L2 Norm of Full Gradient: 1241.2558139862958\n",
      "Sum of scalar products for gradients in same class: 20045.274874786803\n",
      "Sum of scalar products for gradients in different class: -18804.019060800507\n",
      "Loss: 0.0007813996635377407\n",
      "\n",
      "\n",
      "Iteration: 549\n",
      "Squared L2 Norm of Full Gradient: 1236.6856799810776\n",
      "Sum of scalar products for gradients in same class: 19975.760898385288\n",
      "Sum of scalar products for gradients in different class: -18739.07521840421\n",
      "Loss: 0.0007800246821716428\n",
      "\n",
      "\n",
      "Iteration: 550\n",
      "Squared L2 Norm of Full Gradient: 1232.149951941814\n",
      "Sum of scalar products for gradients in same class: 19906.440381841512\n",
      "Sum of scalar products for gradients in different class: -18674.2904298997\n",
      "Loss: 0.0007786512142047286\n",
      "\n",
      "\n",
      "Iteration: 551\n",
      "Squared L2 Norm of Full Gradient: 1227.6401997381472\n",
      "Sum of scalar products for gradients in same class: 19837.676280122003\n",
      "Sum of scalar products for gradients in different class: -18610.036080383856\n",
      "Loss: 0.0007772836252115667\n",
      "\n",
      "\n",
      "Iteration: 552\n",
      "Squared L2 Norm of Full Gradient: 1223.151256519428\n",
      "Sum of scalar products for gradients in same class: 19769.116302365015\n",
      "Sum of scalar products for gradients in different class: -18545.965045845587\n",
      "Loss: 0.0007759192958474159\n",
      "\n",
      "\n",
      "Iteration: 553\n",
      "Squared L2 Norm of Full Gradient: 1218.683852330083\n",
      "Sum of scalar products for gradients in same class: 19700.894156073213\n",
      "Sum of scalar products for gradients in different class: -18482.21030374313\n",
      "Loss: 0.000774562475271523\n",
      "\n",
      "\n",
      "Iteration: 554\n",
      "Squared L2 Norm of Full Gradient: 1214.240838399288\n",
      "Sum of scalar products for gradients in same class: 19633.162034824047\n",
      "Sum of scalar products for gradients in different class: -18418.92119642476\n",
      "Loss: 0.0007732080412097275\n",
      "\n",
      "\n",
      "Iteration: 555\n",
      "Squared L2 Norm of Full Gradient: 1209.8330059684813\n",
      "Sum of scalar products for gradients in same class: 19565.710231880203\n",
      "Sum of scalar products for gradients in different class: -18355.87722591172\n",
      "Loss: 0.0007718603010289371\n",
      "\n",
      "\n",
      "Iteration: 556\n",
      "Squared L2 Norm of Full Gradient: 1205.4482871997752\n",
      "Sum of scalar products for gradients in same class: 19498.737728888012\n",
      "Sum of scalar products for gradients in different class: -18293.289441688237\n",
      "Loss: 0.0007705157622694969\n",
      "\n",
      "\n",
      "Iteration: 557\n",
      "Squared L2 Norm of Full Gradient: 1201.0794607387506\n",
      "Sum of scalar products for gradients in same class: 19431.98197618224\n",
      "Sum of scalar products for gradients in different class: -18230.90251544349\n",
      "Loss: 0.0007691781502217054\n",
      "\n",
      "\n",
      "Iteration: 558\n",
      "Squared L2 Norm of Full Gradient: 1196.7301783576258\n",
      "Sum of scalar products for gradients in same class: 19365.46585581186\n",
      "Sum of scalar products for gradients in different class: -18168.735677454235\n",
      "Loss: 0.0007678428082726896\n",
      "\n",
      "\n",
      "Iteration: 559\n",
      "Squared L2 Norm of Full Gradient: 1192.4053823955037\n",
      "Sum of scalar products for gradients in same class: 19299.288421092857\n",
      "Sum of scalar products for gradients in different class: -18106.883038697353\n",
      "Loss: 0.0007665136945433915\n",
      "\n",
      "\n",
      "Iteration: 560\n",
      "Squared L2 Norm of Full Gradient: 1188.1275987514673\n",
      "Sum of scalar products for gradients in same class: 19233.913195758774\n",
      "Sum of scalar products for gradients in different class: -18045.785597007307\n",
      "Loss: 0.0007651900523342192\n",
      "\n",
      "\n",
      "Iteration: 561\n",
      "Squared L2 Norm of Full Gradient: 1183.8475270097988\n",
      "Sum of scalar products for gradients in same class: 19168.492576443718\n",
      "Sum of scalar products for gradients in different class: -17984.64504943392\n",
      "Loss: 0.0007638680399395525\n",
      "\n",
      "\n",
      "Iteration: 562\n",
      "Squared L2 Norm of Full Gradient: 1179.6155315187207\n",
      "Sum of scalar products for gradients in same class: 19103.619036501106\n",
      "Sum of scalar products for gradients in different class: -17924.003504982385\n",
      "Loss: 0.0007625594735145569\n",
      "\n",
      "\n",
      "Iteration: 563\n",
      "Squared L2 Norm of Full Gradient: 1175.3937294677744\n",
      "Sum of scalar products for gradients in same class: 19039.01798500479\n",
      "Sum of scalar products for gradients in different class: -17863.624255537015\n",
      "Loss: 0.000761251721996814\n",
      "\n",
      "\n",
      "Iteration: 564\n",
      "Squared L2 Norm of Full Gradient: 1171.190200805664\n",
      "Sum of scalar products for gradients in same class: 18974.660172714728\n",
      "Sum of scalar products for gradients in different class: -17803.469971909064\n",
      "Loss: 0.0007599456002935767\n",
      "\n",
      "\n",
      "Iteration: 565\n",
      "Squared L2 Norm of Full Gradient: 1167.0061911081575\n",
      "Sum of scalar products for gradients in same class: 18910.581693118882\n",
      "Sum of scalar products for gradients in different class: -17743.575502010724\n",
      "Loss: 0.0007586444262415171\n",
      "\n",
      "\n",
      "Iteration: 566\n",
      "Squared L2 Norm of Full Gradient: 1162.8595874732273\n",
      "Sum of scalar products for gradients in same class: 18847.082244615678\n",
      "Sum of scalar products for gradients in different class: -17684.22265714245\n",
      "Loss: 0.0007573505863547325\n",
      "\n",
      "\n",
      "Iteration: 567\n",
      "Squared L2 Norm of Full Gradient: 1158.7341281832778\n",
      "Sum of scalar products for gradients in same class: 18783.898754608188\n",
      "Sum of scalar products for gradients in different class: -17625.16462642491\n",
      "Loss: 0.0007560623926110566\n",
      "\n",
      "\n",
      "Iteration: 568\n",
      "Squared L2 Norm of Full Gradient: 1154.62792507642\n",
      "Sum of scalar products for gradients in same class: 18720.941595343676\n",
      "Sum of scalar products for gradients in different class: -17566.313670267256\n",
      "Loss: 0.0007547734421677887\n",
      "\n",
      "\n",
      "Iteration: 569\n",
      "Squared L2 Norm of Full Gradient: 1150.545831537238\n",
      "Sum of scalar products for gradients in same class: 18658.335790810168\n",
      "Sum of scalar products for gradients in different class: -17507.78995927293\n",
      "Loss: 0.0007534928736276925\n",
      "\n",
      "\n",
      "Iteration: 570\n",
      "Squared L2 Norm of Full Gradient: 1146.4743250050233\n",
      "Sum of scalar products for gradients in same class: 18595.821682213234\n",
      "Sum of scalar products for gradients in different class: -17449.34735720821\n",
      "Loss: 0.0007522107334807515\n",
      "\n",
      "\n",
      "Iteration: 571\n",
      "Squared L2 Norm of Full Gradient: 1142.431696487256\n",
      "Sum of scalar products for gradients in same class: 18533.828230213472\n",
      "Sum of scalar products for gradients in different class: -17391.396533726216\n",
      "Loss: 0.0007509394199587405\n",
      "\n",
      "\n",
      "Iteration: 572\n",
      "Squared L2 Norm of Full Gradient: 1138.411138219817\n",
      "Sum of scalar products for gradients in same class: 18472.117940199063\n",
      "Sum of scalar products for gradients in different class: -17333.706801979246\n",
      "Loss: 0.0007496719481423497\n",
      "\n",
      "\n",
      "Iteration: 573\n",
      "Squared L2 Norm of Full Gradient: 1134.4143699403503\n",
      "Sum of scalar products for gradients in same class: 18410.75945073092\n",
      "Sum of scalar products for gradients in different class: -17276.34508079057\n",
      "Loss: 0.0007484088419005275\n",
      "\n",
      "\n",
      "Iteration: 574\n",
      "Squared L2 Norm of Full Gradient: 1130.4407904240215\n",
      "Sum of scalar products for gradients in same class: 18349.815284817763\n",
      "Sum of scalar products for gradients in different class: -17219.37449439374\n",
      "Loss: 0.0007471517892554402\n",
      "\n",
      "\n",
      "Iteration: 575\n",
      "Squared L2 Norm of Full Gradient: 1126.4795597446064\n",
      "Sum of scalar products for gradients in same class: 18289.047098483057\n",
      "Sum of scalar products for gradients in different class: -17162.56753873845\n",
      "Loss: 0.0007458938052877784\n",
      "\n",
      "\n",
      "Iteration: 576\n",
      "Squared L2 Norm of Full Gradient: 1122.552121466084\n",
      "Sum of scalar products for gradients in same class: 18228.662841151952\n",
      "Sum of scalar products for gradients in different class: -17106.11071968587\n",
      "Loss: 0.0007446453091688454\n",
      "\n",
      "\n",
      "Iteration: 577\n",
      "Squared L2 Norm of Full Gradient: 1118.6312864260399\n",
      "Sum of scalar products for gradients in same class: 18168.418061533164\n",
      "Sum of scalar products for gradients in different class: -17049.786775107124\n",
      "Loss: 0.0007434005965478718\n",
      "\n",
      "\n",
      "Iteration: 578\n",
      "Squared L2 Norm of Full Gradient: 1114.737943552449\n",
      "Sum of scalar products for gradients in same class: 18108.585684515674\n",
      "Sum of scalar products for gradients in different class: -16993.847740963225\n",
      "Loss: 0.0007421551854349673\n",
      "\n",
      "\n",
      "Iteration: 579\n",
      "Squared L2 Norm of Full Gradient: 1110.8699505599361\n",
      "Sum of scalar products for gradients in same class: 18049.14832061713\n",
      "Sum of scalar products for gradients in different class: -16938.278370057193\n",
      "Loss: 0.0007409182144328952\n",
      "\n",
      "\n",
      "Iteration: 580\n",
      "Squared L2 Norm of Full Gradient: 1107.0203567664284\n",
      "Sum of scalar products for gradients in same class: 17989.99694948766\n",
      "Sum of scalar products for gradients in different class: -16882.976592721232\n",
      "Loss: 0.0007396888104267418\n",
      "\n",
      "\n",
      "Iteration: 581\n",
      "Squared L2 Norm of Full Gradient: 1103.1868206733488\n",
      "Sum of scalar products for gradients in same class: 17931.006726987507\n",
      "Sum of scalar products for gradients in different class: -16827.81990631416\n",
      "Loss: 0.0007384549826383591\n",
      "\n",
      "\n",
      "Iteration: 582\n",
      "Squared L2 Norm of Full Gradient: 1099.3773883730173\n",
      "Sum of scalar products for gradients in same class: 17872.452416488733\n",
      "Sum of scalar products for gradients in different class: -16773.075028115716\n",
      "Loss: 0.0007372307009063661\n",
      "\n",
      "\n",
      "Iteration: 583\n",
      "Squared L2 Norm of Full Gradient: 1095.5886863219202\n",
      "Sum of scalar products for gradients in same class: 17814.117592565588\n",
      "Sum of scalar products for gradients in different class: -16718.528906243668\n",
      "Loss: 0.0007360059535130858\n",
      "\n",
      "\n",
      "Iteration: 584\n",
      "Squared L2 Norm of Full Gradient: 1091.8213975150284\n",
      "Sum of scalar products for gradients in same class: 17756.13929019626\n",
      "Sum of scalar products for gradients in different class: -16664.317892681232\n",
      "Loss: 0.0007347920327447355\n",
      "\n",
      "\n",
      "Iteration: 585\n",
      "Squared L2 Norm of Full Gradient: 1088.070663443068\n",
      "Sum of scalar products for gradients in same class: 17698.462482018927\n",
      "Sum of scalar products for gradients in different class: -16610.39181857586\n",
      "Loss: 0.0007335823029279709\n",
      "\n",
      "\n",
      "Iteration: 586\n",
      "Squared L2 Norm of Full Gradient: 1084.3304025798716\n",
      "Sum of scalar products for gradients in same class: 17640.84496988045\n",
      "Sum of scalar products for gradients in different class: -16556.51456730058\n",
      "Loss: 0.0007323695463128388\n",
      "\n",
      "\n",
      "Iteration: 587\n",
      "Squared L2 Norm of Full Gradient: 1080.6201564150397\n",
      "Sum of scalar products for gradients in same class: 17583.68201333927\n",
      "Sum of scalar products for gradients in different class: -16503.06185692423\n",
      "Loss: 0.0007311696535907686\n",
      "\n",
      "\n",
      "Iteration: 588\n",
      "Squared L2 Norm of Full Gradient: 1076.9322924893495\n",
      "Sum of scalar products for gradients in same class: 17526.918023100556\n",
      "Sum of scalar products for gradients in different class: -16449.985730611206\n",
      "Loss: 0.0007299687713384628\n",
      "\n",
      "\n",
      "Iteration: 589\n",
      "Squared L2 Norm of Full Gradient: 1073.254481310505\n",
      "Sum of scalar products for gradients in same class: 17470.143086972126\n",
      "Sum of scalar products for gradients in different class: -16396.88860566162\n",
      "Loss: 0.0007287744083441794\n",
      "\n",
      "\n",
      "Iteration: 590\n",
      "Squared L2 Norm of Full Gradient: 1069.6051678734366\n",
      "Sum of scalar products for gradients in same class: 17413.928048860274\n",
      "Sum of scalar products for gradients in different class: -16344.322880986838\n",
      "Loss: 0.0007275841780938208\n",
      "\n",
      "\n",
      "Iteration: 591\n",
      "Squared L2 Norm of Full Gradient: 1065.9787585358717\n",
      "Sum of scalar products for gradients in same class: 17358.038661714574\n",
      "Sum of scalar products for gradients in different class: -16292.059903178702\n",
      "Loss: 0.0007263926672749221\n",
      "\n",
      "\n",
      "Iteration: 592\n",
      "Squared L2 Norm of Full Gradient: 1062.3599991929368\n",
      "Sum of scalar products for gradients in same class: 17302.236330689215\n",
      "Sum of scalar products for gradients in different class: -16239.876331496278\n",
      "Loss: 0.0007252107025124133\n",
      "\n",
      "\n",
      "Iteration: 593\n",
      "Squared L2 Norm of Full Gradient: 1058.7605499371566\n",
      "Sum of scalar products for gradients in same class: 17246.749164719702\n",
      "Sum of scalar products for gradients in different class: -16187.988614782545\n",
      "Loss: 0.0007240303093567491\n",
      "\n",
      "\n",
      "Iteration: 594\n",
      "Squared L2 Norm of Full Gradient: 1055.180095900083\n",
      "Sum of scalar products for gradients in same class: 17191.5156972105\n",
      "Sum of scalar products for gradients in different class: -16136.335601310417\n",
      "Loss: 0.0007228539325296879\n",
      "\n",
      "\n",
      "Iteration: 595\n",
      "Squared L2 Norm of Full Gradient: 1051.6227775370353\n",
      "Sum of scalar products for gradients in same class: 17136.655614133913\n",
      "Sum of scalar products for gradients in different class: -16085.032836596878\n",
      "Loss: 0.0007216837839223444\n",
      "\n",
      "\n",
      "Iteration: 596\n",
      "Squared L2 Norm of Full Gradient: 1048.083321400918\n",
      "Sum of scalar products for gradients in same class: 17081.96555396088\n",
      "Sum of scalar products for gradients in different class: -16033.882232559961\n",
      "Loss: 0.0007205157307907939\n",
      "\n",
      "\n",
      "Iteration: 597\n",
      "Squared L2 Norm of Full Gradient: 1044.5596948499442\n",
      "Sum of scalar products for gradients in same class: 17027.6036232845\n",
      "Sum of scalar products for gradients in different class: -15983.043928434556\n",
      "Loss: 0.0007193574565462768\n",
      "\n",
      "\n",
      "Iteration: 598\n",
      "Squared L2 Norm of Full Gradient: 1041.0567713240162\n",
      "Sum of scalar products for gradients in same class: 16973.468463257705\n",
      "Sum of scalar products for gradients in different class: -15932.411691933688\n",
      "Loss: 0.0007181985420174897\n",
      "\n",
      "\n",
      "Iteration: 599\n",
      "Squared L2 Norm of Full Gradient: 1037.563663213572\n",
      "Sum of scalar products for gradients in same class: 16919.541653208675\n",
      "Sum of scalar products for gradients in different class: -15881.977989995103\n",
      "Loss: 0.0007170370663516223\n",
      "\n",
      "\n",
      "Iteration: 600\n",
      "Squared L2 Norm of Full Gradient: 1034.1016953125509\n",
      "Sum of scalar products for gradients in same class: 16865.99008927843\n",
      "Sum of scalar products for gradients in different class: -15831.88839396588\n",
      "Loss: 0.0007158854277804494\n",
      "\n",
      "\n",
      "Iteration: 601\n",
      "Squared L2 Norm of Full Gradient: 1030.647962040326\n",
      "Sum of scalar products for gradients in same class: 16812.704783213136\n",
      "Sum of scalar products for gradients in different class: -15782.05682117281\n",
      "Loss: 0.0007147379801608622\n",
      "\n",
      "\n",
      "Iteration: 602\n",
      "Squared L2 Norm of Full Gradient: 1027.2222574802581\n",
      "Sum of scalar products for gradients in same class: 16759.696385985913\n",
      "Sum of scalar products for gradients in different class: -15732.474128505655\n",
      "Loss: 0.0007135974592529237\n",
      "\n",
      "\n",
      "Iteration: 603\n",
      "Squared L2 Norm of Full Gradient: 1023.8038424027072\n",
      "Sum of scalar products for gradients in same class: 16706.833015418357\n",
      "Sum of scalar products for gradients in different class: -15683.02917301565\n",
      "Loss: 0.0007124554831534624\n",
      "\n",
      "\n",
      "Iteration: 604\n",
      "Squared L2 Norm of Full Gradient: 1020.4059911175282\n",
      "Sum of scalar products for gradients in same class: 16654.311556725563\n",
      "Sum of scalar products for gradients in different class: -15633.905565608035\n",
      "Loss: 0.0007113179308362305\n",
      "\n",
      "\n",
      "Iteration: 605\n",
      "Squared L2 Norm of Full Gradient: 1017.0195053955686\n",
      "Sum of scalar products for gradients in same class: 16601.919285636224\n",
      "Sum of scalar products for gradients in different class: -15584.899780240656\n",
      "Loss: 0.0007101845112629235\n",
      "\n",
      "\n",
      "Iteration: 606\n",
      "Squared L2 Norm of Full Gradient: 1013.6539513933385\n",
      "Sum of scalar products for gradients in same class: 16549.878175510228\n",
      "Sum of scalar products for gradients in different class: -15536.22422411689\n",
      "Loss: 0.0007090571452863514\n",
      "\n",
      "\n",
      "Iteration: 607\n",
      "Squared L2 Norm of Full Gradient: 1010.3119204957184\n",
      "Sum of scalar products for gradients in same class: 16498.10866464457\n",
      "Sum of scalar products for gradients in different class: -15487.79674414885\n",
      "Loss: 0.0007079290226101875\n",
      "\n",
      "\n",
      "Iteration: 608\n",
      "Squared L2 Norm of Full Gradient: 1006.9810974796164\n",
      "Sum of scalar products for gradients in same class: 16446.63753369802\n",
      "Sum of scalar products for gradients in different class: -15439.656436218404\n",
      "Loss: 0.0007068123668432236\n",
      "\n",
      "\n",
      "Iteration: 609\n",
      "Squared L2 Norm of Full Gradient: 1003.6639920324669\n",
      "Sum of scalar products for gradients in same class: 16395.26301987495\n",
      "Sum of scalar products for gradients in different class: -15391.599027842483\n",
      "Loss: 0.0007056908798404038\n",
      "\n",
      "\n",
      "Iteration: 610\n",
      "Squared L2 Norm of Full Gradient: 1000.3637004296215\n",
      "Sum of scalar products for gradients in same class: 16344.129991941641\n",
      "Sum of scalar products for gradients in different class: -15343.76629151202\n",
      "Loss: 0.0007045745733194053\n",
      "\n",
      "\n",
      "Iteration: 611\n",
      "Squared L2 Norm of Full Gradient: 997.0901643894067\n",
      "Sum of scalar products for gradients in same class: 16293.396382406638\n",
      "Sum of scalar products for gradients in different class: -15296.306218017231\n",
      "Loss: 0.0007034690352156758\n",
      "\n",
      "\n",
      "Iteration: 612\n",
      "Squared L2 Norm of Full Gradient: 993.8254806900077\n",
      "Sum of scalar products for gradients in same class: 16242.78504027675\n",
      "Sum of scalar products for gradients in different class: -15248.959559586743\n",
      "Loss: 0.0007023577927611768\n",
      "\n",
      "\n",
      "Iteration: 613\n",
      "Squared L2 Norm of Full Gradient: 990.5816383147758\n",
      "Sum of scalar products for gradients in same class: 16192.547351247813\n",
      "Sum of scalar products for gradients in different class: -15201.965712933037\n",
      "Loss: 0.000701253826264292\n",
      "\n",
      "\n",
      "Iteration: 614\n",
      "Squared L2 Norm of Full Gradient: 987.3466945088003\n",
      "Sum of scalar products for gradients in same class: 16142.471492477125\n",
      "Sum of scalar products for gradients in different class: -15155.124797968325\n",
      "Loss: 0.0007001588237471879\n",
      "\n",
      "\n",
      "Iteration: 615\n",
      "Squared L2 Norm of Full Gradient: 984.1325986213633\n",
      "Sum of scalar products for gradients in same class: 16092.595129787038\n",
      "Sum of scalar products for gradients in different class: -15108.462531165675\n",
      "Loss: 0.000699058931786567\n",
      "\n",
      "\n",
      "Iteration: 616\n",
      "Squared L2 Norm of Full Gradient: 980.9370044568823\n",
      "Sum of scalar products for gradients in same class: 16043.031622028931\n",
      "Sum of scalar products for gradients in different class: -15062.09461757205\n",
      "Loss: 0.0006979710306040943\n",
      "\n",
      "\n",
      "Iteration: 617\n",
      "Squared L2 Norm of Full Gradient: 977.7466069677757\n",
      "Sum of scalar products for gradients in same class: 15993.534729198218\n",
      "Sum of scalar products for gradients in different class: -15015.788122230442\n",
      "Loss: 0.0006968784728087485\n",
      "\n",
      "\n",
      "Iteration: 618\n",
      "Squared L2 Norm of Full Gradient: 974.5889154659235\n",
      "Sum of scalar products for gradients in same class: 15944.640458501388\n",
      "Sum of scalar products for gradients in different class: -14970.051543035464\n",
      "Loss: 0.0006957946461625397\n",
      "\n",
      "\n",
      "Iteration: 619\n",
      "Squared L2 Norm of Full Gradient: 971.4357367118973\n",
      "Sum of scalar products for gradients in same class: 15895.711272039149\n",
      "Sum of scalar products for gradients in different class: -14924.275535327251\n",
      "Loss: 0.0006947119254618883\n",
      "\n",
      "\n",
      "Iteration: 620\n",
      "Squared L2 Norm of Full Gradient: 968.3059474863112\n",
      "Sum of scalar products for gradients in same class: 15847.056672130584\n",
      "Sum of scalar products for gradients in different class: -14878.750724644273\n",
      "Loss: 0.0006936336867511272\n",
      "\n",
      "\n",
      "Iteration: 621\n",
      "Squared L2 Norm of Full Gradient: 965.1782453921769\n",
      "Sum of scalar products for gradients in same class: 15798.512570851784\n",
      "Sum of scalar products for gradients in different class: -14833.334325459607\n",
      "Loss: 0.0006925586494617164\n",
      "\n",
      "\n",
      "Iteration: 622\n",
      "Squared L2 Norm of Full Gradient: 962.0791487635906\n",
      "Sum of scalar products for gradients in same class: 15750.380875535167\n",
      "Sum of scalar products for gradients in different class: -14788.301726771577\n",
      "Loss: 0.0006914841942489147\n",
      "\n",
      "\n",
      "Iteration: 623\n",
      "Squared L2 Norm of Full Gradient: 958.9891702024943\n",
      "Sum of scalar products for gradients in same class: 15702.468172152225\n",
      "Sum of scalar products for gradients in different class: -14743.47900194973\n",
      "Loss: 0.0006904200999997556\n",
      "\n",
      "\n",
      "Iteration: 624\n",
      "Squared L2 Norm of Full Gradient: 955.9143047889847\n",
      "Sum of scalar products for gradients in same class: 15654.645504309177\n",
      "Sum of scalar products for gradients in different class: -14698.731199520193\n",
      "Loss: 0.0006893526297062635\n",
      "\n",
      "\n",
      "Iteration: 625\n",
      "Squared L2 Norm of Full Gradient: 952.8503822583152\n",
      "Sum of scalar products for gradients in same class: 15607.03887165284\n",
      "Sum of scalar products for gradients in different class: -14654.188489394524\n",
      "Loss: 0.0006882935995236039\n",
      "\n",
      "\n",
      "Iteration: 626\n",
      "Squared L2 Norm of Full Gradient: 949.805838318207\n",
      "Sum of scalar products for gradients in same class: 15559.75405803318\n",
      "Sum of scalar products for gradients in different class: -14609.948219714974\n",
      "Loss: 0.0006872359081171453\n",
      "\n",
      "\n",
      "Iteration: 627\n",
      "Squared L2 Norm of Full Gradient: 946.7777864387936\n",
      "Sum of scalar products for gradients in same class: 15512.65040045937\n",
      "Sum of scalar products for gradients in different class: -14565.872614020576\n",
      "Loss: 0.0006861781002953649\n",
      "\n",
      "\n",
      "Iteration: 628\n",
      "Squared L2 Norm of Full Gradient: 943.7618348747637\n",
      "Sum of scalar products for gradients in same class: 15465.804206040597\n",
      "Sum of scalar products for gradients in different class: -14522.042371165833\n",
      "Loss: 0.0006851295474916697\n",
      "\n",
      "\n",
      "Iteration: 629\n",
      "Squared L2 Norm of Full Gradient: 940.7623949653098\n",
      "Sum of scalar products for gradients in same class: 15419.170949343748\n",
      "Sum of scalar products for gradients in different class: -14478.408554378439\n",
      "Loss: 0.0006840829737484455\n",
      "\n",
      "\n",
      "Iteration: 630\n",
      "Squared L2 Norm of Full Gradient: 937.7777753445698\n",
      "Sum of scalar products for gradients in same class: 15372.644413735841\n",
      "Sum of scalar products for gradients in different class: -14434.866638391271\n",
      "Loss: 0.0006830391357652843\n",
      "\n",
      "\n",
      "Iteration: 631\n",
      "Squared L2 Norm of Full Gradient: 934.8109605488171\n",
      "Sum of scalar products for gradients in same class: 15326.548561827247\n",
      "Sum of scalar products for gradients in different class: -14391.73760127843\n",
      "Loss: 0.0006819956470280886\n",
      "\n",
      "\n",
      "Iteration: 632\n",
      "Squared L2 Norm of Full Gradient: 931.8496613331408\n",
      "Sum of scalar products for gradients in same class: 15280.425116047201\n",
      "Sum of scalar products for gradients in different class: -14348.57545471406\n",
      "Loss: 0.0006809595506638288\n",
      "\n",
      "\n",
      "Iteration: 633\n",
      "Squared L2 Norm of Full Gradient: 928.9055001942907\n",
      "Sum of scalar products for gradients in same class: 15234.607685392246\n",
      "Sum of scalar products for gradients in different class: -14305.702185197955\n",
      "Loss: 0.0006799252587370574\n",
      "\n",
      "\n",
      "Iteration: 634\n",
      "Squared L2 Norm of Full Gradient: 925.9735426465195\n",
      "Sum of scalar products for gradients in same class: 15188.965326186513\n",
      "Sum of scalar products for gradients in different class: -14262.991783539994\n",
      "Loss: 0.0006788889295421541\n",
      "\n",
      "\n",
      "Iteration: 635\n",
      "Squared L2 Norm of Full Gradient: 923.0589682707941\n",
      "Sum of scalar products for gradients in same class: 15143.624077342589\n",
      "Sum of scalar products for gradients in different class: -14220.565109071795\n",
      "Loss: 0.0006778661045245826\n",
      "\n",
      "\n",
      "Iteration: 636\n",
      "Squared L2 Norm of Full Gradient: 920.1685439700705\n",
      "Sum of scalar products for gradients in same class: 15098.646947659709\n",
      "Sum of scalar products for gradients in different class: -14178.478403689638\n",
      "Loss: 0.0006768415914848447\n",
      "\n",
      "\n",
      "Iteration: 637\n",
      "Squared L2 Norm of Full Gradient: 917.2690192196897\n",
      "Sum of scalar products for gradients in same class: 15053.460950907513\n",
      "Sum of scalar products for gradients in different class: -14136.191931687823\n",
      "Loss: 0.0006758170202374458\n",
      "\n",
      "\n",
      "Iteration: 638\n",
      "Squared L2 Norm of Full Gradient: 914.405561140753\n",
      "Sum of scalar products for gradients in same class: 15008.797839357543\n",
      "Sum of scalar products for gradients in different class: -14094.39227821679\n",
      "Loss: 0.0006747976294718683\n",
      "\n",
      "\n",
      "Iteration: 639\n",
      "Squared L2 Norm of Full Gradient: 911.549919521527\n",
      "Sum of scalar products for gradients in same class: 14964.265167847534\n",
      "Sum of scalar products for gradients in different class: -14052.715248326007\n",
      "Loss: 0.0006737835356034338\n",
      "\n",
      "\n",
      "Iteration: 640\n",
      "Squared L2 Norm of Full Gradient: 908.70046878004\n",
      "Sum of scalar products for gradients in same class: 14919.941902988157\n",
      "Sum of scalar products for gradients in different class: -14011.241434208117\n",
      "Loss: 0.0006727768923155963\n",
      "\n",
      "\n",
      "Iteration: 641\n",
      "Squared L2 Norm of Full Gradient: 905.8636303323001\n",
      "Sum of scalar products for gradients in same class: 14875.713145833382\n",
      "Sum of scalar products for gradients in different class: -13969.849515501082\n",
      "Loss: 0.0006717611104249954\n",
      "\n",
      "\n",
      "Iteration: 642\n",
      "Squared L2 Norm of Full Gradient: 903.0491098314851\n",
      "Sum of scalar products for gradients in same class: 14831.792930851552\n",
      "Sum of scalar products for gradients in different class: -13928.743821020067\n",
      "Loss: 0.000670754408929497\n",
      "\n",
      "\n",
      "Iteration: 643\n",
      "Squared L2 Norm of Full Gradient: 900.2438901168389\n",
      "Sum of scalar products for gradients in same class: 14788.052313724893\n",
      "Sum of scalar products for gradients in different class: -13887.808423608054\n",
      "Loss: 0.0006697528879158199\n",
      "\n",
      "\n",
      "Iteration: 644\n",
      "Squared L2 Norm of Full Gradient: 897.4585761384842\n",
      "Sum of scalar products for gradients in same class: 14744.581484567148\n",
      "Sum of scalar products for gradients in different class: -13847.122908428664\n",
      "Loss: 0.0006687533459626138\n",
      "\n",
      "\n",
      "Iteration: 645\n",
      "Squared L2 Norm of Full Gradient: 894.6815712319367\n",
      "Sum of scalar products for gradients in same class: 14701.195427380615\n",
      "Sum of scalar products for gradients in different class: -13806.513856148678\n",
      "Loss: 0.0006677550263702869\n",
      "\n",
      "\n",
      "Iteration: 646\n",
      "Squared L2 Norm of Full Gradient: 891.9110340095503\n",
      "Sum of scalar products for gradients in same class: 14657.983990325803\n",
      "Sum of scalar products for gradients in different class: -13766.072956316253\n",
      "Loss: 0.0006667625857517123\n",
      "\n",
      "\n",
      "Iteration: 647\n",
      "Squared L2 Norm of Full Gradient: 889.1645855458919\n",
      "Sum of scalar products for gradients in same class: 14615.14687109414\n",
      "Sum of scalar products for gradients in different class: -13725.982285548249\n",
      "Loss: 0.0006657729973085225\n",
      "\n",
      "\n",
      "Iteration: 648\n",
      "Squared L2 Norm of Full Gradient: 886.4216907080845\n",
      "Sum of scalar products for gradients in same class: 14572.345635104164\n",
      "Sum of scalar products for gradients in different class: -13685.92394439608\n",
      "Loss: 0.0006647860864177346\n",
      "\n",
      "\n",
      "Iteration: 649\n",
      "Squared L2 Norm of Full Gradient: 883.6982285493432\n",
      "Sum of scalar products for gradients in same class: 14529.827490717831\n",
      "Sum of scalar products for gradients in different class: -13646.129262168488\n",
      "Loss: 0.0006638018530793488\n",
      "\n",
      "\n",
      "Iteration: 650\n",
      "Squared L2 Norm of Full Gradient: 880.9845046840528\n",
      "Sum of scalar products for gradients in same class: 14487.404108994211\n",
      "Sum of scalar products for gradients in different class: -13606.419604310158\n",
      "Loss: 0.0006628225673921406\n",
      "\n",
      "\n",
      "Iteration: 651\n",
      "Squared L2 Norm of Full Gradient: 878.2887462830549\n",
      "Sum of scalar products for gradients in same class: 14445.270276913117\n",
      "Sum of scalar products for gradients in different class: -13566.981530630062\n",
      "Loss: 0.0006618464249186218\n",
      "\n",
      "\n",
      "Iteration: 652\n",
      "Squared L2 Norm of Full Gradient: 875.596215601985\n",
      "Sum of scalar products for gradients in same class: 14403.241241489115\n",
      "Sum of scalar products for gradients in different class: -13527.64502588713\n",
      "Loss: 0.0006608706316910684\n",
      "\n",
      "\n",
      "Iteration: 653\n",
      "Squared L2 Norm of Full Gradient: 872.9195398336742\n",
      "Sum of scalar products for gradients in same class: 14361.360194913846\n",
      "Sum of scalar products for gradients in different class: -13488.440655080172\n",
      "Loss: 0.000659894896671176\n",
      "\n",
      "\n",
      "Iteration: 654\n",
      "Squared L2 Norm of Full Gradient: 870.2557392214985\n",
      "Sum of scalar products for gradients in same class: 14319.740785770216\n",
      "Sum of scalar products for gradients in different class: -13449.485046548718\n",
      "Loss: 0.0006589270196855068\n",
      "\n",
      "\n",
      "Iteration: 655\n",
      "Squared L2 Norm of Full Gradient: 867.6055600315194\n",
      "Sum of scalar products for gradients in same class: 14278.253399320187\n",
      "Sum of scalar products for gradients in different class: -13410.647839288667\n",
      "Loss: 0.0006579634500667453\n",
      "\n",
      "\n",
      "Iteration: 656\n",
      "Squared L2 Norm of Full Gradient: 864.9676122377277\n",
      "Sum of scalar products for gradients in same class: 14237.08915032279\n",
      "Sum of scalar products for gradients in different class: -13372.121538085063\n",
      "Loss: 0.0006569987745024264\n",
      "\n",
      "\n",
      "Iteration: 657\n",
      "Squared L2 Norm of Full Gradient: 862.3426425502148\n",
      "Sum of scalar products for gradients in same class: 14195.947602226039\n",
      "Sum of scalar products for gradients in different class: -13333.604959675824\n",
      "Loss: 0.0006560382898896933\n",
      "\n",
      "\n",
      "Iteration: 658\n",
      "Squared L2 Norm of Full Gradient: 859.7292678652011\n",
      "Sum of scalar products for gradients in same class: 14155.112731143276\n",
      "Sum of scalar products for gradients in different class: -13295.383463278074\n",
      "Loss: 0.0006550843245349824\n",
      "\n",
      "\n",
      "Iteration: 659\n",
      "Squared L2 Norm of Full Gradient: 857.1285703481735\n",
      "Sum of scalar products for gradients in same class: 14114.451115348758\n",
      "Sum of scalar products for gradients in different class: -13257.322545000585\n",
      "Loss: 0.0006541259353980422\n",
      "\n",
      "\n",
      "Iteration: 660\n",
      "Squared L2 Norm of Full Gradient: 854.5414024880301\n",
      "Sum of scalar products for gradients in same class: 14073.910977259795\n",
      "Sum of scalar products for gradients in different class: -13219.369574771765\n",
      "Loss: 0.0006531738908961415\n",
      "\n",
      "\n",
      "Iteration: 661\n",
      "Squared L2 Norm of Full Gradient: 851.9715065080127\n",
      "Sum of scalar products for gradients in same class: 14033.674244949445\n",
      "Sum of scalar products for gradients in different class: -13181.702738441432\n",
      "Loss: 0.0006522270268760622\n",
      "\n",
      "\n",
      "Iteration: 662\n",
      "Squared L2 Norm of Full Gradient: 849.3974758500699\n",
      "Sum of scalar products for gradients in same class: 13993.372389362234\n",
      "Sum of scalar products for gradients in different class: -13143.974913512164\n",
      "Loss: 0.0006512812688015401\n",
      "\n",
      "\n",
      "Iteration: 663\n",
      "Squared L2 Norm of Full Gradient: 846.8458780655637\n",
      "Sum of scalar products for gradients in same class: 13953.41786847969\n",
      "Sum of scalar products for gradients in different class: -13106.571990414126\n",
      "Loss: 0.000650338304694742\n",
      "\n",
      "\n",
      "Iteration: 664\n",
      "Squared L2 Norm of Full Gradient: 844.3115306074069\n",
      "Sum of scalar products for gradients in same class: 13913.676151425876\n",
      "Sum of scalar products for gradients in different class: -13069.36462081847\n",
      "Loss: 0.0006493978435173631\n",
      "\n",
      "\n",
      "Iteration: 665\n",
      "Squared L2 Norm of Full Gradient: 841.7769967049971\n",
      "Sum of scalar products for gradients in same class: 13873.978907988097\n",
      "Sum of scalar products for gradients in different class: -13032.2019112831\n",
      "Loss: 0.0006484595942310989\n",
      "\n",
      "\n",
      "Iteration: 666\n",
      "Squared L2 Norm of Full Gradient: 839.2577658888513\n",
      "Sum of scalar products for gradients in same class: 13834.474387978982\n",
      "Sum of scalar products for gradients in different class: -12995.21662209013\n",
      "Loss: 0.0006475257105194032\n",
      "\n",
      "\n",
      "Iteration: 667\n",
      "Squared L2 Norm of Full Gradient: 836.7527933293641\n",
      "Sum of scalar products for gradients in same class: 13795.234857298201\n",
      "Sum of scalar products for gradients in different class: -12958.482063968837\n",
      "Loss: 0.0006465931073762476\n",
      "\n",
      "\n",
      "Iteration: 668\n",
      "Squared L2 Norm of Full Gradient: 834.2503527188674\n",
      "Sum of scalar products for gradients in same class: 13756.031760793147\n",
      "Sum of scalar products for gradients in different class: -12921.78140807428\n",
      "Loss: 0.000645663239993155\n",
      "\n",
      "\n",
      "Iteration: 669\n",
      "Squared L2 Norm of Full Gradient: 831.7653017585144\n",
      "Sum of scalar products for gradients in same class: 13717.041569249312\n",
      "Sum of scalar products for gradients in different class: -12885.276267490797\n",
      "Loss: 0.0006447380874305964\n",
      "\n",
      "\n",
      "Iteration: 670\n",
      "Squared L2 Norm of Full Gradient: 829.2967005258106\n",
      "Sum of scalar products for gradients in same class: 13678.318190913942\n",
      "Sum of scalar products for gradients in different class: -12849.021490388131\n",
      "Loss: 0.0006438180571421981\n",
      "\n",
      "\n",
      "Iteration: 671\n",
      "Squared L2 Norm of Full Gradient: 826.8317680275686\n",
      "Sum of scalar products for gradients in same class: 13639.729699224543\n",
      "Sum of scalar products for gradients in different class: -12812.897931196974\n",
      "Loss: 0.0006428949418477714\n",
      "\n",
      "\n",
      "Iteration: 672\n",
      "Squared L2 Norm of Full Gradient: 824.3857285908634\n",
      "Sum of scalar products for gradients in same class: 13601.29751456116\n",
      "Sum of scalar products for gradients in different class: -12776.911785970296\n",
      "Loss: 0.0006419805577024817\n",
      "\n",
      "\n",
      "Iteration: 673\n",
      "Squared L2 Norm of Full Gradient: 821.949437097941\n",
      "Sum of scalar products for gradients in same class: 13563.078920304786\n",
      "Sum of scalar products for gradients in different class: -12741.129483206845\n",
      "Loss: 0.0006410633795894682\n",
      "\n",
      "\n",
      "Iteration: 674\n",
      "Squared L2 Norm of Full Gradient: 819.5164232850075\n",
      "Sum of scalar products for gradients in same class: 13524.912700838802\n",
      "Sum of scalar products for gradients in different class: -12705.396277553795\n",
      "Loss: 0.0006401468999683857\n",
      "\n",
      "\n",
      "Iteration: 675\n",
      "Squared L2 Norm of Full Gradient: 817.0929040205701\n",
      "Sum of scalar products for gradients in same class: 13486.823051155428\n",
      "Sum of scalar products for gradients in different class: -12669.730147134858\n",
      "Loss: 0.0006392372888512909\n",
      "\n",
      "\n",
      "Iteration: 676\n",
      "Squared L2 Norm of Full Gradient: 814.6841883192283\n",
      "Sum of scalar products for gradients in same class: 13449.020112704271\n",
      "Sum of scalar products for gradients in different class: -12634.335924385043\n",
      "Loss: 0.0006383275613188744\n",
      "\n",
      "\n",
      "Iteration: 677\n",
      "Squared L2 Norm of Full Gradient: 812.2896828729754\n",
      "Sum of scalar products for gradients in same class: 13411.401460928253\n",
      "Sum of scalar products for gradients in different class: -12599.111778055278\n",
      "Loss: 0.0006374281365424395\n",
      "\n",
      "\n",
      "Iteration: 678\n",
      "Squared L2 Norm of Full Gradient: 809.9103176631033\n",
      "Sum of scalar products for gradients in same class: 13374.0521939305\n",
      "Sum of scalar products for gradients in different class: -12564.141876267397\n",
      "Loss: 0.0006365235894918442\n",
      "\n",
      "\n",
      "Iteration: 679\n",
      "Squared L2 Norm of Full Gradient: 807.5348760053203\n",
      "Sum of scalar products for gradients in same class: 13336.76636042878\n",
      "Sum of scalar products for gradients in different class: -12529.23148442346\n",
      "Loss: 0.000635627016890794\n",
      "\n",
      "\n",
      "Iteration: 680\n",
      "Squared L2 Norm of Full Gradient: 805.1763452676969\n",
      "Sum of scalar products for gradients in same class: 13299.69961679602\n",
      "Sum of scalar products for gradients in different class: -12494.523271528324\n",
      "Loss: 0.0006347279995679855\n",
      "\n",
      "\n",
      "Iteration: 681\n",
      "Squared L2 Norm of Full Gradient: 802.8141301349715\n",
      "Sum of scalar products for gradients in same class: 13262.562972528744\n",
      "Sum of scalar products for gradients in different class: -12459.748842393772\n",
      "Loss: 0.0006338332896120846\n",
      "\n",
      "\n",
      "Iteration: 682\n",
      "Squared L2 Norm of Full Gradient: 800.4756755477283\n",
      "Sum of scalar products for gradients in same class: 13225.82915223046\n",
      "Sum of scalar products for gradients in different class: -12425.353476682732\n",
      "Loss: 0.0006329423049464822\n",
      "\n",
      "\n",
      "Iteration: 683\n",
      "Squared L2 Norm of Full Gradient: 798.135782016674\n",
      "Sum of scalar products for gradients in same class: 13189.055717997177\n",
      "Sum of scalar products for gradients in different class: -12390.919935980502\n",
      "Loss: 0.0006320527754724026\n",
      "\n",
      "\n",
      "Iteration: 684\n",
      "Squared L2 Norm of Full Gradient: 795.8214816836553\n",
      "Sum of scalar products for gradients in same class: 13152.58798568914\n",
      "Sum of scalar products for gradients in different class: -12356.766504005485\n",
      "Loss: 0.0006311699980869889\n",
      "\n",
      "\n",
      "Iteration: 685\n",
      "Squared L2 Norm of Full Gradient: 793.5124757689337\n",
      "Sum of scalar products for gradients in same class: 13116.351100391868\n",
      "Sum of scalar products for gradients in different class: -12322.838624622935\n",
      "Loss: 0.0006302864640019834\n",
      "\n",
      "\n",
      "Iteration: 686\n",
      "Squared L2 Norm of Full Gradient: 791.2103653588019\n",
      "Sum of scalar products for gradients in same class: 13080.164575293158\n",
      "Sum of scalar products for gradients in different class: -12288.954209934356\n",
      "Loss: 0.0006294064223766327\n",
      "\n",
      "\n",
      "Iteration: 687\n",
      "Squared L2 Norm of Full Gradient: 788.9196351410683\n",
      "Sum of scalar products for gradients in same class: 13044.07343898038\n",
      "Sum of scalar products for gradients in different class: -12255.153803839312\n",
      "Loss: 0.0006285248091444373\n",
      "\n",
      "\n",
      "Iteration: 688\n",
      "Squared L2 Norm of Full Gradient: 786.6447437788011\n",
      "Sum of scalar products for gradients in same class: 13008.245440250783\n",
      "Sum of scalar products for gradients in different class: -12221.600696471982\n",
      "Loss: 0.0006276492495089769\n",
      "\n",
      "\n",
      "Iteration: 689\n",
      "Squared L2 Norm of Full Gradient: 784.3723891801346\n",
      "Sum of scalar products for gradients in same class: 12972.456524845533\n",
      "Sum of scalar products for gradients in different class: -12188.084135665398\n",
      "Loss: 0.0006267791613936424\n",
      "\n",
      "\n",
      "Iteration: 690\n",
      "Squared L2 Norm of Full Gradient: 782.1054550144472\n",
      "Sum of scalar products for gradients in same class: 12936.807477571885\n",
      "Sum of scalar products for gradients in different class: -12154.702022557438\n",
      "Loss: 0.0006259030778892338\n",
      "\n",
      "\n",
      "Iteration: 691\n",
      "Squared L2 Norm of Full Gradient: 779.8507498211839\n",
      "Sum of scalar products for gradients in same class: 12901.267999787331\n",
      "Sum of scalar products for gradients in different class: -12121.417249966147\n",
      "Loss: 0.0006250331061892211\n",
      "\n",
      "\n",
      "Iteration: 692\n",
      "Squared L2 Norm of Full Gradient: 777.6225955430164\n",
      "Sum of scalar products for gradients in same class: 12866.188798163064\n",
      "Sum of scalar products for gradients in different class: -12088.566202620048\n",
      "Loss: 0.0006241719820536673\n",
      "\n",
      "\n",
      "Iteration: 693\n",
      "Squared L2 Norm of Full Gradient: 775.3820140738717\n",
      "Sum of scalar products for gradients in same class: 12830.89920808413\n",
      "Sum of scalar products for gradients in different class: -12055.51719401026\n",
      "Loss: 0.0006233090534806252\n",
      "\n",
      "\n",
      "Iteration: 694\n",
      "Squared L2 Norm of Full Gradient: 773.1571814322124\n",
      "Sum of scalar products for gradients in same class: 12795.870930907153\n",
      "Sum of scalar products for gradients in different class: -12022.71374947494\n",
      "Loss: 0.0006224460666999221\n",
      "\n",
      "\n",
      "Iteration: 695\n",
      "Squared L2 Norm of Full Gradient: 770.9540810092003\n",
      "Sum of scalar products for gradients in same class: 12761.178038317055\n",
      "Sum of scalar products for gradients in different class: -11990.223957307855\n",
      "Loss: 0.000621589832007885\n",
      "\n",
      "\n",
      "Iteration: 696\n",
      "Squared L2 Norm of Full Gradient: 768.7525374005199\n",
      "Sum of scalar products for gradients in same class: 12726.418452560443\n",
      "Sum of scalar products for gradients in different class: -11957.665915159923\n",
      "Loss: 0.0006207344704307616\n",
      "\n",
      "\n",
      "Iteration: 697\n",
      "Squared L2 Norm of Full Gradient: 766.5575213917182\n",
      "Sum of scalar products for gradients in same class: 12691.928072199826\n",
      "Sum of scalar products for gradients in different class: -11925.370550808108\n",
      "Loss: 0.0006198796909302473\n",
      "\n",
      "\n",
      "Iteration: 698\n",
      "Squared L2 Norm of Full Gradient: 764.3800924247225\n",
      "Sum of scalar products for gradients in same class: 12657.53970714425\n",
      "Sum of scalar products for gradients in different class: -11893.159614719527\n",
      "Loss: 0.0006190293352119625\n",
      "\n",
      "\n",
      "Iteration: 699\n",
      "Squared L2 Norm of Full Gradient: 762.1990201453591\n",
      "Sum of scalar products for gradients in same class: 12623.168353047979\n",
      "Sum of scalar products for gradients in different class: -11860.96933290262\n",
      "Loss: 0.0006181813660077751\n",
      "\n",
      "\n",
      "Iteration: 700\n",
      "Squared L2 Norm of Full Gradient: 760.0415714271512\n",
      "Sum of scalar products for gradients in same class: 12589.147363353888\n",
      "Sum of scalar products for gradients in different class: -11829.105791926737\n",
      "Loss: 0.0006173303117975593\n",
      "\n",
      "\n",
      "Iteration: 701\n",
      "Squared L2 Norm of Full Gradient: 757.8882306071464\n",
      "Sum of scalar products for gradients in same class: 12555.177513663937\n",
      "Sum of scalar products for gradients in different class: -11797.28928305679\n",
      "Loss: 0.0006164883961901069\n",
      "\n",
      "\n",
      "Iteration: 702\n",
      "Squared L2 Norm of Full Gradient: 755.737420182737\n",
      "Sum of scalar products for gradients in same class: 12521.219033394882\n",
      "Sum of scalar products for gradients in different class: -11765.481613212145\n",
      "Loss: 0.0006156467134132981\n",
      "\n",
      "\n",
      "Iteration: 703\n",
      "Squared L2 Norm of Full Gradient: 753.5997190933122\n",
      "Sum of scalar products for gradients in same class: 12487.52227534058\n",
      "Sum of scalar products for gradients in different class: -11733.922556247267\n",
      "Loss: 0.0006148079410195351\n",
      "\n",
      "\n",
      "Iteration: 704\n",
      "Squared L2 Norm of Full Gradient: 751.4689148301259\n",
      "Sum of scalar products for gradients in same class: 12453.875857531973\n",
      "Sum of scalar products for gradients in different class: -11702.406942701848\n",
      "Loss: 0.0006139687029644847\n",
      "\n",
      "\n",
      "Iteration: 705\n",
      "Squared L2 Norm of Full Gradient: 749.355537825264\n",
      "Sum of scalar products for gradients in same class: 12420.467035668124\n",
      "Sum of scalar products for gradients in different class: -11671.11149784286\n",
      "Loss: 0.0006131355185061693\n",
      "\n",
      "\n",
      "Iteration: 706\n",
      "Squared L2 Norm of Full Gradient: 747.2469094838052\n",
      "Sum of scalar products for gradients in same class: 12387.182161762805\n",
      "Sum of scalar products for gradients in different class: -11639.935252279\n",
      "Loss: 0.0006123062339611351\n",
      "\n",
      "\n",
      "Iteration: 707\n",
      "Squared L2 Norm of Full Gradient: 745.1507280188707\n",
      "Sum of scalar products for gradients in same class: 12354.11722662874\n",
      "Sum of scalar products for gradients in different class: -11608.966498609869\n",
      "Loss: 0.0006114757270552218\n",
      "\n",
      "\n",
      "Iteration: 708\n",
      "Squared L2 Norm of Full Gradient: 743.0631060035703\n",
      "Sum of scalar products for gradients in same class: 12321.133444196348\n",
      "Sum of scalar products for gradients in different class: -11578.070338192778\n",
      "Loss: 0.0006106494693085551\n",
      "\n",
      "\n",
      "Iteration: 709\n",
      "Squared L2 Norm of Full Gradient: 740.9820468328544\n",
      "Sum of scalar products for gradients in same class: 12288.230294502358\n",
      "Sum of scalar products for gradients in different class: -11547.248247669504\n",
      "Loss: 0.0006098229205235839\n",
      "\n",
      "\n",
      "Iteration: 710\n",
      "Squared L2 Norm of Full Gradient: 738.9054613208864\n",
      "Sum of scalar products for gradients in same class: 12255.441641072553\n",
      "Sum of scalar products for gradients in different class: -11516.536179751667\n",
      "Loss: 0.000609001552220434\n",
      "\n",
      "\n",
      "Iteration: 711\n",
      "Squared L2 Norm of Full Gradient: 736.8448368675454\n",
      "Sum of scalar products for gradients in same class: 12222.928801811886\n",
      "Sum of scalar products for gradients in different class: -11486.08396494434\n",
      "Loss: 0.0006081797764636576\n",
      "\n",
      "\n",
      "Iteration: 712\n",
      "Squared L2 Norm of Full Gradient: 734.7848148088815\n",
      "Sum of scalar products for gradients in same class: 12190.347646704762\n",
      "Sum of scalar products for gradients in different class: -11455.56283189588\n",
      "Loss: 0.0006073611439205706\n",
      "\n",
      "\n",
      "Iteration: 713\n",
      "Squared L2 Norm of Full Gradient: 732.7388285226334\n",
      "Sum of scalar products for gradients in same class: 12157.99028620452\n",
      "Sum of scalar products for gradients in different class: -11425.251457681887\n",
      "Loss: 0.0006065444904379547\n",
      "\n",
      "\n",
      "Iteration: 714\n",
      "Squared L2 Norm of Full Gradient: 730.7009536560545\n",
      "Sum of scalar products for gradients in same class: 12125.688681414318\n",
      "Sum of scalar products for gradients in different class: -11394.987727758264\n",
      "Loss: 0.0006057317950762808\n",
      "\n",
      "\n",
      "Iteration: 715\n",
      "Squared L2 Norm of Full Gradient: 728.6689028068249\n",
      "Sum of scalar products for gradients in same class: 12093.675287000318\n",
      "Sum of scalar products for gradients in different class: -11365.006384193493\n",
      "Loss: 0.0006049163057468832\n",
      "\n",
      "\n",
      "Iteration: 716\n",
      "Squared L2 Norm of Full Gradient: 726.6515069129528\n",
      "Sum of scalar products for gradients in same class: 12061.750122202695\n",
      "Sum of scalar products for gradients in different class: -11335.098615289742\n",
      "Loss: 0.0006041108281351626\n",
      "\n",
      "\n",
      "Iteration: 717\n",
      "Squared L2 Norm of Full Gradient: 724.6458414732624\n",
      "Sum of scalar products for gradients in same class: 12030.026551333664\n",
      "Sum of scalar products for gradients in different class: -11305.380709860401\n",
      "Loss: 0.0006033035460859537\n",
      "\n",
      "\n",
      "Iteration: 718\n",
      "Squared L2 Norm of Full Gradient: 722.641409625885\n",
      "Sum of scalar products for gradients in same class: 11998.298648368298\n",
      "Sum of scalar products for gradients in different class: -11275.657238742413\n",
      "Loss: 0.0006024996982887387\n",
      "\n",
      "\n",
      "Iteration: 719\n",
      "Squared L2 Norm of Full Gradient: 720.647741409266\n",
      "Sum of scalar products for gradients in same class: 11966.717639527393\n",
      "Sum of scalar products for gradients in different class: -11246.069898118127\n",
      "Loss: 0.0006016987608745694\n",
      "\n",
      "\n",
      "Iteration: 720\n",
      "Squared L2 Norm of Full Gradient: 718.6574407023763\n",
      "Sum of scalar products for gradients in same class: 11935.30511435225\n",
      "Sum of scalar products for gradients in different class: -11216.647673649873\n",
      "Loss: 0.0006008995696902275\n",
      "\n",
      "\n",
      "Iteration: 721\n",
      "Squared L2 Norm of Full Gradient: 716.6764280535281\n",
      "Sum of scalar products for gradients in same class: 11903.879271200196\n",
      "Sum of scalar products for gradients in different class: -11187.202843146668\n",
      "Loss: 0.0006001000292599201\n",
      "\n",
      "\n",
      "Iteration: 722\n",
      "Squared L2 Norm of Full Gradient: 714.708755666743\n",
      "Sum of scalar products for gradients in same class: 11872.765372192334\n",
      "Sum of scalar products for gradients in different class: -11158.056616525591\n",
      "Loss: 0.0005993028171360493\n",
      "\n",
      "\n",
      "Iteration: 723\n",
      "Squared L2 Norm of Full Gradient: 712.7473526413123\n",
      "Sum of scalar products for gradients in same class: 11841.685001966147\n",
      "Sum of scalar products for gradients in different class: -11128.937649324835\n",
      "Loss: 0.0005985087482258677\n",
      "\n",
      "\n",
      "Iteration: 724\n",
      "Squared L2 Norm of Full Gradient: 710.7954587558197\n",
      "Sum of scalar products for gradients in same class: 11810.745102713969\n",
      "Sum of scalar products for gradients in different class: -11099.949643958149\n",
      "Loss: 0.0005977174150757492\n",
      "\n",
      "\n",
      "Iteration: 725\n",
      "Squared L2 Norm of Full Gradient: 708.8487802958698\n",
      "Sum of scalar products for gradients in same class: 11779.965185884583\n",
      "Sum of scalar products for gradients in different class: -11071.116405588713\n",
      "Loss: 0.0005969292833469808\n",
      "\n",
      "\n",
      "Iteration: 726\n",
      "Squared L2 Norm of Full Gradient: 706.9129865721661\n",
      "Sum of scalar products for gradients in same class: 11749.259048942971\n",
      "Sum of scalar products for gradients in different class: -11042.346062370805\n",
      "Loss: 0.0005961415008641779\n",
      "\n",
      "\n",
      "Iteration: 727\n",
      "Squared L2 Norm of Full Gradient: 704.9837898419391\n",
      "Sum of scalar products for gradients in same class: 11718.716996880168\n",
      "Sum of scalar products for gradients in different class: -11013.733207038229\n",
      "Loss: 0.0005953549989499152\n",
      "\n",
      "\n",
      "Iteration: 728\n",
      "Squared L2 Norm of Full Gradient: 703.0666358960443\n",
      "Sum of scalar products for gradients in same class: 11688.281228210613\n",
      "Sum of scalar products for gradients in different class: -10985.214592314569\n",
      "Loss: 0.0005945730954408646\n",
      "\n",
      "\n",
      "Iteration: 729\n",
      "Squared L2 Norm of Full Gradient: 701.1549205782103\n",
      "Sum of scalar products for gradients in same class: 11657.994958451734\n",
      "Sum of scalar products for gradients in different class: -10956.840037873524\n",
      "Loss: 0.0005937933456152678\n",
      "\n",
      "\n",
      "Iteration: 730\n",
      "Squared L2 Norm of Full Gradient: 699.2429834401846\n",
      "Sum of scalar products for gradients in same class: 11627.739971509807\n",
      "Sum of scalar products for gradients in different class: -10928.496988069623\n",
      "Loss: 0.000593016273342073\n",
      "\n",
      "\n",
      "Iteration: 731\n",
      "Squared L2 Norm of Full Gradient: 697.346349303265\n",
      "Sum of scalar products for gradients in same class: 11597.63243513669\n",
      "Sum of scalar products for gradients in different class: -10900.286085833424\n",
      "Loss: 0.0005922376876696944\n",
      "\n",
      "\n",
      "Iteration: 732\n",
      "Squared L2 Norm of Full Gradient: 695.4657712200569\n",
      "Sum of scalar products for gradients in same class: 11567.823579472893\n",
      "Sum of scalar products for gradients in different class: -10872.357808252837\n",
      "Loss: 0.0005914625944569707\n",
      "\n",
      "\n",
      "Iteration: 733\n",
      "Squared L2 Norm of Full Gradient: 693.5778868546222\n",
      "Sum of scalar products for gradients in same class: 11537.862163495534\n",
      "Sum of scalar products for gradients in different class: -10844.284276640912\n",
      "Loss: 0.0005906890728510916\n",
      "\n",
      "\n",
      "Iteration: 734\n",
      "Squared L2 Norm of Full Gradient: 691.7073164688518\n",
      "Sum of scalar products for gradients in same class: 11508.207469470904\n",
      "Sum of scalar products for gradients in different class: -10816.500153002053\n",
      "Loss: 0.0005899211391806602\n",
      "\n",
      "\n",
      "Iteration: 735\n",
      "Squared L2 Norm of Full Gradient: 689.83937213436\n",
      "Sum of scalar products for gradients in same class: 11478.616174153813\n",
      "Sum of scalar products for gradients in different class: -10788.776802019453\n",
      "Loss: 0.0005891535547561944\n",
      "\n",
      "\n",
      "Iteration: 736\n",
      "Squared L2 Norm of Full Gradient: 687.9842592641362\n",
      "Sum of scalar products for gradients in same class: 11449.171432946212\n",
      "Sum of scalar products for gradients in different class: -10761.187173682076\n",
      "Loss: 0.0005883860867470503\n",
      "\n",
      "\n",
      "Iteration: 737\n",
      "Squared L2 Norm of Full Gradient: 686.1325434378559\n",
      "Sum of scalar products for gradients in same class: 11419.742896569333\n",
      "Sum of scalar products for gradients in different class: -10733.610353131477\n",
      "Loss: 0.0005876244977116585\n",
      "\n",
      "\n",
      "Iteration: 738\n",
      "Squared L2 Norm of Full Gradient: 684.2881127551809\n",
      "Sum of scalar products for gradients in same class: 11390.490003460629\n",
      "Sum of scalar products for gradients in different class: -10706.201890705448\n",
      "Loss: 0.0005868600565008819\n",
      "\n",
      "\n",
      "Iteration: 739\n",
      "Squared L2 Norm of Full Gradient: 682.451147171847\n",
      "Sum of scalar products for gradients in same class: 11361.37021919811\n",
      "Sum of scalar products for gradients in different class: -10678.919072026263\n",
      "Loss: 0.0005861016688868403\n",
      "\n",
      "\n",
      "Iteration: 740\n",
      "Squared L2 Norm of Full Gradient: 680.6235174758513\n",
      "Sum of scalar products for gradients in same class: 11332.27808772582\n",
      "Sum of scalar products for gradients in different class: -10651.654570249968\n",
      "Loss: 0.0005853388574905694\n",
      "\n",
      "\n",
      "Iteration: 741\n",
      "Squared L2 Norm of Full Gradient: 678.8050966391202\n",
      "Sum of scalar products for gradients in same class: 11303.437690218918\n",
      "Sum of scalar products for gradients in different class: -10624.632593579798\n",
      "Loss: 0.0005845872219651937\n",
      "\n",
      "\n",
      "Iteration: 742\n",
      "Squared L2 Norm of Full Gradient: 676.9931776361918\n",
      "Sum of scalar products for gradients in same class: 11274.690999329101\n",
      "Sum of scalar products for gradients in different class: -10597.69782169291\n",
      "Loss: 0.0005838346551172435\n",
      "\n",
      "\n",
      "Iteration: 743\n",
      "Squared L2 Norm of Full Gradient: 675.1870502831334\n",
      "Sum of scalar products for gradients in same class: 11245.977577044014\n",
      "Sum of scalar products for gradients in different class: -10570.79052676088\n",
      "Loss: 0.0005830833106301725\n",
      "\n",
      "\n",
      "Iteration: 744\n",
      "Squared L2 Norm of Full Gradient: 673.3921455399868\n",
      "Sum of scalar products for gradients in same class: 11217.455857015506\n",
      "Sum of scalar products for gradients in different class: -10544.063711475519\n",
      "Loss: 0.0005823327810503542\n",
      "\n",
      "\n",
      "Iteration: 745\n",
      "Squared L2 Norm of Full Gradient: 671.5975537109771\n",
      "Sum of scalar products for gradients in same class: 11188.938577389348\n",
      "Sum of scalar products for gradients in different class: -10517.341023678371\n",
      "Loss: 0.0005815874319523573\n",
      "\n",
      "\n",
      "Iteration: 746\n",
      "Squared L2 Norm of Full Gradient: 669.813748160901\n",
      "Sum of scalar products for gradients in same class: 11160.56258355406\n",
      "Sum of scalar products for gradients in different class: -10490.748835393159\n",
      "Loss: 0.000580839638132602\n",
      "\n",
      "\n",
      "Iteration: 747\n",
      "Squared L2 Norm of Full Gradient: 668.0440476747208\n",
      "Sum of scalar products for gradients in same class: 11132.423790829183\n",
      "Sum of scalar products for gradients in different class: -10464.379743154463\n",
      "Loss: 0.0005800958606414497\n",
      "\n",
      "\n",
      "Iteration: 748\n",
      "Squared L2 Norm of Full Gradient: 666.2699924378103\n",
      "Sum of scalar products for gradients in same class: 11104.228928610406\n",
      "Sum of scalar products for gradients in different class: -10437.958936172596\n",
      "Loss: 0.0005793532473035157\n",
      "\n",
      "\n",
      "Iteration: 749\n",
      "Squared L2 Norm of Full Gradient: 664.5070477425033\n",
      "Sum of scalar products for gradients in same class: 11076.191658117092\n",
      "Sum of scalar products for gradients in different class: -10411.684610374588\n",
      "Loss: 0.0005786170368082821\n",
      "\n",
      "\n",
      "Iteration: 750\n",
      "Squared L2 Norm of Full Gradient: 662.7518397945423\n",
      "Sum of scalar products for gradients in same class: 11048.267326356116\n",
      "Sum of scalar products for gradients in different class: -10385.515486561573\n",
      "Loss: 0.0005778775666840374\n",
      "\n",
      "\n",
      "Iteration: 751\n",
      "Squared L2 Norm of Full Gradient: 661.0043471512072\n",
      "Sum of scalar products for gradients in same class: 11020.49741580059\n",
      "Sum of scalar products for gradients in different class: -10359.493068649383\n",
      "Loss: 0.0005771397263742983\n",
      "\n",
      "\n",
      "Iteration: 752\n",
      "Squared L2 Norm of Full Gradient: 659.2697396226904\n",
      "Sum of scalar products for gradients in same class: 10992.86989800047\n",
      "Sum of scalar products for gradients in different class: -10333.60015837778\n",
      "Loss: 0.0005764102679677308\n",
      "\n",
      "\n",
      "Iteration: 753\n",
      "Squared L2 Norm of Full Gradient: 657.5309550688871\n",
      "Sum of scalar products for gradients in same class: 10965.266811649359\n",
      "Sum of scalar products for gradients in different class: -10307.735856580472\n",
      "Loss: 0.0005756751634180546\n",
      "\n",
      "\n",
      "Iteration: 754\n",
      "Squared L2 Norm of Full Gradient: 655.8000347769266\n",
      "Sum of scalar products for gradients in same class: 10937.633385667861\n",
      "Sum of scalar products for gradients in different class: -10281.833350890935\n",
      "Loss: 0.0005749417468905449\n",
      "\n",
      "\n",
      "Iteration: 755\n",
      "Squared L2 Norm of Full Gradient: 654.0865176905791\n",
      "Sum of scalar products for gradients in same class: 10910.361311157114\n",
      "Sum of scalar products for gradients in different class: -10256.274793466535\n",
      "Loss: 0.000574214500375092\n",
      "\n",
      "\n",
      "Iteration: 756\n",
      "Squared L2 Norm of Full Gradient: 652.3683243598825\n",
      "Sum of scalar products for gradients in same class: 10883.032608293426\n",
      "Sum of scalar products for gradients in different class: -10230.664283933544\n",
      "Loss: 0.0005734902224503458\n",
      "\n",
      "\n",
      "Iteration: 757\n",
      "Squared L2 Norm of Full Gradient: 650.6601751374546\n",
      "Sum of scalar products for gradients in same class: 10855.874905767054\n",
      "Sum of scalar products for gradients in different class: -10205.2147306296\n",
      "Loss: 0.0005727625684812665\n",
      "\n",
      "\n",
      "Iteration: 758\n",
      "Squared L2 Norm of Full Gradient: 648.964566029932\n",
      "Sum of scalar products for gradients in same class: 10828.815595383337\n",
      "Sum of scalar products for gradients in different class: -10179.851029353405\n",
      "Loss: 0.0005720413755625486\n",
      "\n",
      "\n",
      "Iteration: 759\n",
      "Squared L2 Norm of Full Gradient: 647.2680635186989\n",
      "Sum of scalar products for gradients in same class: 10801.845375583947\n",
      "Sum of scalar products for gradients in different class: -10154.577312065248\n",
      "Loss: 0.000571321346797049\n",
      "\n",
      "\n",
      "Iteration: 760\n",
      "Squared L2 Norm of Full Gradient: 645.583764631534\n",
      "Sum of scalar products for gradients in same class: 10774.985403511117\n",
      "Sum of scalar products for gradients in different class: -10129.401638879583\n",
      "Loss: 0.0005706012598238885\n",
      "\n",
      "\n",
      "Iteration: 761\n",
      "Squared L2 Norm of Full Gradient: 643.9078551491402\n",
      "Sum of scalar products for gradients in same class: 10748.309264224317\n",
      "Sum of scalar products for gradients in different class: -10104.401409075177\n",
      "Loss: 0.0005698857130482793\n",
      "\n",
      "\n",
      "Iteration: 762\n",
      "Squared L2 Norm of Full Gradient: 642.2397308581421\n",
      "Sum of scalar products for gradients in same class: 10721.688149866146\n",
      "Sum of scalar products for gradients in different class: -10079.448419008004\n",
      "Loss: 0.0005691703408956528\n",
      "\n",
      "\n",
      "Iteration: 763\n",
      "Squared L2 Norm of Full Gradient: 640.5651773430909\n",
      "Sum of scalar products for gradients in same class: 10695.01910007662\n",
      "Sum of scalar products for gradients in different class: -10054.45392273353\n",
      "Loss: 0.0005684547359123826\n",
      "\n",
      "\n",
      "Iteration: 764\n",
      "Squared L2 Norm of Full Gradient: 638.9139262574645\n",
      "Sum of scalar products for gradients in same class: 10668.668883020651\n",
      "Sum of scalar products for gradients in different class: -10029.754956763187\n",
      "Loss: 0.000567746174056083\n",
      "\n",
      "\n",
      "Iteration: 765\n",
      "Squared L2 Norm of Full Gradient: 637.2618209661596\n",
      "Sum of scalar products for gradients in same class: 10642.331794783455\n",
      "Sum of scalar products for gradients in different class: -10005.069973817295\n",
      "Loss: 0.000567036506254226\n",
      "\n",
      "\n",
      "Iteration: 766\n",
      "Squared L2 Norm of Full Gradient: 635.6175287077203\n",
      "Sum of scalar products for gradients in same class: 10616.11041727601\n",
      "Sum of scalar products for gradients in different class: -9980.49288856829\n",
      "Loss: 0.0005663338233716786\n",
      "\n",
      "\n",
      "Iteration: 767\n",
      "Squared L2 Norm of Full Gradient: 633.9727671889741\n",
      "Sum of scalar products for gradients in same class: 10589.903891593265\n",
      "Sum of scalar products for gradients in different class: -9955.931124404291\n",
      "Loss: 0.000565625261515379\n",
      "\n",
      "\n",
      "Iteration: 768\n",
      "Squared L2 Norm of Full Gradient: 632.3337816261337\n",
      "Sum of scalar products for gradients in same class: 10563.764200756708\n",
      "Sum of scalar products for gradients in different class: -9931.430419130575\n",
      "Loss: 0.0005649179802276194\n",
      "\n",
      "\n",
      "Iteration: 769\n",
      "Squared L2 Norm of Full Gradient: 630.7124372810686\n",
      "Sum of scalar products for gradients in same class: 10537.879061028689\n",
      "Sum of scalar products for gradients in different class: -9907.16662374762\n",
      "Loss: 0.0005642204196192324\n",
      "\n",
      "\n",
      "Iteration: 770\n",
      "Squared L2 Norm of Full Gradient: 629.0940353336955\n",
      "Sum of scalar products for gradients in same class: 10512.038011773155\n",
      "Sum of scalar products for gradients in different class: -9882.94397643946\n",
      "Loss: 0.0005635194829665124\n",
      "\n",
      "\n",
      "Iteration: 771\n",
      "Squared L2 Norm of Full Gradient: 627.4779035689753\n",
      "Sum of scalar products for gradients in same class: 10486.245533843718\n",
      "Sum of scalar products for gradients in different class: -9858.767630274742\n",
      "Loss: 0.000562820874620229\n",
      "\n",
      "\n",
      "Iteration: 772\n",
      "Squared L2 Norm of Full Gradient: 625.8712942031307\n",
      "Sum of scalar products for gradients in same class: 10460.623440983356\n",
      "Sum of scalar products for gradients in different class: -9834.752146780225\n",
      "Loss: 0.0005621250602416694\n",
      "\n",
      "\n",
      "Iteration: 773\n",
      "Squared L2 Norm of Full Gradient: 624.2679833248403\n",
      "Sum of scalar products for gradients in same class: 10435.031922987593\n",
      "Sum of scalar products for gradients in different class: -9810.763939662753\n",
      "Loss: 0.0005614276160486042\n",
      "\n",
      "\n",
      "Iteration: 774\n",
      "Squared L2 Norm of Full Gradient: 622.6715833641501\n",
      "Sum of scalar products for gradients in same class: 10409.59195255577\n",
      "Sum of scalar products for gradients in different class: -9786.92036919162\n",
      "Loss: 0.0005607340717688203\n",
      "\n",
      "\n",
      "Iteration: 775\n",
      "Squared L2 Norm of Full Gradient: 621.0816953913345\n",
      "Sum of scalar products for gradients in same class: 10384.249440850082\n",
      "Sum of scalar products for gradients in different class: -9763.167745458748\n",
      "Loss: 0.0005600405856966972\n",
      "\n",
      "\n",
      "Iteration: 776\n",
      "Squared L2 Norm of Full Gradient: 619.4990618346528\n",
      "Sum of scalar products for gradients in same class: 10358.940345091\n",
      "Sum of scalar products for gradients in different class: -9739.441283256347\n",
      "Loss: 0.0005593538517132401\n",
      "\n",
      "\n",
      "Iteration: 777\n",
      "Squared L2 Norm of Full Gradient: 617.9219558285695\n",
      "Sum of scalar products for gradients in same class: 10333.685532397285\n",
      "Sum of scalar products for gradients in different class: -9715.763576568716\n",
      "Loss: 0.0005586635088548064\n",
      "\n",
      "\n",
      "Iteration: 778\n",
      "Squared L2 Norm of Full Gradient: 616.3567092153571\n",
      "Sum of scalar products for gradients in same class: 10308.75073304481\n",
      "Sum of scalar products for gradients in different class: -9692.394023829453\n",
      "Loss: 0.0005579779390245676\n",
      "\n",
      "\n",
      "Iteration: 779\n",
      "Squared L2 Norm of Full Gradient: 614.7780302210922\n",
      "Sum of scalar products for gradients in same class: 10283.502288630232\n",
      "Sum of scalar products for gradients in different class: -9668.72425840914\n",
      "Loss: 0.0005572927766479552\n",
      "\n",
      "\n",
      "Iteration: 780\n",
      "Squared L2 Norm of Full Gradient: 613.2291479915475\n",
      "Sum of scalar products for gradients in same class: 10258.73869177323\n",
      "Sum of scalar products for gradients in different class: -9645.509543781682\n",
      "Loss: 0.0005566143663600087\n",
      "\n",
      "\n",
      "Iteration: 781\n",
      "Squared L2 Norm of Full Gradient: 611.6766529687593\n",
      "Sum of scalar products for gradients in same class: 10233.910469099166\n",
      "Sum of scalar products for gradients in different class: -9622.233816130407\n",
      "Loss: 0.0005559299024753273\n",
      "\n",
      "\n",
      "Iteration: 782\n",
      "Squared L2 Norm of Full Gradient: 610.1242411267922\n",
      "Sum of scalar products for gradients in same class: 10209.159868808296\n",
      "Sum of scalar products for gradients in different class: -9599.035627681504\n",
      "Loss: 0.0005552499205805361\n",
      "\n",
      "\n",
      "Iteration: 783\n",
      "Squared L2 Norm of Full Gradient: 608.5883882663948\n",
      "Sum of scalar products for gradients in same class: 10184.653807042625\n",
      "Sum of scalar products for gradients in different class: -9576.06541877623\n",
      "Loss: 0.0005545762251131237\n",
      "\n",
      "\n",
      "Iteration: 784\n",
      "Squared L2 Norm of Full Gradient: 607.053437056733\n",
      "Sum of scalar products for gradients in same class: 10160.083743410352\n",
      "Sum of scalar products for gradients in different class: -9553.03030635362\n",
      "Loss: 0.0005538998520933092\n",
      "\n",
      "\n",
      "Iteration: 785\n",
      "Squared L2 Norm of Full Gradient: 605.528402913842\n",
      "Sum of scalar products for gradients in same class: 10135.68693151891\n",
      "Sum of scalar products for gradients in different class: -9530.158528605069\n",
      "Loss: 0.0005532288341782987\n",
      "\n",
      "\n",
      "Iteration: 786\n",
      "Squared L2 Norm of Full Gradient: 604.0017241993919\n",
      "Sum of scalar products for gradients in same class: 10111.299053636354\n",
      "Sum of scalar products for gradients in different class: -9507.297329436962\n",
      "Loss: 0.0005525515880435705\n",
      "\n",
      "\n",
      "Iteration: 787\n",
      "Squared L2 Norm of Full Gradient: 602.4942947559211\n",
      "Sum of scalar products for gradients in same class: 10087.148060543663\n",
      "Sum of scalar products for gradients in different class: -9484.653765787742\n",
      "Loss: 0.0005518850521184504\n",
      "\n",
      "\n",
      "Iteration: 788\n",
      "Squared L2 Norm of Full Gradient: 600.9735989850597\n",
      "Sum of scalar products for gradients in same class: 10062.827469932061\n",
      "Sum of scalar products for gradients in different class: -9461.853870947001\n",
      "Loss: 0.0005512101924978197\n",
      "\n",
      "\n",
      "Iteration: 789\n",
      "Squared L2 Norm of Full Gradient: 599.4734111356083\n",
      "Sum of scalar products for gradients in same class: 10038.782527536296\n",
      "Sum of scalar products for gradients in different class: -9439.309116400687\n",
      "Loss: 0.0005505448789335787\n",
      "\n",
      "\n",
      "Iteration: 790\n",
      "Squared L2 Norm of Full Gradient: 597.9690346907919\n",
      "Sum of scalar products for gradients in same class: 10014.758431298607\n",
      "Sum of scalar products for gradients in different class: -9416.789396607815\n",
      "Loss: 0.0005498763057403266\n",
      "\n",
      "\n",
      "Iteration: 791\n",
      "Squared L2 Norm of Full Gradient: 596.4808025730927\n",
      "Sum of scalar products for gradients in same class: 9990.926731722979\n",
      "Sum of scalar products for gradients in different class: -9394.445929149886\n",
      "Loss: 0.0005492164636962116\n",
      "\n",
      "\n",
      "Iteration: 792\n",
      "Squared L2 Norm of Full Gradient: 594.9920054296999\n",
      "Sum of scalar products for gradients in same class: 9967.061350287018\n",
      "Sum of scalar products for gradients in different class: -9372.069344857318\n",
      "Loss: 0.000548552256077528\n",
      "\n",
      "\n",
      "Iteration: 793\n",
      "Squared L2 Norm of Full Gradient: 593.5115739667126\n",
      "Sum of scalar products for gradients in same class: 9943.37734105936\n",
      "Sum of scalar products for gradients in different class: -9349.865767092648\n",
      "Loss: 0.0005478925304487348\n",
      "\n",
      "\n",
      "Iteration: 794\n",
      "Squared L2 Norm of Full Gradient: 592.033079387169\n",
      "Sum of scalar products for gradients in same class: 9919.710983867582\n",
      "Sum of scalar products for gradients in different class: -9327.677904480413\n",
      "Loss: 0.0005472386837936938\n",
      "\n",
      "\n",
      "Iteration: 795\n",
      "Squared L2 Norm of Full Gradient: 590.555872427216\n",
      "Sum of scalar products for gradients in same class: 9896.072568978372\n",
      "Sum of scalar products for gradients in different class: -9305.516696551156\n",
      "Loss: 0.0005465760477818549\n",
      "\n",
      "\n",
      "Iteration: 796\n",
      "Squared L2 Norm of Full Gradient: 589.0918988787198\n",
      "Sum of scalar products for gradients in same class: 9872.572158522598\n",
      "Sum of scalar products for gradients in different class: -9283.480259643879\n",
      "Loss: 0.0005459193489514291\n",
      "\n",
      "\n",
      "Iteration: 797\n",
      "Squared L2 Norm of Full Gradient: 587.6338109512326\n",
      "Sum of scalar products for gradients in same class: 9849.20786516001\n",
      "Sum of scalar products for gradients in different class: -9261.574054208777\n",
      "Loss: 0.0005452650948427618\n",
      "\n",
      "\n",
      "Iteration: 798\n",
      "Squared L2 Norm of Full Gradient: 586.1789151212579\n",
      "Sum of scalar products for gradients in same class: 9825.924759365877\n",
      "Sum of scalar products for gradients in different class: -9239.745844244619\n",
      "Loss: 0.0005446143331937492\n",
      "\n",
      "\n",
      "Iteration: 799\n",
      "Squared L2 Norm of Full Gradient: 584.7295123291005\n",
      "Sum of scalar products for gradients in same class: 9802.669992270203\n",
      "Sum of scalar products for gradients in different class: -9217.940479941102\n",
      "Loss: 0.0005439636879600585\n",
      "\n",
      "\n",
      "Iteration: 800\n",
      "Squared L2 Norm of Full Gradient: 583.2869708138787\n",
      "Sum of scalar products for gradients in same class: 9779.599787367515\n",
      "Sum of scalar products for gradients in different class: -9196.312816553636\n",
      "Loss: 0.0005433110054582357\n",
      "\n",
      "\n",
      "Iteration: 801\n",
      "Squared L2 Norm of Full Gradient: 581.8454747597607\n",
      "Sum of scalar products for gradients in same class: 9756.484264647344\n",
      "Sum of scalar products for gradients in different class: -9174.638789887584\n",
      "Loss: 0.0005426658317446709\n",
      "\n",
      "\n",
      "Iteration: 802\n",
      "Squared L2 Norm of Full Gradient: 580.4116438741366\n",
      "Sum of scalar products for gradients in same class: 9733.540366961584\n",
      "Sum of scalar products for gradients in different class: -9153.128723087448\n",
      "Loss: 0.0005420194356702268\n",
      "\n",
      "\n",
      "Iteration: 803\n",
      "Squared L2 Norm of Full Gradient: 578.983253424758\n",
      "Sum of scalar products for gradients in same class: 9710.688237675924\n",
      "Sum of scalar products for gradients in different class: -9131.704984251166\n",
      "Loss: 0.0005413735052570701\n",
      "\n",
      "\n",
      "Iteration: 804\n",
      "Squared L2 Norm of Full Gradient: 577.5634985201905\n",
      "Sum of scalar products for gradients in same class: 9687.855582494944\n",
      "Sum of scalar products for gradients in different class: -9110.292083974753\n",
      "Loss: 0.0005407299031503499\n",
      "\n",
      "\n",
      "Iteration: 805\n",
      "Squared L2 Norm of Full Gradient: 576.1495153165924\n",
      "Sum of scalar products for gradients in same class: 9665.208880547601\n",
      "Sum of scalar products for gradients in different class: -9089.059365231009\n",
      "Loss: 0.0005400907248258591\n",
      "\n",
      "\n",
      "Iteration: 806\n",
      "Squared L2 Norm of Full Gradient: 574.7385454155883\n",
      "Sum of scalar products for gradients in same class: 9642.524373900538\n",
      "Sum of scalar products for gradients in different class: -9067.78582848495\n",
      "Loss: 0.0005394526524469256\n",
      "\n",
      "\n",
      "Iteration: 807\n",
      "Squared L2 Norm of Full Gradient: 573.3321368921461\n",
      "Sum of scalar products for gradients in same class: 9620.023675586875\n",
      "Sum of scalar products for gradients in different class: -9046.69153869473\n",
      "Loss: 0.0005388134159147739\n",
      "\n",
      "\n",
      "Iteration: 808\n",
      "Squared L2 Norm of Full Gradient: 571.9319214520547\n",
      "Sum of scalar products for gradients in same class: 9597.508130382343\n",
      "Sum of scalar products for gradients in different class: -9025.576208930288\n",
      "Loss: 0.0005381766241043806\n",
      "\n",
      "\n",
      "Iteration: 809\n",
      "Squared L2 Norm of Full Gradient: 570.5315955914557\n",
      "Sum of scalar products for gradients in same class: 9575.033995429963\n",
      "Sum of scalar products for gradients in different class: -9004.502399838508\n",
      "Loss: 0.0005375421023927629\n",
      "\n",
      "\n",
      "Iteration: 810\n",
      "Squared L2 Norm of Full Gradient: 569.1442708412978\n",
      "Sum of scalar products for gradients in same class: 9552.763023767646\n",
      "Sum of scalar products for gradients in different class: -8983.618752926348\n",
      "Loss: 0.0005369044374674559\n",
      "\n",
      "\n",
      "Iteration: 811\n",
      "Squared L2 Norm of Full Gradient: 567.7588166697533\n",
      "Sum of scalar products for gradients in same class: 9530.518869800966\n",
      "Sum of scalar products for gradients in different class: -8962.760053131213\n",
      "Loss: 0.0005362780066207051\n",
      "\n",
      "\n",
      "Iteration: 812\n",
      "Squared L2 Norm of Full Gradient: 566.38131499663\n",
      "Sum of scalar products for gradients in same class: 9508.387088682663\n",
      "Sum of scalar products for gradients in different class: -8942.005773686033\n",
      "Loss: 0.0005356462206691504\n",
      "\n",
      "\n",
      "Iteration: 813\n",
      "Squared L2 Norm of Full Gradient: 564.9996832376928\n",
      "Sum of scalar products for gradients in same class: 9486.262663663012\n",
      "Sum of scalar products for gradients in different class: -8921.26298042532\n",
      "Loss: 0.0005350153078325093\n",
      "\n",
      "\n",
      "Iteration: 814\n",
      "Squared L2 Norm of Full Gradient: 563.632779933745\n",
      "Sum of scalar products for gradients in same class: 9464.318117118324\n",
      "Sum of scalar products for gradients in different class: -8900.68533718458\n",
      "Loss: 0.0005343880620785058\n",
      "\n",
      "\n",
      "Iteration: 815\n",
      "Squared L2 Norm of Full Gradient: 562.2652707394773\n",
      "Sum of scalar products for gradients in same class: 9442.348274092346\n",
      "Sum of scalar products for gradients in different class: -8880.08300335287\n",
      "Loss: 0.0005337634356692433\n",
      "\n",
      "\n",
      "Iteration: 816\n",
      "Squared L2 Norm of Full Gradient: 560.9054756242585\n",
      "Sum of scalar products for gradients in same class: 9420.504590828983\n",
      "Sum of scalar products for gradients in different class: -8859.599115204725\n",
      "Loss: 0.0005331364809535444\n",
      "\n",
      "\n",
      "Iteration: 817\n",
      "Squared L2 Norm of Full Gradient: 559.5543651883818\n",
      "Sum of scalar products for gradients in same class: 9398.794210198044\n",
      "Sum of scalar products for gradients in different class: -8839.239845009663\n",
      "Loss: 0.0005325174424797297\n",
      "\n",
      "\n",
      "Iteration: 818\n",
      "Squared L2 Norm of Full Gradient: 558.1980343321666\n",
      "Sum of scalar products for gradients in same class: 9377.073915463927\n",
      "Sum of scalar products for gradients in different class: -8818.87588113176\n",
      "Loss: 0.0005318924668245018\n",
      "\n",
      "\n",
      "Iteration: 819\n",
      "Squared L2 Norm of Full Gradient: 556.8543314894814\n",
      "Sum of scalar products for gradients in same class: 9355.457866155073\n",
      "Sum of scalar products for gradients in different class: -8798.603534665592\n",
      "Loss: 0.0005312735447660089\n",
      "\n",
      "\n",
      "Iteration: 820\n",
      "Squared L2 Norm of Full Gradient: 555.5171030256352\n",
      "Sum of scalar products for gradients in same class: 9333.900426248096\n",
      "Sum of scalar products for gradients in different class: -8778.38332322246\n",
      "Loss: 0.0005306564271450043\n",
      "\n",
      "\n",
      "Iteration: 821\n",
      "Squared L2 Norm of Full Gradient: 554.180045269608\n",
      "Sum of scalar products for gradients in same class: 9312.484852223395\n",
      "Sum of scalar products for gradients in different class: -8758.304806953787\n",
      "Loss: 0.0005300369812175632\n",
      "\n",
      "\n",
      "Iteration: 822\n",
      "Squared L2 Norm of Full Gradient: 552.8469305522776\n",
      "Sum of scalar products for gradients in same class: 9291.027161180842\n",
      "Sum of scalar products for gradients in different class: -8738.180230628564\n",
      "Loss: 0.0005294239381328225\n",
      "\n",
      "\n",
      "Iteration: 823\n",
      "Squared L2 Norm of Full Gradient: 551.5232151991368\n",
      "Sum of scalar products for gradients in same class: 9269.750393154533\n",
      "Sum of scalar products for gradients in different class: -8718.227177955396\n",
      "Loss: 0.0005288068205118179\n",
      "\n",
      "\n",
      "Iteration: 824\n",
      "Squared L2 Norm of Full Gradient: 550.2049340733938\n",
      "Sum of scalar products for gradients in same class: 9248.570426919836\n",
      "Sum of scalar products for gradients in different class: -8698.365492846442\n",
      "Loss: 0.0005281969788484275\n",
      "\n",
      "\n",
      "Iteration: 825\n",
      "Squared L2 Norm of Full Gradient: 548.8852810715944\n",
      "Sum of scalar products for gradients in same class: 9227.362826741111\n",
      "Sum of scalar products for gradients in different class: -8678.477545669517\n",
      "Loss: 0.0005275835283100605\n",
      "\n",
      "\n",
      "Iteration: 826\n",
      "Squared L2 Norm of Full Gradient: 547.5842622011296\n",
      "Sum of scalar products for gradients in same class: 9206.45442909071\n",
      "Sum of scalar products for gradients in different class: -8658.870166889581\n",
      "Loss: 0.0005269775865599513\n",
      "\n",
      "\n",
      "Iteration: 827\n",
      "Squared L2 Norm of Full Gradient: 546.2755144671282\n",
      "Sum of scalar products for gradients in same class: 9185.37899927505\n",
      "Sum of scalar products for gradients in different class: -8639.103484807922\n",
      "Loss: 0.0005263672210276127\n",
      "\n",
      "\n",
      "Iteration: 828\n",
      "Squared L2 Norm of Full Gradient: 544.9734085835516\n",
      "Sum of scalar products for gradients in same class: 9164.377876883562\n",
      "Sum of scalar products for gradients in different class: -8619.40446830001\n",
      "Loss: 0.0005257636657916009\n",
      "\n",
      "\n",
      "Iteration: 829\n",
      "Squared L2 Norm of Full Gradient: 543.6799721502211\n",
      "Sum of scalar products for gradients in same class: 9143.578214252902\n",
      "Sum of scalar products for gradients in different class: -8599.898242102681\n",
      "Loss: 0.0005251605180092156\n",
      "\n",
      "\n",
      "Iteration: 830\n",
      "Squared L2 Norm of Full Gradient: 542.3839857636485\n",
      "Sum of scalar products for gradients in same class: 9122.757927260638\n",
      "Sum of scalar products for gradients in different class: -8580.37394149699\n",
      "Loss: 0.0005245514330454171\n",
      "\n",
      "\n",
      "Iteration: 831\n",
      "Squared L2 Norm of Full Gradient: 541.0934502061027\n",
      "Sum of scalar products for gradients in same class: 9101.984512806092\n",
      "Sum of scalar products for gradients in different class: -8560.891062599989\n",
      "Loss: 0.0005239470046944916\n",
      "\n",
      "\n",
      "Iteration: 832\n",
      "Squared L2 Norm of Full Gradient: 539.8188098874525\n",
      "Sum of scalar products for gradients in same class: 9081.44100256588\n",
      "Sum of scalar products for gradients in different class: -8541.622192678427\n",
      "Loss: 0.0005233516567386687\n",
      "\n",
      "\n",
      "Iteration: 833\n",
      "Squared L2 Norm of Full Gradient: 538.5331020255726\n",
      "Sum of scalar products for gradients in same class: 9060.731146231228\n",
      "Sum of scalar products for gradients in different class: -8522.198044205656\n",
      "Loss: 0.0005227506626397371\n",
      "\n",
      "\n",
      "Iteration: 834\n",
      "Squared L2 Norm of Full Gradient: 537.2621901012608\n",
      "Sum of scalar products for gradients in same class: 9040.32262004237\n",
      "Sum of scalar products for gradients in different class: -8503.06042994111\n",
      "Loss: 0.0005221514729782939\n",
      "\n",
      "\n",
      "Iteration: 835\n",
      "Squared L2 Norm of Full Gradient: 535.9980785692787\n",
      "Sum of scalar products for gradients in same class: 9019.87239050162\n",
      "Sum of scalar products for gradients in different class: -8483.87431193234\n",
      "Loss: 0.0005215569399297237\n",
      "\n",
      "\n",
      "Iteration: 836\n",
      "Squared L2 Norm of Full Gradient: 534.7303396323696\n",
      "Sum of scalar products for gradients in same class: 8999.526355273145\n",
      "Sum of scalar products for gradients in different class: -8464.796015640775\n",
      "Loss: 0.0005209605442360044\n",
      "\n",
      "\n",
      "Iteration: 837\n",
      "Squared L2 Norm of Full Gradient: 533.466480598785\n",
      "Sum of scalar products for gradients in same class: 8979.179769889277\n",
      "Sum of scalar products for gradients in different class: -8445.713289290492\n",
      "Loss: 0.0005203656619414687\n",
      "\n",
      "\n",
      "Iteration: 838\n",
      "Squared L2 Norm of Full Gradient: 532.2152934103542\n",
      "Sum of scalar products for gradients in same class: 8959.00160024707\n",
      "Sum of scalar products for gradients in different class: -8426.786306836715\n",
      "Loss: 0.0005197743885219097\n",
      "\n",
      "\n",
      "Iteration: 839\n",
      "Squared L2 Norm of Full Gradient: 530.9626744810121\n",
      "Sum of scalar products for gradients in same class: 8938.785775287597\n",
      "Sum of scalar products for gradients in different class: -8407.823100806585\n",
      "Loss: 0.0005191846867091954\n",
      "\n",
      "\n",
      "Iteration: 840\n",
      "Squared L2 Norm of Full Gradient: 529.717325986745\n",
      "Sum of scalar products for gradients in same class: 8918.737777264258\n",
      "Sum of scalar products for gradients in different class: -8389.020451277513\n",
      "Loss: 0.0005185937625356019\n",
      "\n",
      "\n",
      "Iteration: 841\n",
      "Squared L2 Norm of Full Gradient: 528.4763335792959\n",
      "Sum of scalar products for gradients in same class: 8898.773542167095\n",
      "Sum of scalar products for gradients in different class: -8370.2972085878\n",
      "Loss: 0.000518006447236985\n",
      "\n",
      "\n",
      "Iteration: 842\n",
      "Squared L2 Norm of Full Gradient: 527.2389863359276\n",
      "Sum of scalar products for gradients in same class: 8878.82785411521\n",
      "Sum of scalar products for gradients in different class: -8351.588867779283\n",
      "Loss: 0.0005174199468456209\n",
      "\n",
      "\n",
      "Iteration: 843\n",
      "Squared L2 Norm of Full Gradient: 526.0018644738593\n",
      "Sum of scalar products for gradients in same class: 8858.82528610677\n",
      "Sum of scalar products for gradients in different class: -8332.823421632911\n",
      "Loss: 0.0005168329807929695\n",
      "\n",
      "\n",
      "Iteration: 844\n",
      "Squared L2 Norm of Full Gradient: 524.7721379986615\n",
      "Sum of scalar products for gradients in same class: 8839.065732227431\n",
      "Sum of scalar products for gradients in different class: -8314.29359422877\n",
      "Loss: 0.0005162511952221394\n",
      "\n",
      "\n",
      "Iteration: 845\n",
      "Squared L2 Norm of Full Gradient: 523.5540630035721\n",
      "Sum of scalar products for gradients in same class: 8819.40633052387\n",
      "Sum of scalar products for gradients in different class: -8295.852267520298\n",
      "Loss: 0.000515668245498091\n",
      "\n",
      "\n",
      "Iteration: 846\n",
      "Squared L2 Norm of Full Gradient: 522.3352237271356\n",
      "Sum of scalar products for gradients in same class: 8799.643724447687\n",
      "Sum of scalar products for gradients in different class: -8277.308500720552\n",
      "Loss: 0.0005150859942659736\n",
      "\n",
      "\n",
      "Iteration: 847\n",
      "Squared L2 Norm of Full Gradient: 521.1160632026476\n",
      "Sum of scalar products for gradients in same class: 8780.08163312023\n",
      "Sum of scalar products for gradients in different class: -8258.965569917582\n",
      "Loss: 0.0005145061877556145\n",
      "\n",
      "\n",
      "Iteration: 848\n",
      "Squared L2 Norm of Full Gradient: 519.9041548112873\n",
      "Sum of scalar products for gradients in same class: 8760.520807188928\n",
      "Sum of scalar products for gradients in different class: -8240.616652377641\n",
      "Loss: 0.0005139259737916291\n",
      "\n",
      "\n",
      "Iteration: 849\n",
      "Squared L2 Norm of Full Gradient: 518.69704556129\n",
      "Sum of scalar products for gradients in same class: 8741.090910695162\n",
      "Sum of scalar products for gradients in different class: -8222.393865133872\n",
      "Loss: 0.000513348204549402\n",
      "\n",
      "\n",
      "Iteration: 850\n",
      "Squared L2 Norm of Full Gradient: 517.4986286796629\n",
      "Sum of scalar products for gradients in same class: 8721.703771651293\n",
      "Sum of scalar products for gradients in different class: -8204.20514297163\n",
      "Loss: 0.0005127763142809272\n",
      "\n",
      "\n",
      "Iteration: 851\n",
      "Squared L2 Norm of Full Gradient: 516.2946635695553\n",
      "Sum of scalar products for gradients in same class: 8702.31510421489\n",
      "Sum of scalar products for gradients in different class: -8186.020440645334\n",
      "Loss: 0.0005121981375850737\n",
      "\n",
      "\n",
      "Iteration: 852\n",
      "Squared L2 Norm of Full Gradient: 515.1060395996647\n",
      "Sum of scalar products for gradients in same class: 8683.142473503674\n",
      "Sum of scalar products for gradients in different class: -8168.03643390401\n",
      "Loss: 0.0005116290412843227\n",
      "\n",
      "\n",
      "Iteration: 853\n",
      "Squared L2 Norm of Full Gradient: 513.9107429902688\n",
      "Sum of scalar products for gradients in same class: 8663.834064384744\n",
      "Sum of scalar products for gradients in different class: -8149.923321394475\n",
      "Loss: 0.0005110502825118601\n",
      "\n",
      "\n",
      "Iteration: 854\n",
      "Squared L2 Norm of Full Gradient: 512.7307416424301\n",
      "Sum of scalar products for gradients in same class: 8644.801620028371\n",
      "Sum of scalar products for gradients in different class: -8132.070878385941\n",
      "Loss: 0.0005104836309328675\n",
      "\n",
      "\n",
      "Iteration: 855\n",
      "Squared L2 Norm of Full Gradient: 511.54622961121277\n",
      "Sum of scalar products for gradients in same class: 8625.673323742314\n",
      "Sum of scalar products for gradients in different class: -8114.127094131101\n",
      "Loss: 0.0005099137779325247\n",
      "\n",
      "\n",
      "Iteration: 856\n",
      "Squared L2 Norm of Full Gradient: 510.36920609703884\n",
      "Sum of scalar products for gradients in same class: 8606.641196231521\n",
      "Sum of scalar products for gradients in different class: -8096.271990134483\n",
      "Loss: 0.0005093435174785554\n",
      "\n",
      "\n",
      "Iteration: 857\n",
      "Squared L2 Norm of Full Gradient: 509.1894064328844\n",
      "Sum of scalar products for gradients in same class: 8587.619985087214\n",
      "Sum of scalar products for gradients in different class: -8078.43057865433\n",
      "Loss: 0.0005087740137241781\n",
      "\n",
      "\n",
      "Iteration: 858\n",
      "Squared L2 Norm of Full Gradient: 508.0255026911036\n",
      "Sum of scalar products for gradients in same class: 8568.840871681947\n",
      "Sum of scalar products for gradients in different class: -8060.815368990843\n",
      "Loss: 0.0005082131829112768\n",
      "\n",
      "\n",
      "Iteration: 859\n",
      "Squared L2 Norm of Full Gradient: 506.8617283396634\n",
      "Sum of scalar products for gradients in same class: 8550.031122521996\n",
      "Sum of scalar products for gradients in different class: -8043.169394182332\n",
      "Loss: 0.0005076492670923471\n",
      "\n",
      "\n",
      "Iteration: 860\n",
      "Squared L2 Norm of Full Gradient: 505.7026340735356\n",
      "Sum of scalar products for gradients in same class: 8531.235514942728\n",
      "Sum of scalar products for gradients in different class: -8025.532880869192\n",
      "Loss: 0.0005070848856121302\n",
      "\n",
      "\n",
      "Iteration: 861\n",
      "Squared L2 Norm of Full Gradient: 504.5432386035245\n",
      "Sum of scalar products for gradients in same class: 8512.557220742296\n",
      "Sum of scalar products for gradients in different class: -8008.013982138771\n",
      "Loss: 0.0005065257428213954\n",
      "\n",
      "\n",
      "Iteration: 862\n",
      "Squared L2 Norm of Full Gradient: 503.386115161833\n",
      "Sum of scalar products for gradients in same class: 8493.84386101699\n",
      "Sum of scalar products for gradients in different class: -7990.457745855158\n",
      "Loss: 0.000505962991155684\n",
      "\n",
      "\n",
      "Iteration: 863\n",
      "Squared L2 Norm of Full Gradient: 502.23476557307004\n",
      "Sum of scalar products for gradients in same class: 8475.251126102437\n",
      "Sum of scalar products for gradients in different class: -7973.016360529367\n",
      "Loss: 0.0005054048961028457\n",
      "\n",
      "\n",
      "Iteration: 864\n",
      "Squared L2 Norm of Full Gradient: 501.09737223260163\n",
      "Sum of scalar products for gradients in same class: 8456.866908980945\n",
      "Sum of scalar products for gradients in different class: -7955.769536748343\n",
      "Loss: 0.0005048501188866794\n",
      "\n",
      "\n",
      "Iteration: 865\n",
      "Squared L2 Norm of Full Gradient: 499.95905056834454\n",
      "Sum of scalar products for gradients in same class: 8438.442155852696\n",
      "Sum of scalar products for gradients in different class: -7938.483105284351\n",
      "Loss: 0.0005042913253419101\n",
      "\n",
      "\n",
      "Iteration: 866\n",
      "Squared L2 Norm of Full Gradient: 498.82176771725426\n",
      "Sum of scalar products for gradients in same class: 8420.072986051564\n",
      "Sum of scalar products for gradients in different class: -7921.25121833431\n",
      "Loss: 0.0005037380033172667\n",
      "\n",
      "\n",
      "Iteration: 867\n",
      "Squared L2 Norm of Full Gradient: 497.6868010773469\n",
      "Sum of scalar products for gradients in same class: 8401.707813415607\n",
      "Sum of scalar products for gradients in different class: -7904.02101233826\n",
      "Loss: 0.0005031811888329685\n",
      "\n",
      "\n",
      "Iteration: 868\n",
      "Squared L2 Norm of Full Gradient: 496.5578023698763\n",
      "Sum of scalar products for gradients in same class: 8383.437214154535\n",
      "Sum of scalar products for gradients in different class: -7886.879411784659\n",
      "Loss: 0.0005026295548304915\n",
      "\n",
      "\n",
      "Iteration: 869\n",
      "Squared L2 Norm of Full Gradient: 495.4324631208001\n",
      "Sum of scalar products for gradients in same class: 8365.269608626928\n",
      "Sum of scalar products for gradients in different class: -7869.837145506128\n",
      "Loss: 0.0005020758253522217\n",
      "\n",
      "\n",
      "Iteration: 870\n",
      "Squared L2 Norm of Full Gradient: 494.31442218076336\n",
      "Sum of scalar products for gradients in same class: 8347.174001719763\n",
      "Sum of scalar products for gradients in different class: -7852.859579538999\n",
      "Loss: 0.0005015269853174686\n",
      "\n",
      "\n",
      "Iteration: 871\n",
      "Squared L2 Norm of Full Gradient: 493.19188346673036\n",
      "Sum of scalar products for gradients in same class: 8329.07378156568\n",
      "Sum of scalar products for gradients in different class: -7835.881898098949\n",
      "Loss: 0.0005009800079278648\n",
      "\n",
      "\n",
      "Iteration: 872\n",
      "Squared L2 Norm of Full Gradient: 492.0843293486141\n",
      "Sum of scalar products for gradients in same class: 8311.102670798755\n",
      "Sum of scalar products for gradients in different class: -7819.018341450141\n",
      "Loss: 0.0005004331469535828\n",
      "\n",
      "\n",
      "Iteration: 873\n",
      "Squared L2 Norm of Full Gradient: 490.97007481200853\n",
      "Sum of scalar products for gradients in same class: 8293.11087010696\n",
      "Sum of scalar products for gradients in different class: -7802.140795294952\n",
      "Loss: 0.0004998838412575424\n",
      "\n",
      "\n",
      "Iteration: 874\n",
      "Squared L2 Norm of Full Gradient: 489.86155802012945\n",
      "Sum of scalar products for gradients in same class: 8275.171413888147\n",
      "Sum of scalar products for gradients in different class: -7785.309855868018\n",
      "Loss: 0.0004993384936824441\n",
      "\n",
      "\n",
      "Iteration: 875\n",
      "Squared L2 Norm of Full Gradient: 488.76432991197\n",
      "Sum of scalar products for gradients in same class: 8257.395423884274\n",
      "Sum of scalar products for gradients in different class: -7768.631093972304\n",
      "Loss: 0.0004987951833754778\n",
      "\n",
      "\n",
      "Iteration: 876\n",
      "Squared L2 Norm of Full Gradient: 487.6618454901072\n",
      "Sum of scalar products for gradients in same class: 8239.593892725708\n",
      "Sum of scalar products for gradients in different class: -7751.932047235601\n",
      "Loss: 0.0004982550162822008\n",
      "\n",
      "\n",
      "Iteration: 877\n",
      "Squared L2 Norm of Full Gradient: 486.56758994948177\n",
      "Sum of scalar products for gradients in same class: 8221.856209939448\n",
      "Sum of scalar products for gradients in different class: -7735.288619989966\n",
      "Loss: 0.0004977108328603208\n",
      "\n",
      "\n",
      "Iteration: 878\n",
      "Squared L2 Norm of Full Gradient: 485.47691691143336\n",
      "Sum of scalar products for gradients in same class: 8204.185370265874\n",
      "Sum of scalar products for gradients in different class: -7718.70845335444\n",
      "Loss: 0.0004971734015271068\n",
      "\n",
      "\n",
      "Iteration: 879\n",
      "Squared L2 Norm of Full Gradient: 484.3993056516374\n",
      "Sum of scalar products for gradients in same class: 8186.746034487129\n",
      "Sum of scalar products for gradients in different class: -7702.346728835491\n",
      "Loss: 0.0004966336418874562\n",
      "\n",
      "\n",
      "Iteration: 880\n",
      "Squared L2 Norm of Full Gradient: 483.30880255310694\n",
      "Sum of scalar products for gradients in same class: 8169.086604810197\n",
      "Sum of scalar products for gradients in different class: -7685.77780225709\n",
      "Loss: 0.0004960958031006157\n",
      "\n",
      "\n",
      "Iteration: 881\n",
      "Squared L2 Norm of Full Gradient: 482.2227115558089\n",
      "Sum of scalar products for gradients in same class: 8151.510373008219\n",
      "Sum of scalar products for gradients in different class: -7669.28766145241\n",
      "Loss: 0.0004955549375154078\n",
      "\n",
      "\n",
      "Iteration: 882\n",
      "Squared L2 Norm of Full Gradient: 481.14938945859103\n",
      "Sum of scalar products for gradients in same class: 8134.151122779623\n",
      "Sum of scalar products for gradients in different class: -7653.001733321032\n",
      "Loss: 0.000495020707603544\n",
      "\n",
      "\n",
      "Iteration: 883\n",
      "Squared L2 Norm of Full Gradient: 480.0774303475955\n",
      "Sum of scalar products for gradients in same class: 8116.740125714845\n",
      "Sum of scalar products for gradients in different class: -7636.662695367249\n",
      "Loss: 0.0004944860702380538\n",
      "\n",
      "\n",
      "Iteration: 884\n",
      "Squared L2 Norm of Full Gradient: 479.00992277312616\n",
      "Sum of scalar products for gradients in same class: 8099.428859880621\n",
      "Sum of scalar products for gradients in different class: -7620.4189371074945\n",
      "Loss: 0.0004939530044794083\n",
      "\n",
      "\n",
      "Iteration: 885\n",
      "Squared L2 Norm of Full Gradient: 477.94568830076605\n",
      "Sum of scalar products for gradients in same class: 8082.24228430769\n",
      "Sum of scalar products for gradients in different class: -7604.296596006924\n",
      "Loss: 0.0004934226744808257\n",
      "\n",
      "\n",
      "Iteration: 886\n",
      "Squared L2 Norm of Full Gradient: 476.88372032108964\n",
      "Sum of scalar products for gradients in same class: 8064.9650210156115\n",
      "Sum of scalar products for gradients in different class: -7588.081300694522\n",
      "Loss: 0.0004928912385366857\n",
      "\n",
      "\n",
      "Iteration: 887\n",
      "Squared L2 Norm of Full Gradient: 475.8235991613619\n",
      "Sum of scalar products for gradients in same class: 8047.796030341102\n",
      "Sum of scalar products for gradients in different class: -7571.97243117974\n",
      "Loss: 0.0004923606174997985\n",
      "\n",
      "\n",
      "Iteration: 888\n",
      "Squared L2 Norm of Full Gradient: 474.7699772656233\n",
      "Sum of scalar products for gradients in same class: 8030.695722097696\n",
      "Sum of scalar products for gradients in different class: -7555.925744832072\n",
      "Loss: 0.0004918326740153134\n",
      "\n",
      "\n",
      "Iteration: 889\n",
      "Squared L2 Norm of Full Gradient: 473.725493820908\n",
      "Sum of scalar products for gradients in same class: 8013.755319342523\n",
      "Sum of scalar products for gradients in different class: -7540.029825521615\n",
      "Loss: 0.0004913071170449257\n",
      "\n",
      "\n",
      "Iteration: 890\n",
      "Squared L2 Norm of Full Gradient: 472.67245706405083\n",
      "Sum of scalar products for gradients in same class: 7996.732234599299\n",
      "Sum of scalar products for gradients in different class: -7524.059777535248\n",
      "Loss: 0.0004907812108285725\n",
      "\n",
      "\n",
      "Iteration: 891\n",
      "Squared L2 Norm of Full Gradient: 471.6294562547446\n",
      "Sum of scalar products for gradients in same class: 7979.820086592459\n",
      "Sum of scalar products for gradients in different class: -7508.1906303377145\n",
      "Loss: 0.0004902561195194721\n",
      "\n",
      "\n",
      "Iteration: 892\n",
      "Squared L2 Norm of Full Gradient: 470.591414077222\n",
      "Sum of scalar products for gradients in same class: 7962.988995168483\n",
      "Sum of scalar products for gradients in different class: -7492.397581091261\n",
      "Loss: 0.0004897333565168083\n",
      "\n",
      "\n",
      "Iteration: 893\n",
      "Squared L2 Norm of Full Gradient: 469.5487292236976\n",
      "Sum of scalar products for gradients in same class: 7946.0588920078735\n",
      "Sum of scalar products for gradients in different class: -7476.510162784176\n",
      "Loss: 0.0004892090219072998\n",
      "\n",
      "\n",
      "Iteration: 894\n",
      "Squared L2 Norm of Full Gradient: 468.51091640757295\n",
      "Sum of scalar products for gradients in same class: 7929.253864654763\n",
      "Sum of scalar products for gradients in different class: -7460.74294824719\n",
      "Loss: 0.0004886843380518258\n",
      "\n",
      "\n",
      "Iteration: 895\n",
      "Squared L2 Norm of Full Gradient: 467.48703596660926\n",
      "Sum of scalar products for gradients in same class: 7912.656814927102\n",
      "Sum of scalar products for gradients in different class: -7445.169778960492\n",
      "Loss: 0.0004881670465692878\n",
      "\n",
      "\n",
      "Iteration: 896\n",
      "Squared L2 Norm of Full Gradient: 466.4602384877071\n",
      "Sum of scalar products for gradients in same class: 7895.988271988773\n",
      "Sum of scalar products for gradients in different class: -7429.528033501066\n",
      "Loss: 0.0004876475140918046\n",
      "\n",
      "\n",
      "Iteration: 897\n",
      "Squared L2 Norm of Full Gradient: 465.4363804459572\n",
      "Sum of scalar products for gradients in same class: 7879.3692769317495\n",
      "Sum of scalar products for gradients in different class: -7413.932896485792\n",
      "Loss: 0.0004871267592534423\n",
      "\n",
      "\n",
      "Iteration: 898\n",
      "Squared L2 Norm of Full Gradient: 464.4187441911199\n",
      "Sum of scalar products for gradients in same class: 7862.859387164907\n",
      "Sum of scalar products for gradients in different class: -7398.440642973787\n",
      "Loss: 0.0004866139206569642\n",
      "\n",
      "\n",
      "Iteration: 899\n",
      "Squared L2 Norm of Full Gradient: 463.3977051537986\n",
      "Sum of scalar products for gradients in same class: 7846.2627228192405\n",
      "Sum of scalar products for gradients in different class: -7382.865017665442\n",
      "Loss: 0.0004860955523326993\n",
      "\n",
      "\n",
      "Iteration: 900\n",
      "Squared L2 Norm of Full Gradient: 462.39148841009956\n",
      "Sum of scalar products for gradients in same class: 7829.899838275481\n",
      "Sum of scalar products for gradients in different class: -7367.508349865381\n",
      "Loss: 0.00048558422713540494\n",
      "\n",
      "\n",
      "Iteration: 901\n",
      "Squared L2 Norm of Full Gradient: 461.3819405844297\n",
      "Sum of scalar products for gradients in same class: 7813.532440104527\n",
      "Sum of scalar products for gradients in different class: -7352.150499520098\n",
      "Loss: 0.0004850686527788639\n",
      "\n",
      "\n",
      "Iteration: 902\n",
      "Squared L2 Norm of Full Gradient: 460.36711181849023\n",
      "Sum of scalar products for gradients in same class: 7797.101645640779\n",
      "Sum of scalar products for gradients in different class: -7336.7345338222885\n",
      "Loss: 0.00048455302021466196\n",
      "\n",
      "\n",
      "Iteration: 903\n",
      "Squared L2 Norm of Full Gradient: 459.37155095336857\n",
      "Sum of scalar products for gradients in same class: 7780.914528636247\n",
      "Sum of scalar products for gradients in different class: -7321.542977682879\n",
      "Loss: 0.0004840441688429564\n",
      "\n",
      "\n",
      "Iteration: 904\n",
      "Squared L2 Norm of Full Gradient: 458.37110570866207\n",
      "Sum of scalar products for gradients in same class: 7764.711862218502\n",
      "Sum of scalar products for gradients in different class: -7306.34075650984\n",
      "Loss: 0.0004835336876567453\n",
      "\n",
      "\n",
      "Iteration: 905\n",
      "Squared L2 Norm of Full Gradient: 457.3777065757313\n",
      "Sum of scalar products for gradients in same class: 7748.569038790138\n",
      "Sum of scalar products for gradients in different class: -7291.191332214406\n",
      "Loss: 0.00048302760114893317\n",
      "\n",
      "\n",
      "Iteration: 906\n",
      "Squared L2 Norm of Full Gradient: 456.38465163065484\n",
      "Sum of scalar products for gradients in same class: 7732.422970002799\n",
      "Sum of scalar products for gradients in different class: -7276.038318372144\n",
      "Loss: 0.0004825162759516388\n",
      "\n",
      "\n",
      "Iteration: 907\n",
      "Squared L2 Norm of Full Gradient: 455.3930015356891\n",
      "Sum of scalar products for gradients in same class: 7716.245893310076\n",
      "Sum of scalar products for gradients in different class: -7260.852891774387\n",
      "Loss: 0.0004820087051484734\n",
      "\n",
      "\n",
      "Iteration: 908\n",
      "Squared L2 Norm of Full Gradient: 454.4065771278838\n",
      "Sum of scalar products for gradients in same class: 7700.2348708945465\n",
      "Sum of scalar products for gradients in different class: -7245.828293766663\n",
      "Loss: 0.00048150503425858915\n",
      "\n",
      "\n",
      "Iteration: 909\n",
      "Squared L2 Norm of Full Gradient: 453.4210597651545\n",
      "Sum of scalar products for gradients in same class: 7684.265814042873\n",
      "Sum of scalar products for gradients in different class: -7230.8447542777185\n",
      "Loss: 0.0004810012469533831\n",
      "\n",
      "\n",
      "Iteration: 910\n",
      "Squared L2 Norm of Full Gradient: 452.4500005790069\n",
      "Sum of scalar products for gradients in same class: 7668.430367835943\n",
      "Sum of scalar products for gradients in different class: -7215.980367256936\n",
      "Loss: 0.00048050066106952727\n",
      "\n",
      "\n",
      "Iteration: 911\n",
      "Squared L2 Norm of Full Gradient: 451.47155266023765\n",
      "Sum of scalar products for gradients in same class: 7652.5384246741905\n",
      "Sum of scalar products for gradients in different class: -7201.066872013953\n",
      "Loss: 0.0004799930320587009\n",
      "\n",
      "\n",
      "Iteration: 912\n",
      "Squared L2 Norm of Full Gradient: 450.4956212564175\n",
      "Sum of scalar products for gradients in same class: 7636.6923245599155\n",
      "Sum of scalar products for gradients in different class: -7186.196703303498\n",
      "Loss: 0.000479493202874437\n",
      "\n",
      "\n",
      "Iteration: 913\n",
      "Squared L2 Norm of Full Gradient: 449.52414273181057\n",
      "Sum of scalar products for gradients in same class: 7620.876715600903\n",
      "Sum of scalar products for gradients in different class: -7171.352572869092\n",
      "Loss: 0.00047899267519824207\n",
      "\n",
      "\n",
      "Iteration: 914\n",
      "Squared L2 Norm of Full Gradient: 448.5613072801243\n",
      "Sum of scalar products for gradients in same class: 7605.217017827786\n",
      "Sum of scalar products for gradients in different class: -7156.655710547661\n",
      "Loss: 0.0004784925258718431\n",
      "\n",
      "\n",
      "Iteration: 915\n",
      "Squared L2 Norm of Full Gradient: 447.59369328204775\n",
      "Sum of scalar products for gradients in same class: 7589.48529942855\n",
      "Sum of scalar products for gradients in different class: -7141.891606146502\n",
      "Loss: 0.00047799275489524007\n",
      "\n",
      "\n",
      "Iteration: 916\n",
      "Squared L2 Norm of Full Gradient: 446.63429909620027\n",
      "Sum of scalar products for gradients in same class: 7573.907030634765\n",
      "Sum of scalar products for gradients in different class: -7127.272731538565\n",
      "Loss: 0.0004774993285536766\n",
      "\n",
      "\n",
      "Iteration: 917\n",
      "Squared L2 Norm of Full Gradient: 445.67899444956856\n",
      "Sum of scalar products for gradients in same class: 7558.36895453118\n",
      "Sum of scalar products for gradients in different class: -7112.689960081611\n",
      "Loss: 0.00047700473805889487\n",
      "\n",
      "\n",
      "Iteration: 918\n",
      "Squared L2 Norm of Full Gradient: 444.71827687068435\n",
      "Sum of scalar products for gradients in same class: 7542.765048620222\n",
      "Sum of scalar products for gradients in different class: -7098.046771749538\n",
      "Loss: 0.00047650773194618523\n",
      "\n",
      "\n",
      "Iteration: 919\n",
      "Squared L2 Norm of Full Gradient: 443.7723373455847\n",
      "Sum of scalar products for gradients in same class: 7527.389523442661\n",
      "Sum of scalar products for gradients in different class: -7083.617186097076\n",
      "Loss: 0.00047601666301488876\n",
      "\n",
      "\n",
      "Iteration: 920\n",
      "Squared L2 Norm of Full Gradient: 442.8221068261337\n",
      "Sum of scalar products for gradients in same class: 7511.921040756362\n",
      "Sum of scalar products for gradients in different class: -7069.098933930229\n",
      "Loss: 0.00047552207252010703\n",
      "\n",
      "\n",
      "Iteration: 921\n",
      "Squared L2 Norm of Full Gradient: 441.87546075715\n",
      "Sum of scalar products for gradients in same class: 7496.540440295365\n",
      "Sum of scalar products for gradients in different class: -7054.664979538215\n",
      "Loss: 0.00047502981033176184\n",
      "\n",
      "\n",
      "Iteration: 922\n",
      "Squared L2 Norm of Full Gradient: 440.93567510581124\n",
      "Sum of scalar products for gradients in same class: 7481.225755796324\n",
      "Sum of scalar products for gradients in different class: -7040.290080690513\n",
      "Loss: 0.0004745392070617527\n",
      "\n",
      "\n",
      "Iteration: 923\n",
      "Squared L2 Norm of Full Gradient: 439.9976100495551\n",
      "Sum of scalar products for gradients in same class: 7465.934677877293\n",
      "Sum of scalar products for gradients in different class: -7025.937067827738\n",
      "Loss: 0.00047404924407601357\n",
      "\n",
      "\n",
      "Iteration: 924\n",
      "Squared L2 Norm of Full Gradient: 439.06078369253373\n",
      "Sum of scalar products for gradients in same class: 7450.700997648805\n",
      "Sum of scalar products for gradients in different class: -7011.6402139562715\n",
      "Loss: 0.0004735638212878257\n",
      "\n",
      "\n",
      "Iteration: 925\n",
      "Squared L2 Norm of Full Gradient: 438.12838915782413\n",
      "Sum of scalar products for gradients in same class: 7435.472353507057\n",
      "Sum of scalar products for gradients in different class: -6997.343964349233\n",
      "Loss: 0.00047307193744927645\n",
      "\n",
      "\n",
      "Iteration: 926\n",
      "Squared L2 Norm of Full Gradient: 437.19953810074367\n",
      "Sum of scalar products for gradients in same class: 7420.416724730581\n",
      "Sum of scalar products for gradients in different class: -6983.217186629838\n",
      "Loss: 0.00047258724225685\n",
      "\n",
      "\n",
      "Iteration: 927\n",
      "Squared L2 Norm of Full Gradient: 436.27087591094096\n",
      "Sum of scalar products for gradients in same class: 7405.2878775235595\n",
      "Sum of scalar products for gradients in different class: -6969.0170016126185\n",
      "Loss: 0.00047210173215717077\n",
      "\n",
      "\n",
      "Iteration: 928\n",
      "Squared L2 Norm of Full Gradient: 435.3489317919739\n",
      "Sum of scalar products for gradients in same class: 7390.303756901217\n",
      "Sum of scalar products for gradients in different class: -6954.954825109243\n",
      "Loss: 0.0004716178809758276\n",
      "\n",
      "\n",
      "Iteration: 929\n",
      "Squared L2 Norm of Full Gradient: 434.4297915674397\n",
      "Sum of scalar products for gradients in same class: 7375.327321636285\n",
      "Sum of scalar products for gradients in different class: -6940.897530068845\n",
      "Loss: 0.00047113472828641534\n",
      "\n",
      "\n",
      "Iteration: 930\n",
      "Squared L2 Norm of Full Gradient: 433.51329058525516\n",
      "Sum of scalar products for gradients in same class: 7360.369658123262\n",
      "Sum of scalar products for gradients in different class: -6926.856367538006\n",
      "Loss: 0.0004706559993792325\n",
      "\n",
      "\n",
      "Iteration: 931\n",
      "Squared L2 Norm of Full Gradient: 432.59823342994787\n",
      "Sum of scalar products for gradients in same class: 7345.475498040294\n",
      "Sum of scalar products for gradients in different class: -6912.877264610346\n",
      "Loss: 0.00047017514589242637\n",
      "\n",
      "\n",
      "Iteration: 932\n",
      "Squared L2 Norm of Full Gradient: 431.68438081775093\n",
      "Sum of scalar products for gradients in same class: 7330.565728534566\n",
      "Sum of scalar products for gradients in different class: -6898.881347716815\n",
      "Loss: 0.00046968937385827303\n",
      "\n",
      "\n",
      "Iteration: 933\n",
      "Squared L2 Norm of Full Gradient: 430.7751364912983\n",
      "Sum of scalar products for gradients in same class: 7315.7937620531175\n",
      "Sum of scalar products for gradients in different class: -6885.018625561819\n",
      "Loss: 0.00046920854947529733\n",
      "\n",
      "\n",
      "Iteration: 934\n",
      "Squared L2 Norm of Full Gradient: 429.85933712014594\n",
      "Sum of scalar products for gradients in same class: 7300.857111264471\n",
      "Sum of scalar products for gradients in different class: -6870.997774144325\n",
      "Loss: 0.00046872784150764346\n",
      "\n",
      "\n",
      "Iteration: 935\n",
      "Squared L2 Norm of Full Gradient: 428.9622097989195\n",
      "Sum of scalar products for gradients in same class: 7286.209291699432\n",
      "Sum of scalar products for gradients in different class: -6857.247081900512\n",
      "Loss: 0.00046825219760648906\n",
      "\n",
      "\n",
      "Iteration: 936\n",
      "Squared L2 Norm of Full Gradient: 428.06262584455544\n",
      "Sum of scalar products for gradients in same class: 7271.5224535022835\n",
      "Sum of scalar products for gradients in different class: -6843.459827657728\n",
      "Loss: 0.00046777710667811334\n",
      "\n",
      "\n",
      "Iteration: 937\n",
      "Squared L2 Norm of Full Gradient: 427.162803518444\n",
      "Sum of scalar products for gradients in same class: 7256.916201732122\n",
      "Sum of scalar products for gradients in different class: -6829.753398213678\n",
      "Loss: 0.00046730111353099346\n",
      "\n",
      "\n",
      "Iteration: 938\n",
      "Squared L2 Norm of Full Gradient: 426.2658969109216\n",
      "Sum of scalar products for gradients in same class: 7242.327634860479\n",
      "Sum of scalar products for gradients in different class: -6816.061737949557\n",
      "Loss: 0.00046682788524776697\n",
      "\n",
      "\n",
      "Iteration: 939\n",
      "Squared L2 Norm of Full Gradient: 425.3740240763036\n",
      "Sum of scalar products for gradients in same class: 7227.7229060241025\n",
      "Sum of scalar products for gradients in different class: -6802.348881947799\n",
      "Loss: 0.00046635547187179327\n",
      "\n",
      "\n",
      "Iteration: 940\n",
      "Squared L2 Norm of Full Gradient: 424.4880366948346\n",
      "Sum of scalar products for gradients in same class: 7213.300445620607\n",
      "Sum of scalar products for gradients in different class: -6788.812408925773\n",
      "Loss: 0.0004658818361349404\n",
      "\n",
      "\n",
      "Iteration: 941\n",
      "Squared L2 Norm of Full Gradient: 423.60360106325606\n",
      "Sum of scalar products for gradients in same class: 7198.920629825356\n",
      "Sum of scalar products for gradients in different class: -6775.3170287621\n",
      "Loss: 0.00046541064511984587\n",
      "\n",
      "\n",
      "Iteration: 942\n",
      "Squared L2 Norm of Full Gradient: 422.7168721132657\n",
      "Sum of scalar products for gradients in same class: 7184.411656898902\n",
      "Sum of scalar products for gradients in different class: -6761.694784785636\n",
      "Loss: 0.0004649406182579696\n",
      "\n",
      "\n",
      "Iteration: 943\n",
      "Squared L2 Norm of Full Gradient: 421.836243231377\n",
      "Sum of scalar products for gradients in same class: 7170.079752563576\n",
      "Sum of scalar products for gradients in different class: -6748.243509332199\n",
      "Loss: 0.00046447335625998676\n",
      "\n",
      "\n",
      "Iteration: 944\n",
      "Squared L2 Norm of Full Gradient: 420.9581762040616\n",
      "Sum of scalar products for gradients in same class: 7155.757096357077\n",
      "Sum of scalar products for gradients in different class: -6734.798920153015\n",
      "Loss: 0.0004639997205231339\n",
      "\n",
      "\n",
      "Iteration: 945\n",
      "Squared L2 Norm of Full Gradient: 420.0803203230171\n",
      "Sum of scalar products for gradients in same class: 7141.445366150576\n",
      "Sum of scalar products for gradients in different class: -6721.365045827559\n",
      "Loss: 0.0004635340010281652\n",
      "\n",
      "\n",
      "Iteration: 946\n",
      "Squared L2 Norm of Full Gradient: 419.21048820807846\n",
      "Sum of scalar products for gradients in same class: 7127.253356519003\n",
      "Sum of scalar products for gradients in different class: -6708.042868310925\n",
      "Loss: 0.0004630675830412656\n",
      "\n",
      "\n",
      "Iteration: 947\n",
      "Squared L2 Norm of Full Gradient: 418.3450686442993\n",
      "Sum of scalar products for gradients in same class: 7113.134242738969\n",
      "Sum of scalar products for gradients in different class: -6694.78917409467\n",
      "Loss: 0.0004626046575140208\n",
      "\n",
      "\n",
      "Iteration: 948\n",
      "Squared L2 Norm of Full Gradient: 417.47594465553993\n",
      "Sum of scalar products for gradients in same class: 7098.960952965562\n",
      "Sum of scalar products for gradients in different class: -6681.485008310022\n",
      "Loss: 0.00046213893801905215\n",
      "\n",
      "\n",
      "Iteration: 949\n",
      "Squared L2 Norm of Full Gradient: 416.6088923468633\n",
      "Sum of scalar products for gradients in same class: 7084.772386903428\n",
      "Sum of scalar products for gradients in different class: -6668.163494556565\n",
      "Loss: 0.0004616732767317444\n",
      "\n",
      "\n",
      "Iteration: 950\n",
      "Squared L2 Norm of Full Gradient: 415.7474082224653\n",
      "Sum of scalar products for gradients in same class: 7070.7593914601175\n",
      "Sum of scalar products for gradients in different class: -6655.011983237652\n",
      "Loss: 0.00046121154446154833\n",
      "\n",
      "\n",
      "Iteration: 951\n",
      "Squared L2 Norm of Full Gradient: 414.8889136509424\n",
      "Sum of scalar products for gradients in same class: 7056.745864369566\n",
      "Sum of scalar products for gradients in different class: -6641.856950718624\n",
      "Loss: 0.0004607490263879299\n",
      "\n",
      "\n",
      "Iteration: 952\n",
      "Squared L2 Norm of Full Gradient: 414.0350321611768\n",
      "Sum of scalar products for gradients in same class: 7042.824211177981\n",
      "Sum of scalar products for gradients in different class: -6628.789179016804\n",
      "Loss: 0.0004602896806318313\n",
      "\n",
      "\n",
      "Iteration: 953\n",
      "Squared L2 Norm of Full Gradient: 413.1845115743672\n",
      "Sum of scalar products for gradients in same class: 7028.868060972059\n",
      "Sum of scalar products for gradients in different class: -6615.683549397691\n",
      "Loss: 0.00045983114978298545\n",
      "\n",
      "\n",
      "Iteration: 954\n",
      "Squared L2 Norm of Full Gradient: 412.3347880044057\n",
      "Sum of scalar products for gradients in same class: 7015.0225868891475\n",
      "Sum of scalar products for gradients in different class: -6602.687798884742\n",
      "Loss: 0.00045937340473756194\n",
      "\n",
      "\n",
      "Iteration: 955\n",
      "Squared L2 Norm of Full Gradient: 411.4893438686304\n",
      "Sum of scalar products for gradients in same class: 7001.229267166789\n",
      "Sum of scalar products for gradients in different class: -6589.739923298159\n",
      "Loss: 0.00045891248737461865\n",
      "\n",
      "\n",
      "Iteration: 956\n",
      "Squared L2 Norm of Full Gradient: 410.64260289902813\n",
      "Sum of scalar products for gradients in same class: 6987.357693259877\n",
      "Sum of scalar products for gradients in different class: -6576.715090360849\n",
      "Loss: 0.0004584570706356317\n",
      "\n",
      "\n",
      "Iteration: 957\n",
      "Squared L2 Norm of Full Gradient: 409.7991279198468\n",
      "Sum of scalar products for gradients in same class: 6973.6042312919535\n",
      "Sum of scalar products for gradients in different class: -6563.805103372107\n",
      "Loss: 0.00045799731742590666\n",
      "\n",
      "\n",
      "Iteration: 958\n",
      "Squared L2 Norm of Full Gradient: 408.9599144113927\n",
      "Sum of scalar products for gradients in same class: 6959.9067713299455\n",
      "Sum of scalar products for gradients in different class: -6550.946856918553\n",
      "Loss: 0.00045754274469800293\n",
      "\n",
      "\n",
      "Iteration: 959\n",
      "Squared L2 Norm of Full Gradient: 408.11809318315136\n",
      "Sum of scalar products for gradients in same class: 6946.119282797107\n",
      "Sum of scalar products for gradients in different class: -6538.001189613956\n",
      "Loss: 0.00045709015103057027\n",
      "\n",
      "\n",
      "Iteration: 960\n",
      "Squared L2 Norm of Full Gradient: 407.2853766861954\n",
      "Sum of scalar products for gradients in same class: 6932.557760513964\n",
      "Sum of scalar products for gradients in different class: -6525.272383827769\n",
      "Loss: 0.00045663758646696806\n",
      "\n",
      "\n",
      "Iteration: 961\n",
      "Squared L2 Norm of Full Gradient: 406.4555101694168\n",
      "Sum of scalar products for gradients in same class: 6919.005928446525\n",
      "Sum of scalar products for gradients in different class: -6512.550418277108\n",
      "Loss: 0.0004561849927995354\n",
      "\n",
      "\n",
      "Iteration: 962\n",
      "Squared L2 Norm of Full Gradient: 405.62564484979157\n",
      "Sum of scalar products for gradients in same class: 6905.375965298768\n",
      "Sum of scalar products for gradients in different class: -6499.750320448977\n",
      "Loss: 0.0004557323409244418\n",
      "\n",
      "\n",
      "Iteration: 963\n",
      "Squared L2 Norm of Full Gradient: 404.80038832925493\n",
      "Sum of scalar products for gradients in same class: 6891.9133389083045\n",
      "Sum of scalar products for gradients in different class: -6487.1129505790495\n",
      "Loss: 0.00045528405462391675\n",
      "\n",
      "\n",
      "Iteration: 964\n",
      "Squared L2 Norm of Full Gradient: 403.9762788561384\n",
      "Sum of scalar products for gradients in same class: 6878.458621004688\n",
      "Sum of scalar products for gradients in different class: -6474.48234214855\n",
      "Loss: 0.00045483509893529117\n",
      "\n",
      "\n",
      "Iteration: 965\n",
      "Squared L2 Norm of Full Gradient: 403.1547707812606\n",
      "Sum of scalar products for gradients in same class: 6865.050893493631\n",
      "Sum of scalar products for gradients in different class: -6461.89612271237\n",
      "Loss: 0.00045438602683134377\n",
      "\n",
      "\n",
      "Iteration: 966\n",
      "Squared L2 Norm of Full Gradient: 402.3287427303185\n",
      "Sum of scalar products for gradients in same class: 6851.540728660231\n",
      "Sum of scalar products for gradients in different class: -6449.211985929913\n",
      "Loss: 0.00045393535401672125\n",
      "\n",
      "\n",
      "Iteration: 967\n",
      "Squared L2 Norm of Full Gradient: 401.5140337410994\n",
      "Sum of scalar products for gradients in same class: 6838.215925813282\n",
      "Sum of scalar products for gradients in different class: -6436.701892072183\n",
      "Loss: 0.0004534883191809058\n",
      "\n",
      "\n",
      "Iteration: 968\n",
      "Squared L2 Norm of Full Gradient: 400.6991577858571\n",
      "Sum of scalar products for gradients in same class: 6824.903104813228\n",
      "Sum of scalar products for gradients in different class: -6424.203947027371\n",
      "Loss: 0.0004530460573732853\n",
      "\n",
      "\n",
      "Iteration: 969\n",
      "Squared L2 Norm of Full Gradient: 399.8902205459344\n",
      "Sum of scalar products for gradients in same class: 6811.622021661675\n",
      "Sum of scalar products for gradients in different class: -6411.73180111574\n",
      "Loss: 0.00045260219485498965\n",
      "\n",
      "\n",
      "Iteration: 970\n",
      "Squared L2 Norm of Full Gradient: 399.0856823851973\n",
      "Sum of scalar products for gradients in same class: 6798.490623185036\n",
      "Sum of scalar products for gradients in different class: -6399.404940799839\n",
      "Loss: 0.00045215513091534376\n",
      "\n",
      "\n",
      "Iteration: 971\n",
      "Squared L2 Norm of Full Gradient: 398.2764730281815\n",
      "Sum of scalar products for gradients in same class: 6785.240831218897\n",
      "Sum of scalar products for gradients in different class: -6386.964358190716\n",
      "Loss: 0.0004517132183536887\n",
      "\n",
      "\n",
      "Iteration: 972\n",
      "Squared L2 Norm of Full Gradient: 397.4693777907087\n",
      "Sum of scalar products for gradients in same class: 6772.052966258479\n",
      "Sum of scalar products for gradients in different class: -6374.58358846777\n",
      "Loss: 0.000451269734185189\n",
      "\n",
      "\n",
      "Iteration: 973\n",
      "Squared L2 Norm of Full Gradient: 396.6645446871553\n",
      "Sum of scalar products for gradients in same class: 6758.849938263899\n",
      "Sum of scalar products for gradients in different class: -6362.185393576744\n",
      "Loss: 0.00045082822907716036\n",
      "\n",
      "\n",
      "Iteration: 974\n",
      "Squared L2 Norm of Full Gradient: 395.8717602657998\n",
      "Sum of scalar products for gradients in same class: 6745.901200044752\n",
      "Sum of scalar products for gradients in different class: -6350.029439778952\n",
      "Loss: 0.00045038750977255404\n",
      "\n",
      "\n",
      "Iteration: 975\n",
      "Squared L2 Norm of Full Gradient: 395.0729448130005\n",
      "Sum of scalar products for gradients in same class: 6732.827338987012\n",
      "Sum of scalar products for gradients in different class: -6337.754394174011\n",
      "Loss: 0.00044994716881774366\n",
      "\n",
      "\n",
      "Iteration: 976\n",
      "Squared L2 Norm of Full Gradient: 394.2757693312924\n",
      "Sum of scalar products for gradients in same class: 6719.798853002592\n",
      "Sum of scalar products for gradients in different class: -6325.5230836713\n",
      "Loss: 0.00044951040763407946\n",
      "\n",
      "\n",
      "Iteration: 977\n",
      "Squared L2 Norm of Full Gradient: 393.4826527264704\n",
      "Sum of scalar products for gradients in same class: 6706.811670372649\n",
      "Sum of scalar products for gradients in different class: -6313.329017646179\n",
      "Loss: 0.0004490728606469929\n",
      "\n",
      "\n",
      "Iteration: 978\n",
      "Squared L2 Norm of Full Gradient: 392.69728927757023\n",
      "Sum of scalar products for gradients in same class: 6693.963054357578\n",
      "Sum of scalar products for gradients in different class: -6301.265765080007\n",
      "Loss: 0.00044863775838166475\n",
      "\n",
      "\n",
      "Iteration: 979\n",
      "Squared L2 Norm of Full Gradient: 391.91346556446297\n",
      "Sum of scalar products for gradients in same class: 6681.091958134557\n",
      "Sum of scalar products for gradients in different class: -6289.178492570094\n",
      "Loss: 0.0004482002113945782\n",
      "\n",
      "\n",
      "Iteration: 980\n",
      "Squared L2 Norm of Full Gradient: 391.1234841329897\n",
      "Sum of scalar products for gradients in same class: 6668.1932988411545\n",
      "Sum of scalar products for gradients in different class: -6277.069814708165\n",
      "Loss: 0.0004477669717743993\n",
      "\n",
      "\n",
      "Iteration: 981\n",
      "Squared L2 Norm of Full Gradient: 390.34296688660106\n",
      "Sum of scalar products for gradients in same class: 6655.408493882425\n",
      "Sum of scalar products for gradients in different class: -6265.065526995824\n",
      "Loss: 0.00044732983224093914\n",
      "\n",
      "\n",
      "Iteration: 982\n",
      "Squared L2 Norm of Full Gradient: 389.5624762895786\n",
      "Sum of scalar products for gradients in same class: 6642.583600945611\n",
      "Sum of scalar products for gradients in different class: -6253.021124656032\n",
      "Loss: 0.00044689467176795006\n",
      "\n",
      "\n",
      "Iteration: 983\n",
      "Squared L2 Norm of Full Gradient: 388.7822402530619\n",
      "Sum of scalar products for gradients in same class: 6629.883998106486\n",
      "Sum of scalar products for gradients in different class: -6241.101757853424\n",
      "Loss: 0.00044646149035543203\n",
      "\n",
      "\n",
      "Iteration: 984\n",
      "Squared L2 Norm of Full Gradient: 388.00361290114233\n",
      "Sum of scalar products for gradients in same class: 6617.107208691593\n",
      "Sum of scalar products for gradients in different class: -6229.1035957904505\n",
      "Loss: 0.00044602909474633634\n",
      "\n",
      "\n",
      "Iteration: 985\n",
      "Squared L2 Norm of Full Gradient: 387.23605010751635\n",
      "Sum of scalar products for gradients in same class: 6604.531850908636\n",
      "Sum of scalar products for gradients in different class: -6217.29580080112\n",
      "Loss: 0.0004456006863620132\n",
      "\n",
      "\n",
      "Iteration: 986\n",
      "Squared L2 Norm of Full Gradient: 386.4683473671321\n",
      "Sum of scalar products for gradients in same class: 6591.974065472414\n",
      "Sum of scalar products for gradients in different class: -6205.505718105282\n",
      "Loss: 0.00044517149217426777\n",
      "\n",
      "\n",
      "Iteration: 987\n",
      "Squared L2 Norm of Full Gradient: 385.70148129249355\n",
      "Sum of scalar products for gradients in same class: 6579.379936593204\n",
      "Sum of scalar products for gradients in different class: -6193.67845530071\n",
      "Loss: 0.0004447426472324878\n",
      "\n",
      "\n",
      "Iteration: 988\n",
      "Squared L2 Norm of Full Gradient: 384.9365743134549\n",
      "Sum of scalar products for gradients in same class: 6566.893927323381\n",
      "Sum of scalar products for gradients in different class: -6181.957353009926\n",
      "Loss: 0.0004443149664439261\n",
      "\n",
      "\n",
      "Iteration: 989\n",
      "Squared L2 Norm of Full Gradient: 384.1733985543251\n",
      "Sum of scalar products for gradients in same class: 6554.307747142884\n",
      "Sum of scalar products for gradients in different class: -6170.134348588559\n",
      "Loss: 0.00044388617970980704\n",
      "\n",
      "\n",
      "Iteration: 990\n",
      "Squared L2 Norm of Full Gradient: 383.4115029488785\n",
      "Sum of scalar products for gradients in same class: 6541.875887881753\n",
      "Sum of scalar products for gradients in different class: -6158.464384932875\n",
      "Loss: 0.0004434581205714494\n",
      "\n",
      "\n",
      "Iteration: 991\n",
      "Squared L2 Norm of Full Gradient: 382.6467071711704\n",
      "Sum of scalar products for gradients in same class: 6529.346564956993\n",
      "Sum of scalar products for gradients in different class: -6146.699857785822\n",
      "Loss: 0.0004430321278050542\n",
      "\n",
      "\n",
      "Iteration: 992\n",
      "Squared L2 Norm of Full Gradient: 381.8946769490285\n",
      "Sum of scalar products for gradients in same class: 6517.013594405433\n",
      "Sum of scalar products for gradients in different class: -6135.118917456404\n",
      "Loss: 0.00044260919094085693\n",
      "\n",
      "\n",
      "Iteration: 993\n",
      "Squared L2 Norm of Full Gradient: 381.1377264531948\n",
      "Sum of scalar products for gradients in same class: 6504.590943964517\n",
      "Sum of scalar products for gradients in different class: -6123.453217511322\n",
      "Loss: 0.00044218829134479165\n",
      "\n",
      "\n",
      "Iteration: 994\n",
      "Squared L2 Norm of Full Gradient: 380.38710685461774\n",
      "Sum of scalar products for gradients in same class: 6492.254127863371\n",
      "Sum of scalar products for gradients in different class: -6111.867021008753\n",
      "Loss: 0.0004417618620209396\n",
      "\n",
      "\n",
      "Iteration: 995\n",
      "Squared L2 Norm of Full Gradient: 379.63507165737974\n",
      "Sum of scalar products for gradients in same class: 6479.951864829473\n",
      "Sum of scalar products for gradients in different class: -6100.316793172094\n",
      "Loss: 0.000441337819211185\n",
      "\n",
      "\n",
      "Iteration: 996\n",
      "Squared L2 Norm of Full Gradient: 378.8849686388894\n",
      "Sum of scalar products for gradients in same class: 6467.668505863137\n",
      "Sum of scalar products for gradients in different class: -6088.783537224248\n",
      "Loss: 0.0004409173270687461\n",
      "\n",
      "\n",
      "Iteration: 997\n",
      "Squared L2 Norm of Full Gradient: 378.14391554892063\n",
      "Sum of scalar products for gradients in same class: 6455.447952460353\n",
      "Sum of scalar products for gradients in different class: -6077.304036911432\n",
      "Loss: 0.00044049639836885035\n",
      "\n",
      "\n",
      "Iteration: 998\n",
      "Squared L2 Norm of Full Gradient: 377.39706642780584\n",
      "Sum of scalar products for gradients in same class: 6443.2501940187585\n",
      "Sum of scalar products for gradients in different class: -6065.853127590953\n",
      "Loss: 0.0004400774196255952\n",
      "\n",
      "\n",
      "Iteration: 999\n",
      "Squared L2 Norm of Full Gradient: 376.6609501836101\n",
      "Sum of scalar products for gradients in same class: 6431.17691627695\n",
      "Sum of scalar products for gradients in different class: -6054.51596609334\n",
      "Loss: 0.00043965777149423957\n",
      "\n",
      "\n",
      "Iteration: 1000\n",
      "Squared L2 Norm of Full Gradient: 375.920597076416\n",
      "Sum of scalar products for gradients in same class: 6419.001965849473\n",
      "Sum of scalar products for gradients in different class: -6043.081368773057\n",
      "Loss: 0.000439238065155223\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import random \n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define constants\n",
    "num_classes = 10\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 1000\n",
    "\n",
    "# Load the MNIST dataset\n",
    "training_dataset = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),  # convert the image to tensor\n",
    "            transforms.Normalize((0.1307,), (0.3081,)),  # normalize\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Load the entire dataset in a nice format\n",
    "X = training_dataset.data.reshape(-1, 28 * 28).float()\n",
    "y = training_dataset.targets\n",
    "\n",
    "# Shuffle\n",
    "ind = np.random.permutation(len(training_dataset))\n",
    "X = X[ind]\n",
    "y = y[ind]\n",
    "\n",
    "# Create a subset with equal number of examples for each class\n",
    "subset_indices = []\n",
    "class_counts = [0] * num_classes\n",
    "M = 300  # Example subset size\n",
    "for i in range(len(training_dataset)):\n",
    "    label = y[i]\n",
    "    if class_counts[label] < M // num_classes:\n",
    "        subset_indices.append(i)\n",
    "        class_counts[label] += 1\n",
    "    if all(count == M // num_classes for count in class_counts):\n",
    "        break\n",
    "        \n",
    "class LogRegression(nn.Module):\n",
    "    \"\"\"Multimodal logistic regression model\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LogRegression, self).__init__()\n",
    "        self.linear = nn.Linear(28 * 28, 10, bias=True)\n",
    "\n",
    "    def forward(self, x, verbose=False):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "model = LogRegression()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "v1 = []\n",
    "v2 = []\n",
    "v3 = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Iteration: {epoch+1}')\n",
    "    \n",
    "    gradient_list = []\n",
    "    all_gradients = []\n",
    "    for _ in range(10):\n",
    "        gradient_list.append(torch.zeros(7840))\n",
    "        all_gradients.append([])\n",
    "\n",
    "    gradient_sum = torch.zeros(7840)\n",
    "    for index in subset_indices:\n",
    "        image = X[index]\n",
    "        label = y[index]\n",
    "        model.zero_grad()\n",
    "        output = model(image)\n",
    "        loss=criterion(output, label)\n",
    "        loss.backward()\n",
    "        gradient = []\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'weight' in name:  # Only consider parameters associated with weights\n",
    "                #if param.requires_grad and param.grad is not None:\n",
    "                gradient.append(param.grad)\n",
    "                    \n",
    "        gradient=torch.stack(gradient).view(-1)\n",
    "        all_gradients[label].append(gradient)\n",
    "        gradient_list[label]+=gradient\n",
    "        gradient_sum+=gradient\n",
    "\n",
    "    # sum_diff = 0\n",
    "    # for i in range(0, num_classes-1):      \n",
    "    #     for j in range(i+1, num_classes):\n",
    "    #         for i1 in range(M // num_classes):\n",
    "    #             for j1 in range(M // num_classes):\n",
    "    #                 sum_diff+=2*torch.dot(all_gradients[i][i1],all_gradients[j][j1])\n",
    "            \n",
    "    print(f'Squared L2 Norm of Full Gradient: {gradient_sum.norm().item() ** 2}')\n",
    "    v1.append(gradient_sum.norm().item() ** 2)\n",
    "    \n",
    "    sum = 0\n",
    "    for gr in gradient_list:\n",
    "        sum += gr.norm().item() ** 2\n",
    "\n",
    "    print(f'Sum of scalar products for gradients in same class: {sum}')\n",
    "    v2.append(sum)\n",
    "    \n",
    "    print(f'Sum of scalar products for gradients in different class: {gradient_sum.norm().item() ** 2 - sum}')  \n",
    "    v3.append(gradient_sum.norm().item() ** 2 - sum)\n",
    "    \n",
    "        \n",
    "    images = X[subset_indices]\n",
    "    labels = y[subset_indices]\n",
    "    \n",
    "    model.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(images)\n",
    "        \n",
    "    # Compute loss\n",
    "    loss = criterion(output, labels.type(torch.long))\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Optimize\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print comparison and loss after each epoch\n",
    "    print(f'Loss: {loss.item()}')\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c09c7861-d08f-49b8-acc7-96eb4823c616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(num_epochs),v1, label='Squared L2 norm of full gradient')\n",
    "plt.plot(range(num_epochs),v2, label='Sum of scalar products for gradients in same class')\n",
    "plt.plot(range(num_epochs),v3, label='Sum of scalar products for gradients in different classes')\n",
    "plt.yscale('symlog')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.legend(loc='upper right',fontsize=9)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f54d07a-abc4-41dd-a59f-5f0917ac2c88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
